---
title: "Advances in Artificial Intelligence for Data Visualization: Automate Reading of Diagnostic Plots with Compute Vision Models"
author:
- familyname: Li
  othernames: Weihao (Patrick)
  address: Monash University
  qualifications: PhD student
email: weihao.li@monash.com
phone: (04) 0459 1219
department: Department of\newline Econometrics &\newline Business Statistics
organization: "Progress review" 
bibliography: report.bib
biblio-style: authoryear-comp
linestretch: 1.5
output:
  monash::report:
    fig_caption: yes
    fig_height: 5
    fig_width: 8
    includes:
      in_header: preamble.tex
    keep_tex: yes
    number_sections: yes
    citation_package: biblatex
    toc: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache=TRUE, messages=FALSE, warning=FALSE)
library(ggplot2)
```



keywords:
AI, data visualization, residual plot, visual inference, hypothesis testing, computer vision

# Overview of the thesis

## Background and motivation

Model diagnostics play a critical role in evaluating the accuracy and validity of a statistical model. They enable the assessment of the model's assumptions about the data, identification of outliers or anomalous observations that may have an exaggerated effect on the model, evaluation of how well the model fits the data, and identification of possible approaches to improve the model's performance.

When conducting model diagnostics, despite the availability of numeric summaries with finite or asymptotic properties that have been endorsed, data analysts prefer or require graphical representations of data. The preference for visual diagnostics is attributed to its intuitive nature and the possibility of discovering unexpected abstract and unquantifiable insights. In the context of regression diagnostics, a common practice is to plot residuals against fitted values, which serves as a starting point for evaluating the adequacy of the fit and verifying the underlying assumptions. Other visualization techniques such as histograms, Q-Q plots and box plots can be used to identify potential issues with assumptions made about the data, such as linearity, normality, or homoscedasticity.

In recent times, a novel statistical inferential framework known as visual inference [@buja_statistical_2009] has been developed, which relies on the use of graphical representations of data. The visual inference approach capitalizes on the innate capability of the human visual system to rapidly identify patterns and deviations from expected patterns. By exploiting visualization techniques, visual inference provides a more natural and easily comprehensible way of interpreting data and discerning relationships between variables, compared to conventional statistical techniques.
This inferential framework can be applied to perform exploratory data analysis, model selection, and hypothesis testing. 

In the same paper, @buja_statistical_2009 proposes the use of the lineup protocol as a visual hypothesis test, inspired by the police lineup technique employed in eyewitness identification of criminal suspects. The protocol comprises $m$ randomly positioned plots, where on of them represents the data plot, while the remaining $m - 1$ plots represent the null plots with the same graphical structure, except that the data in them is consistent with the null hypothesis $H_0$. Under $H_0$, the data plot is expected to be indistinguishable from the null plots, and the probability of correctly identifying the data plot by an observer is $1/m$. If the data plot is correctly identified, it provides evidence against $H_0$.

This method has gained increasing traction in recent years and has already been integrated into data analysis of various topics, such as diagnostics of hierarchical linear models [@loy2013diagnostic], geographical research [@widen_graphical_2016] and forensic examinations [@krishnan_hierarchical_2021].
With the advent of sophisticated visualization software and tools, visual inference has the potential to revolutionize statistical analysis by providing an innovative alternative to traditional statistical approaches and enabling more lucid and effective communication of research findings.

The incorporation of human judgment is a fundamental aspect of visual testing, but it may restrict its widespread usage. The reliance on human assessment, akin to handicraft production methods employed in pre-industrial societies, renders the lineup protocol unsuitable for large-scale applications, due to its high labor costs and time requirements. Moreover, it presents significant usability issues for individuals with visual impairments, resulting in reduced accessibility.

The advancement of technology is essential to alleviate the workload of individuals by automating repetitive tasks and providing standardized results in a controlled environment. The evaluation of visual tests on a large scale is not feasible without the aid of machines and technology. Modern computer vision models offer a promising solution to this challenge. As a subfield of AI, computer vision with its modern deep learning architectures has successfully resolved numerous critical problems in automation. The development of the convolutional neural network (CNN) by @fukushima_neocognitron_1982 was inspired by the vision processing in living organisms. This architecture was first applied to hand-written number recognition trained with back-propagation by @lecun_backpropagation_1989, making it one of the earliest attempts at successfully extracting information from digital images via self-learning algorithms. The modern computer vision model typically utilizes deep neural networks with convolutional layers [@fukushima_neocognitron_1982], which leverage the hierarchical pattern in data and provide regularized versions of fully-connected layers. This approach downscales and transforms images by summarizing information in a small space. Numerous studies have shown that it can effectively tackle vision tasks, such as image recognition [@rawat_deep_2017]. The development of graphics processing units and the widespread availability of high-performance personal computers have made computer vision research a new trend in the 21st century. The remarkable achievements, such as computer-aided diagnosis [@lee_image_2015], pedestrian detection [@brunetti_computer_2018], and facial recognition [@emami_facial_2012], have significantly impacted our daily life.

The utilization of computer vision models for reading data plots is not widely adopted. Nevertheless, certain fields have embraced this notion, as evidenced by the application of computer vision models in reading recurrence plots for time series regression [@ojeda_multivariate_2020], time series classification [@chu_automatic_2019; @hailesilassie_financial_2019; @hatami_classification_2018; @zhang_encoding_2020], anomaly detection [@chen_convolutional_2020], and pairwise causality analysis [@singh_deep_2017]. However, the assessment of lineups with computer vision models represents a relatively novel area of investigation.

## Research questions

The main objective of this research is to construct an automatic visual inference system to facilitate conducting regression diagnostics visual tests on a large scale. The study will concentrate on three specific projects, namely

1. Exploring the application of visual inference in regression diagnostics and comparing its efficacy with conventional hypothesis tests.
2. Designing an automated visual inference system to assess lineups of residual plots derived from the classical normal linear regression model.
3. Deploying the automatic visual inference system as an online application and and making the pertinent open-source software accessible.

## Current reserach outcomes

In the initial phase of this research, a pilot investigation was undertaken to explore the viability of implementing visual inference in regression diagnostics. The pilot study involved 64 participants and focused on utilizing a lineup consisting of 20 plots, wherein a residual plot was embedded along with 19 null plots, simulated using the residual rotation technique. The study considered two primary forms of residual departures, namely non-linearity and heteroskedasticity, within a multiple linear regression context. To enrich the visual features, different fitted value distributions, including normal, uniform, lognormal, and discrete uniform, were also incorporated. 

The outcomes of this pilot study demonstrated that the power of visual tests in regression diagnostics increases proportionately with the number of lineup evaluations. Nevertheless, it was observed that conventional tests, such as the F-test for non-linearity and the Breusch-Pagan test for heteroskedasticity, exhibited significantly greater power than the visual tests. While the pilot study successfully provided a comparative analysis of the power of visual and conventional tests, the impact of various factors on the power of visual tests could not be fully analyzed due to inadequate data.

We acknowledge the limitations of this pilot study, particularly in the design of the simulated model, which made it challenging to explicate the involved factors. Furthermore, the methodology utilized for effect size calculation, p-value calculation, and power estimation was incipient. Hence, a follow-up study is necessary to address these limitations and obtain a more comprehensive understanding of the potential of visual inference in regression diagnostics.

In the subsequent year, a similar study was conducted, utilizing simpler simulated models to elicit more distinct visual patterns. Specifically, the non-linearity model was formulated as

\begin{align} \label{eq:nonlinearity-model}
\boldsymbol{y} &= 1 + \boldsymbol{x} + \boldsymbol{z} + \boldsymbol{\varepsilon},\\
\boldsymbol{x} &= g(\boldsymbol{x}_{raw}, 1), \\
\boldsymbol{z} &= g(\boldsymbol{z}_{raw}, 1), \\
\boldsymbol{z}_{raw} &= He_j(g(\boldsymbol{x}, 2)),
\end{align}

\noindent where $\boldsymbol{y}$, $\boldsymbol{x}$, $\boldsymbol{\varepsilon}$, $\boldsymbol{x}_{raw}$, $\boldsymbol{z}_{raw}$ are vectors of size $n$, $He_{j}(.)$ is the $j$th-order probabilist's Hermite polynomials, $\varepsilon \sim N(\boldsymbol{0}, \sigma^2\boldsymbol{I}_n)$, and $g(\boldsymbol{x}, k)$ is a scaling function to enforce the support of the random vector to be $[-k, k]^n$ defined as

\begin{equation} \label{eq:scaling-function}
g(\boldsymbol{x}, k) = \frac{\boldsymbol{x} - min(\boldsymbol{x})}{max(\boldsymbol{x}) - min(\boldsymbol{x})}(2k - k), \quad \text{for} \quad k > 0. 
\end{equation}

The heteroskedasticity model was formulated as

\begin{align} \label{eq:heter-model}
\boldsymbol{y} &= 1 + \boldsymbol{x} + \boldsymbol{\varepsilon},\\
\boldsymbol{x} &= g(\boldsymbol{x}_{raw}, 1),\\
\boldsymbol{\varepsilon} &\sim N(\boldsymbol{0}, 1 + (2 - |a|)(\boldsymbol{x} - a)^2b \boldsymbol{I}). 
\end{align}

The null regression model used to fit the realizations generated by the above models is formulated as

\begin{equation} \label{eq:null-model}
\boldsymbol{y} = \beta_0 + \beta_1 \boldsymbol{x} + \boldsymbol{u},
\end{equation}

\noindent where $\boldsymbol{u} \sim N(\boldsymbol{0}, \sigma^2\boldsymbol{I}_n)$.

Since $z = O(x^j)$, for $j > 1$, $z$ is a higher order term leaves out by the null regression, which will violate the linearity model assumption. Similarly, for $b \neq 0$, the variance-covariance matrix of the error term $\boldsymbol{\varepsilon}$ is correlated with the predictor $\boldsymbol{x}$, which will lead to the presence of heteroskedasticity.

- draft below

The effect size was derived using the Kullback-Leibler divergence method, formulated as Equation 3. To account for the interdependence of lineups presented to different participants, p-value calculation, as suggested by VanderPlas et al. (2021), was adopted. Furthermore, power estimation was simplified through a logistic regression model that lacked an intercept but included a fixed offset to ensure that the power equated to 5% when the effect size was zero. A detailed description of the experimental design, effect size derivation, p-value calculation, and power estimation can be found in the attached paper.



3. summarise the work in the first year
- an experiment to compare visual test with conventional test 
- a prototype model for lineup evaluation
- points out the limitation of the work
4. summarise the work in the second year
- refine and reconduct the experiment
5. main findings to date
- findings from the first year
- findings from the second year

# Thesis structure

topic

chapter 1: Introduction

chapter 2
the first paper

chapter 3
build a computer vision system to evaluate residual plot

chapter 4?
software publication

chapter 5
discussion and future work

# Timetable

- April: submit abstract to ASC
- May: submit paper
- June: submit poster/short paper to IEEE vis conf, start working on computer vision model
- July: leave for few weeks
- Aug
- Sep: finalize the computer vision model
- Oct: IEEE vis conf
- Nov: web interface development 
- Dec: ASC

- Jan, 2024: 
- Feb, 2024: 
- Mar, 2024: submit paper
- Aug, 2024: submit thesis  

# Difficulties

things that are actually quite serious

1. identified difficulties
2. suggestions for overcoming these difficulties

# References


