\documentclass[11pt,a4paper,]{article}
\usepackage{lmodern}

\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\PassOptionsToPackage{hyphens}{url} % url is loaded by hyperref
\usepackage[unicode=true]{hyperref}
\hypersetup{
            pdftitle={Advances in Artificial Intelligence for Data Visualization: Automate Reading of Diagnostic Plots with Compute Vision Models},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{geometry}
\geometry{a4paper, centering, text={16cm,25cm}}
\usepackage[style=authoryear-comp,]{biblatex}
\addbibresource{report.bib}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{long table}}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother


\title{Advances in Artificial Intelligence for Data Visualization: Automate Reading of Diagnostic Plots with Compute Vision Models}

%% MONASH STUFF

%% CAPTIONS
\RequirePackage{caption}
\DeclareCaptionStyle{italic}[justification=centering]
 {labelfont={bf},textfont={it},labelsep=colon}
\captionsetup[figure]{style=italic,format=hang,singlelinecheck=true}
\captionsetup[table]{style=italic,format=hang,singlelinecheck=true}


%% FONT
\RequirePackage{bera}
\RequirePackage[charter,expert,sfscaled]{mathdesign}
\RequirePackage{fontawesome}

%% HEADERS AND FOOTERS
\RequirePackage{fancyhdr}
\pagestyle{fancy}
\rfoot{\Large\sffamily\raisebox{-0.1cm}{\textbf{\thepage}}}
\makeatletter
\lhead{\textsf{\expandafter{\@title}}}
\makeatother
\rhead{}
\cfoot{}
\setlength{\headheight}{15pt}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\fancypagestyle{plain}{%
\fancyhf{} % clear all header and footer fields
\fancyfoot[C]{\sffamily\thepage} % except the center
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}}

%% MATHS
\RequirePackage{bm,amsmath}
\allowdisplaybreaks

%% GRAPHICS
\RequirePackage{graphicx}
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{4}
\renewcommand{\topfraction}{0.85}
\renewcommand{\bottomfraction}{0.85}
\renewcommand{\textfraction}{0.15}
\renewcommand{\floatpagefraction}{0.8}


%\RequirePackage[section]{placeins}

%% SECTION TITLES


%% SECTION TITLES
\RequirePackage[compact,sf,bf]{titlesec}
\titleformat*{\section}{\Large\sf\bfseries\color[rgb]{0.7,0,0}}
\titleformat*{\subsection}{\large\sf\bfseries\color[rgb]{0.7,0,0}}
\titleformat*{\subsubsection}{\sf\bfseries\color[rgb]{0.7,0,0}}
\titlespacing{\section}{0pt}{2ex}{.5ex}
\titlespacing{\subsection}{0pt}{1.5ex}{0ex}
\titlespacing{\subsubsection}{0pt}{.5ex}{0ex}


%% TITLE PAGE
\def\Date{\number\day}
\def\Month{\ifcase\month\or
 January\or February\or March\or April\or May\or June\or
 July\or August\or September\or October\or November\or December\fi}
\def\Year{\number\year}

%% LINE AND PAGE BREAKING
\sloppy
\clubpenalty = 10000
\widowpenalty = 10000
\brokenpenalty = 10000
\RequirePackage{microtype}

%% PARAGRAPH BREAKS
\setlength{\parskip}{1.4ex}
\setlength{\parindent}{0em}

%% HYPERLINKS
\RequirePackage{xcolor} % Needed for links
\definecolor{darkblue}{rgb}{0,0,.6}
\RequirePackage{url}

\makeatletter
\@ifpackageloaded{hyperref}{}{\RequirePackage{hyperref}}
\makeatother
\hypersetup{
     citecolor=0 0 0,
     breaklinks=true,
     bookmarksopen=true,
     bookmarksnumbered=true,
     linkcolor=darkblue,
     urlcolor=blue,
     citecolor=darkblue,
     colorlinks=true}

\usepackage[showonlyrefs]{mathtools}
\usepackage[no-weekday]{eukdate}

%% BIBLIOGRAPHY

\makeatletter
\@ifpackageloaded{biblatex}{}{\usepackage[style=authoryear-comp, backend=biber, natbib=true]{biblatex}}
\makeatother
\ExecuteBibliographyOptions{bibencoding=utf8,minnames=1,maxnames=3, maxbibnames=99,dashed=false,terseinits=true,giveninits=true,uniquename=false,uniquelist=false,doi=false, isbn=false,url=true,sortcites=false}

\DeclareFieldFormat{url}{\texttt{\url{#1}}}
\DeclareFieldFormat[article]{pages}{#1}
\DeclareFieldFormat[inproceedings]{pages}{\lowercase{pp.}#1}
\DeclareFieldFormat[incollection]{pages}{\lowercase{pp.}#1}
\DeclareFieldFormat[article]{volume}{\mkbibbold{#1}}
\DeclareFieldFormat[article]{number}{\mkbibparens{#1}}
\DeclareFieldFormat[article]{title}{\MakeCapital{#1}}
\DeclareFieldFormat[article]{url}{}
%\DeclareFieldFormat[book]{url}{}
%\DeclareFieldFormat[inbook]{url}{}
%\DeclareFieldFormat[incollection]{url}{}
%\DeclareFieldFormat[inproceedings]{url}{}
\DeclareFieldFormat[inproceedings]{title}{#1}
\DeclareFieldFormat{shorthandwidth}{#1}
%\DeclareFieldFormat{extrayear}{}
% No dot before number of articles
\usepackage{xpatch}
\xpatchbibmacro{volume+number+eid}{\setunit*{\adddot}}{}{}{}
% Remove In: for an article.
\renewbibmacro{in:}{%
  \ifentrytype{article}{}{%
  \printtext{\bibstring{in}\intitlepunct}}}

\AtEveryBibitem{\clearfield{month}}
\AtEveryCitekey{\clearfield{month}}

\makeatletter
\DeclareDelimFormat[cbx@textcite]{nameyeardelim}{\addspace}
\makeatother

\author{\sf{\Large\textbf{Weihao (Patrick) Li}\\\large PhD student\\[0.5cm]}}

\date{\sf\Date~\Month~\Year}
\makeatletter
\lfoot{\sf Li: \@date}
\makeatother


%%%% PAGE STYLE FOR FRONT PAGE OF REPORTS

\makeatletter
\def\organization#1{\gdef\@organization{#1}}
\def\telephone#1{\gdef\@telephone{#1}}
\def\email#1{\gdef\@email{#1}}
\makeatother
  \organization{Progress review}

  \def\name{Department of\newline Econometrics \&\newline Business Statistics}

  \telephone{(04) 0459 1219}

  \email{\href{mailto:weihao.li@monash.com}{\nolinkurl{weihao.li@monash.com}}}

\def\webaddress{\url{http://buseco.monash.edu/ebs/consulting/}}
\def\abn{12 377 614 012}
\def\extraspace{\vspace*{1.6cm}}
\makeatletter
\def\contactdetails{\faicon{phone} & \@telephone \\
                    \faicon{envelope} & \@email}
\makeatother

\usepackage[absolute,overlay]{textpos}
\setlength{\TPHorizModule}{1cm}
\setlength{\TPVertModule}{1cm}

%%%% FRONT PAGE OF REPORTS

\def\reporttype{Report for}

\long\def\front#1#2#3{
\newpage
\begin{textblock}{7}(12.7,28.2)\hfill
\includegraphics[height=0.6cm]{AACSB}~~~
\includegraphics[height=0.6cm]{EQUIS}~~~
\includegraphics[height=0.6cm]{AMBA}
\end{textblock}
\begin{singlespacing}
\thispagestyle{empty}
\vspace*{-1.4cm}
\hspace*{-1.4cm}
\hbox to 16cm{
  \hbox to 6.5cm{\vbox to 14cm{\vbox to 25cm{
    \includegraphics[width=6cm]{monash2}
    \vfill
    \includegraphics[width=3.5cm]{MBSportrait}
    \vspace{0.4cm}
    \par
    \parbox{6.3cm}{\raggedright
      \sf\color[rgb]{0.00,0.00,0.70}
      {\large\textbf{\name}}\par
      \vspace{.7cm}
      \tabcolsep=0.12cm\sf\small
      \begin{tabular}{@{}ll@{}}\contactdetails
      \end{tabular}
      \vspace*{0.3cm}\par
      ABN: \abn\par
    }
  }\vss}\hss}
  \hspace*{0.2cm}
  \hbox to 1cm{\vbox to 14cm{\rule{1pt}{26.8cm}\vss}\hss\hfill}
  \hbox to 10cm{\vbox to 14cm{\vbox to 25cm{
      \vspace*{3cm}\sf\raggedright
      \parbox{11cm}{\sf\raggedright\baselineskip=1.2cm
         \fontsize{24.88}{30}\color[rgb]{0.70,0.00,0.00}\sf\textbf{#1}}
      \par
      \vfill
      \large
      \vbox{\parskip=0.8cm #2}\par
      \vspace*{2cm}\par
      \reporttype\\[0.3cm]
      \hbox{#3}%\\[2cm]\
      \vspace*{1cm}
      {\large\sf\textbf{\Date~\Month~\Year}}
   }\vss}
  }}
\end{singlespacing}
\newpage
}

\makeatletter
\def\titlepage{\front{\expandafter{\@title}}{\@author}{\@organization}}
\makeatother

\usepackage{setspace}
\setstretch{1.5}

%% Any special functions or other packages can be loaded here.


\begin{document}
\titlepage

keywords:
AI, data visualization, residual plot, visual inference, hypothesis testing, computer vision

\hypertarget{overview-of-the-thesis}{%
\section{Overview of the thesis}\label{overview-of-the-thesis}}

\hypertarget{background-and-motivation}{%
\subsection{Background and motivation}\label{background-and-motivation}}

Model diagnostics play a critical role in evaluating the accuracy and validity of a statistical model. They enable the assessment of the model's assumptions about the data, detection of outliers, evaluation of how well the model fits the data, and identification of possible approaches to improve the model's performance.

When conducting model diagnostics, despite the availability of numeric summaries endorsed by finite or asymptotic properties, data analysts prefer or require graphical representations of data. The preference for visual diagnostics is attributed to its intuitive nature and the possibility of discovering unexpected abstract and unquantifiable insights. In the context of regression diagnostics, a common practice is to plot residuals against fitted values, which serves as a starting point for evaluating the adequacy of the fit and verifying the underlying assumptions. Other visualization techniques such as histograms, Q-Q plots and box plots can be used to identify potential issues with assumptions made about the data, such as linearity, normality, or homoscedasticity.

Recently, a novel statistical inferential framework known as visual inference \autocite{buja_statistical_2009} has been developed, which relies on the use of graphical representations of data. The visual inference approach makes use of the natural capability of the human visual system to identify patterns and deviations from expected patterns. It provides a more comprehensible way of interpreting data and conducting hypothesis testing compared to conventional statistical testing.

Practically, visual inference is conducted via the lineup protocol. The protocol is inspired by the police lineup technique employed in eyewitness identification of criminal suspects. It comprises \(m\) randomly positioned plots, where on of them represents the data plot, while the remaining \(m - 1\) plots represent the null plots with the same graphical structure, except that the data has been replaced with data consistent with the null hypothesis \(H_0\). Under \(H_0\), the data plot is expected to be indistinguishable from the null plots, and the probability of correctly identifying the data plot by an observer is \(1/m\). If the data plot is correctly identified, it provides evidence against \(H_0\).

This method has gained increasing traction in recent years and has already been integrated into data analysis of various topics, such as diagnostics of hierarchical linear models \autocite{loy2013diagnostic}, geographical research \autocite{widen_graphical_2016} and forensic examinations \autocite{krishnan_hierarchical_2021}. With the advent of sophisticated visualization techniques and tools, visual inference has the potential to provide an innovative alternative to traditional statistical approaches and enabling more effective communication of model findings.

The reliance of human assessment is a fundamental aspect of visual tests, but it may restrict its widespread usage. The lineup protocol is unsuitable for large-scale applications, due to its high labor costs and time requirements. Moreover, it presents significant usability issues for individuals with visual impairments, resulting in reduced accessibility.

The workload of individuals could be alleviated by automating repetitive tasks and providing standardized results in a controlled environment. The evaluation of visual tests on a large scale is not feasible without the aid of machines and technology.

Modern computer vision models offer a promising solution to this challenge. As a subfield of AI, computer vision with its modern deep learning architectures has successfully resolved numerous critical problems in automation. The development of the convolutional neural network (CNN) by \textcite{fukushima_neocognitron_1982} was inspired by the vision processing in living organisms. This architecture was first applied to hand-written number recognition trained with back-propagation by \textcite{lecun_backpropagation_1989}, making it one of the earliest attempts at successfully extracting information from digital images via self-learning algorithms. The modern computer vision model typically utilizes deep neural networks with convolutional layers \autocite{fukushima_neocognitron_1982}, which leverage the hierarchical pattern in data and provide regularized versions of fully-connected layers. This approach downscales and transforms images by summarizing information in a small space. Numerous studies have shown that it can effectively tackle vision tasks, such as image recognition \autocite{rawat_deep_2017}. With the development of graphics processing units and the widespread availability of high-performance personal computers, computer vision research become a new hype in the 21st century. Remarkable achievements, such as computer-aided diagnosis \autocite{lee_image_2015}, pedestrian detection \autocite{brunetti_computer_2018}, and facial recognition \autocite{emami_facial_2012}, have significantly impacted our daily life.

Utilizing computer vision models in reading data plot is not a common choice. Nevertheless, certain fields have adopted this idea by applying computer vision models in reading recurrence plots for time series regression \autocite{ojeda_multivariate_2020}, time series classification \autocite{chu_automatic_2019,hailesilassie_financial_2019,hatami_classification_2018,zhang_encoding_2020}, anomaly detection \autocite{chen_convolutional_2020}, and pairwise causality analysis \autocite{singh_deep_2017}. However, the assessment of lineups with computer vision models is a relatively novel area of study.

\hypertarget{research-questions}{%
\subsection{Research questions}\label{research-questions}}

The main objective of this research is to construct an automatic visual inference system to enable the conduction of regression diagnostics visual tests on a large scale. The study will concentrate on three specific projects, namely

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Exploring the application of visual inference in regression diagnostics and comparing it with conventional hypothesis tests.
\item
  Designing an automated visual inference system to assess lineups of residual plots of classical normal linear regression model.
\item
  Deploying the automatic visual inference system as an online application and publishing the relevant open-source software.
\end{enumerate}

\hypertarget{current-research-outcomes}{%
\subsection{Current research outcomes}\label{current-research-outcomes}}

\begin{itemize}
\tightlist
\item
  cut this p down, we don't need that many details
\end{itemize}

In the initial phase of this research, a pilot investigation was undertaken to explore the viability of implementing visual inference in regression diagnostics. The pilot study involved 64 participants and focused on utilizing a lineup consisting of 20 plots, wherein a residual plot was embedded along with 19 null plots, simulated using the residual rotation technique. The study considered two primary forms of residual departures, namely non-linearity and heteroskedasticity, within a multiple linear regression context. To enrich the visual features, different fitted value distributions, including normal, uniform, lognormal, and discrete uniform, were also incorporated.

The outcomes of this pilot study demonstrated that the power of visual tests in regression diagnostics increases proportionately with the number of lineup evaluations. Nevertheless, it was observed that conventional tests, such as the F-test for non-linearity and the Breusch-Pagan test for heteroskedasticity, exhibited significantly greater power than the visual tests. While the pilot study successfully provided a comparative analysis of the power of visual and conventional tests, the impact of various factors on the power of visual tests could not be fully analyzed due to inadequate data.

We acknowledge the limitations of this pilot study, particularly in the design of the simulated model, which made it challenging to explicate the involved factors. Furthermore, the methodology utilized for effect size calculation, p-value calculation, and power estimation was incipient. Hence, a follow-up study is necessary to address these limitations and obtain a more comprehensive understanding of the potential of visual inference in regression diagnostics.

In the subsequent year, a similar study was conducted, utilizing simpler simulated models to elicit more distinct visual patterns. Specifically, the non-linearity model was formulated as

\begin{align} \label{eq:nonlinearity-model}
\boldsymbol{y} &= 1 + \boldsymbol{x} + \boldsymbol{z} + \boldsymbol{\varepsilon},\\
\boldsymbol{x} &= g(\boldsymbol{x}_{raw}, 1), \\
\boldsymbol{z} &= g(\boldsymbol{z}_{raw}, 1), \\
\boldsymbol{z}_{raw} &= He_j(g(\boldsymbol{x}, 2)),
\end{align}

\noindent where \(\boldsymbol{y}\), \(\boldsymbol{x}\), \(\boldsymbol{\varepsilon}\), \(\boldsymbol{x}_{raw}\), \(\boldsymbol{z}_{raw}\) are vectors of size \(n\), \(He_{j}(.)\) is the \(j\)th-order probabilist's Hermite polynomials, \(\varepsilon \sim N(\boldsymbol{0}, \sigma^2\boldsymbol{I}_n)\), and \(g(\boldsymbol{x}, k)\) is a scaling function to enforce the support of the random vector to be \([-k, k]^n\) defined as

\begin{equation} \label{eq:scaling-function}
g(\boldsymbol{x}, k) = \frac{\boldsymbol{x} - min(\boldsymbol{x})}{max(\boldsymbol{x}) - min(\boldsymbol{x})}(2k - k), \quad \text{for} \quad k > 0. 
\end{equation}

The heteroskedasticity model was formulated as

\begin{align} \label{eq:heter-model}
\boldsymbol{y} &= 1 + \boldsymbol{x} + \boldsymbol{\varepsilon},\\
\boldsymbol{x} &= g(\boldsymbol{x}_{raw}, 1),\\
\boldsymbol{\varepsilon} &\sim N(\boldsymbol{0}, 1 + (2 - |a|)(\boldsymbol{x} - a)^2b \boldsymbol{I}). 
\end{align}

The null regression model used to fit the realizations generated by the above models is formulated as

\begin{equation} \label{eq:null-model}
\boldsymbol{y} = \beta_0 + \beta_1 \boldsymbol{x} + \boldsymbol{u},
\end{equation}

\noindent where \(\boldsymbol{u} \sim N(\boldsymbol{0}, \sigma^2\boldsymbol{I}_n)\).

Since \(z = O(x^j)\), for \(j > 1\), \(z\) is a higher order term leaves out by the null regression, which will violate the linearity model assumption. Similarly, for \(b \neq 0\), the variance-covariance matrix of the error term \(\boldsymbol{\varepsilon}\) is correlated with the predictor \(\boldsymbol{x}\), which will lead to the presence of heteroskedasticity.

\begin{itemize}
\tightlist
\item
  draft below
\end{itemize}

The effect size was derived using the Kullback-Leibler divergence method, formulated as Equation 3. To account for the interdependence of lineups presented to different participants, p-value calculation, as suggested by VanderPlas et al.~(2021), was adopted. Furthermore, power estimation was simplified through a logistic regression model that lacked an intercept but included a fixed offset to ensure that the power equated to 5\% when the effect size was zero. A detailed description of the experimental design, effect size derivation, p-value calculation, and power estimation can be found in the attached paper.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  summarise the work in the first year
\end{enumerate}

\begin{itemize}
\tightlist
\item
  an experiment to compare visual test with conventional test
\item
  a prototype model for lineup evaluation
\item
  points out the limitation of the work
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  summarise the work in the second year
\end{enumerate}

\begin{itemize}
\tightlist
\item
  refine and reconduct the experiment
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  main findings to date
\end{enumerate}

\begin{itemize}
\tightlist
\item
  findings from the first year
\item
  findings from the second year
\end{itemize}

\hypertarget{thesis-structure}{%
\section{Thesis structure}\label{thesis-structure}}

topic

chapter 1: Introduction

chapter 2
the first paper

chapter 3
build a computer vision system to evaluate residual plot

chapter 4?
software publication

chapter 5
discussion and future work

\hypertarget{timetable}{%
\section{Timetable}\label{timetable}}

\begin{itemize}
\item
  April: submit abstract to ASC
\item
  May: submit paper
\item
  June: submit poster/short paper to IEEE vis conf, start working on computer vision model
\item
  July: leave for few weeks
\item
  Aug
\item
  Sep: finalize the computer vision model
\item
  Oct: IEEE vis conf
\item
  Nov: web interface development
\item
  Dec: ASC
\item
  Jan, 2024:
\item
  Feb, 2024:
\item
  Mar, 2024: submit paper
\item
  Aug, 2024: submit thesis
\end{itemize}

\hypertarget{difficulties}{%
\section{Difficulties}\label{difficulties}}

things that are actually quite serious

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  identified difficulties
\item
  suggestions for overcoming these difficulties
\end{enumerate}

\printbibliography[title=References]

\end{document}
