---
title: "Advances in Artificial Intelligence for Data Visualization: Automated Reading of Residual Plots with Computer Vision"
subtitle: ""  
author: 
  - "Weihao (Patrick) Li"
date: '`r format(Sys.Date(), format="%B %d, %Y")`'
output:
  xaringan::moon_reader:
    seal: false
    css: [xaringan-themer.css, mine.css]
    nature:
      countdown: 55000
      beforeInit: "scripts/my_macro.js"
      countIncrementalSlides: false
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=5, fig.height=5, fig.retina=3,
  out.width = "100%",
  cache = FALSE,
  echo = FALSE,
  message = FALSE, 
  warning = FALSE,
  hiline = TRUE
)
```


```{r}
set.seed(10086)
library(RefManageR)
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "apa",
           style = "Bibtex",
           # max.names = 3,
           longnamesfirst = FALSE,
           hyperlink = FALSE,
           dashed = FALSE)
myBib <- ReadBib("./Visual Inference.bib", check = FALSE)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
library(tidyverse)
library(visage)
style_solarized_light(
  background_color = "#FFFFFF",
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Montserrat", "300", "300i", "400i", "600"),
  code_font_google   = google_font("Fira Mono"),
  text_color = "#000000",
  text_font_size = "1.0rem",
  header_h1_font_size = "2.0rem",
  colors = c(myblue = "#006DAE", mywhite = "#FFFFFF")
)
```


count: false

<!-- need a backaground image -->

.pull-left-full[
<h2 class="myblue"> Advances in Artificial Intelligence for Data Visualization: Automated Reading of Residual Plots with Computer Vision </h2>

<h3 class="myblue"> Progress Review Presentation </h3>

<br>
<br>

<h4 class="myblue"> Weihao (Patrick) Li </h3>

<h4 class="myblue"> Supervised by Di Cook, Emi Tanaka and Susan VanderPlas </h3>

<!-- <h3 class="myblue"> `r format(Sys.Date(), format="%B %d, %Y")` </h3> -->
]

.pull-right[

<br>

![](images/505.png)
]

---

.center[
# üìöThesis Structureüìö
]

<br>

#### 1. **Exploring the application of visual inference in regression diagnostics and comparing it with conventional hypothesis tests.**

#### 2. Designing an automated visual inference system to assess lineups of residual plots of classical normal linear regression model.

#### 3. Deploying the automatic visual inference system as an online application and publishing the relevant open-source software.

<br>
<br>

This presentation will be focused on the **first project**. Parts of the second and third project have been done and will be mentioned later.

---

class: center, middle

# A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol

#### Weihao Li, Dianne Cook, Emi Tanaka and Susan VanderPlas (2023)

---

.center[
# üîçRegression Diagnosticsüîç
]

<br>

**Diagnostics** are the key to determining whether there is anything **importantly wrong** with a model.

**Residuals** summarise what is **not captured by the regression model**. Many different residual-based hypothesis tests are available to detect specific model defects.


<br>
<br>

.pull-left-33p[

*Non-linearity*: 

- **F-test**

- **RESET test** (Ramsey 1969)

]

.pull-left-33p[

*Heteroskedasticity*: 


- **White test** (White 1980)

- **BP test** (Breusch and Pagan 1979)
  
]

.pull-left-33p[

*Non-normality*: 

- **SW test** (Shapiro and Wilk 1965)

- **Jarque‚ÄìBera test** (Jarque and Bera 1980)
  
]



  
---

.pull-left-center[

.image-bottom-0[

```{r}
set.seed(10086)

# Base model
mod <- poly_model(include_z = FALSE, sigma = 0.25)

# Base data
dat <- mod$gen(300)

bind_rows(
  dat %>%
    mutate(type = "(A) Good residuals"),
  mod$set_prm("include_z", TRUE)$
    gen(300, computed = select(dat, x, e)) %>%
    mutate(type = "(B) Non-linearity"),
  heter_model(b = 64)$
    gen(300, computed = select(dat, x, e)) %>%
    mutate(type = "(C) Heteroskedasticity"),
  heter_model(b = 0, e = rand_lognormal(sigma = 0.5))$
    gen(300, computed = select(dat, x)) %>%
    mutate(type = "(D) Non-normality")
) %>%
  mod$plot(remove_grid_line = TRUE, theme = theme_light(base_size = 12)) +
  facet_wrap(~type, ncol = 2, scales = "free") +
  theme(axis.text = element_blank()) +
  xlab("Fitted values") +
  ylab("Residuals")
```

]

.center[
.caption[
Fig. 1: _One classically good looking residual plot and three residual plots with model defects._
]
]

]

.pull-right[

# üîçRegression Diagnosticsüîç

<br>

**Diagnostics** are the key to determining whether there is anything **importantly wrong** with a model.

**Residuals** summarise what is **not captured by the regression model**.

**Residual plots** are commonly used to diagnose **non-linearity** and **heteroskedasticity**. **Non-normality** is usually harder to detect from a residual plot. A favourable graphical summary for this task is the **quantile-quantile plot**.

]

---

.pull-left-center[

.image-bottom-0[

```{r}
set.seed(10086)

# Base model
mod <- poly_model(include_z = FALSE, sigma = 0.25)

# Base data
dat <- mod$gen(300)

bind_rows(
  dat %>%
    mutate(type = "(A) Good residuals"),
  mod$set_prm("include_z", TRUE)$
    gen(300, computed = select(dat, x, e)) %>%
    mutate(type = "(B) Non-linearity"),
  heter_model(b = 64)$
    gen(300, computed = select(dat, x, e)) %>%
    mutate(type = "(C) Heteroskedasticity"),
  heter_model(b = 0, e = rand_lognormal(sigma = 0.5))$
    gen(300, computed = select(dat, x)) %>%
    mutate(type = "(D) Non-normality")
) %>%
  mod$plot(remove_grid_line = TRUE, theme = theme_light(base_size = 12)) +
  facet_wrap(~type, ncol = 2, scales = "free") +
  theme(axis.text = element_blank()) +
  xlab("Fitted values") +
  ylab("Residuals")
```

]

.center[
.caption[
Fig. 1: _One classically good looking residual plot and three residual plots with model defects._
]
]

]

.pull-right[

# üîçRegression Diagnosticsüîç

<br>

Many different hypothesis tests are available to detect specific model defects.

Non-linearity: 
  - **F-test**
  - **RESET test** (Ramsey 1969)

Heteroskedasticity: 
  - **White test** (White 1980)
  - **BP test** (Breusch and Pagan 1979)

Non-normality: 
  - **SW test** (Shapiro and Wilk 1965)
  - **Jarque‚ÄìBera test** (Jarque and Bera 1980)

]



---

.pull-left-center[

.image-bottom-0[

```{r}
set.seed(10086)

# Base model
mod <- poly_model(include_z = FALSE, sigma = 0.25)

# Base data
dat <- mod$gen(300)

bind_rows(
  dat %>%
    mutate(type = "(A) Good residuals"),
  mod$set_prm("include_z", TRUE)$
    gen(300, computed = select(dat, x, e)) %>%
    mutate(type = "(B) Non-linearity"),
  heter_model(b = 64)$
    gen(300, computed = select(dat, x, e)) %>%
    mutate(type = "(C) Heteroskedasticity"),
  heter_model(b = 0, e = rand_lognormal(sigma = 0.5))$
    gen(300, computed = select(dat, x)) %>%
    mutate(type = "(D) Non-normality")
) %>%
  mod$plot(remove_grid_line = TRUE, theme = theme_light(base_size = 12)) +
  facet_wrap(~type, ncol = 2, scales = "free") +
  theme(axis.text = element_blank()) +
  xlab("Fitted values") +
  ylab("Residuals")
```

]

.center[
.caption[
Fig. 1: _One classically good looking residual plot and three residual plots with model defects._
]
]

]

.pull-right[

# üîçRegression Diagnosticsüîç


BP and SW tests reject the residual plots exhibiting structure that **they weren‚Äôt designed for** (**type III error**).

Most residual-based tests for particular types of departure are also sensitive to **other types of departures** (Cook and Weisberg 1982).




```{r}
set.seed(10086)

# Base model
mod <- poly_model(include_z = FALSE, sigma = 0.25)

# Base data
dat0 <- mod$gen(300)

# Replicate data in Figure 1
dat1 <- mod$set_prm("include_z", TRUE)$gen(300, computed = select(dat0, x, e))
dat2 <- heter_model(b = 64)$gen(300, computed = select(dat0, x, e))
dat3 <- heter_model(b = 0, e = rand_lognormal(sigma = 0.5))$
               gen(300, computed = select(dat0, x))

dat_list <- list(dat0, dat1, dat2, dat3)

table_dat <- data.frame(plot = c("A", "B", "C", "D"), 
                        model = c("None", 
                                  "Non-linearity", 
                                  "Heteroskedasticity", 
                                  "Non-normality"),
                        r = map_dbl(dat_list, 
                                    ~POLY_MODEL$test(.x, 
                                                     test = "RESET", 
                                                     power = 2:4)$p_value),
                        b = map_dbl(dat_list, 
                                    ~HETER_MODEL$test(.x)$p_value),
                        
                        # SW test has not been included by visage
                        s = map_dbl(dat_list, 
                                    ~shapiro.test(.x$.resid)$p.value)) %>%
  
  # 3 decimal points
  mutate(across(r:s, ~ format(round(.x, digits = 3), nsmall = 3))) %>%
  
  # Italic if reject
  mutate(across(r:s, ~ kableExtra::cell_spec(.x, italic = as.numeric(.x) <= 0.05)))

  table_dat %>%
  knitr::kable(col.names = c("Plot", 
                             "Departures", 
                             "RESET", 
                             "BP", 
                             "SW"),
               align = "llrrr",
               escape = FALSE,
               format = "html",
               booktabs = TRUE)
```

.center[
.caption[
Tab. 1: _Statistical significance testing for departures from good residuals. Shown are the \\(p\\)-values calculated for the RESET, the BP and the SW tests._
]
]

]

---

.pull-right-center[

.image-bottom-0[

```{r}
set.seed(10086)

# Base model
mod <- poly_model(sigma = 8)
dat <- mod$gen(1000)
this_p_value <- mod$test(dat, test = "RESET", power = 2:4)
dat %>%
mod$plot(remove_grid_line = TRUE, theme = theme_light(base_size = 12)) +
  theme(axis.text = element_blank()) +
  xlab("Fitted values") +
  ylab("Residuals")
```

]

.center[
.caption[
Fig. 2: _One classically good looking residual plot but rejected by the RESET test with $p\text{-value} = `r format(round(this_p_value$p_value, digits = 3), nsmall = 3)`$._
]
]

]

.pull-left[

# üîçRegression Diagnosticsüîç

<br>
<br>

With **large sample sizes**, hypothesis tests may reject a residual plot when there is only a **slight departure** (Belsley, Kuh, and Welsch 1980). 

- While such rejections may be **statistically correct**, their **sensitivity** may render the results **impractical**. **Minor defects** in the model are **unlikely** to have a **material impact** and may be best disregarded for practical purposes. 

Residual plot diagnostics:
  - **Identify** potential issues that could lead to **incorrect conclusions or errors in subsequent analyses**.

]


---

.center[
# üìúLiteature of Regression Diagnosticsüìú
]

### Grahpical approaches (plots) are the recommended methods for diagnosing model fits. 

- Draper and Smith (1998) and Belsley, Kuh, and Welsch (1980):
> Residual plots are usually revealing when the assumptions are violated.

- Cook and Weisberg (1982):
> Formal tests and graphical procedures are complementary and both have a place in residual analysis, but graphical methods are easier to use.

- Montgomery and Peck (1982):
> Residual plots are more informative in most practical situations than the corresponding conventional hypothesis tests.

---

.pull-left-center[

.image-bottom-0[

```{r}
set.seed(10131)
mod <- heter_model(b = 0, x = rand_lognormal())
ori_dat <- mod$gen(300)

ori_dat %>%
  VI_MODEL$plot(theme = theme_light(base_size = 12)) +
  xlab("Fitted values") +
  ylab("Residuals")
```

]

.center[
.caption[
Fig. 3: _Residual plot of a simple linear regression (more meaningful)._
]
]

]

.pull-right[

# ü§îFalse Visual Discoveriesü§î

<br>
<br>

Can you find the evidence on heteroskedasticity?

- Vertical spread of the points varies with the fitted values.

However, the residuals are actually obtained from a **correctly specified classical normal linear model**!

**Unsecured** and **unconfirmed** visual discoveries will lead to **over or under-interpretations of the data**.

]

---

.pull-left[

# üî¨Visual Inferenceüî¨

<br>
<br>
<br>

If we embed the residual plot in a matrix of **null plots**, we will find that it is **not uncommon** for residual plots to exhibit a triangle shape.

- The visual pattern is **over-interpreted**! 

<br>
<br>

### The visual discovery is calibrated via comparison.

]

.pull-right-center[

```{r}
set.seed(10131)
mod$gen_lineup(300, k = 20, pos = 8) %>%
  filter(null != FALSE) %>%
  bind_rows(ori_dat %>% mutate(k = 8, null = FALSE)) %>%
  VI_MODEL$plot_lineup(theme = theme_light(base_size = 12),
                       remove_grid_line = TRUE,
                       remove_axis = TRUE)
```
.center[
.caption[
Fig. 4: _A lineup of 20 residual plots of a simple linear regression. (Plot No.8 is Fig.3) Can you find the most different one?_
]
]

]

---

.pull-left[

# üî¨Visual Inferenceüî¨

<br>
<br>

**Visual inference** was introduced by Buja, et al. (2009) as an inferential framework to extend confirmatory statistics to visual discoveries.

A **lineup** consists of $m$ randomly placed plots, where one plot is the **data plot** and the remaining $m ‚àí 1$ plots (**null plots**) contain data consistent with the null hypothesis.

To perform a **visual test**, observer(s) will be asked to select the **most different plot(s)** from the lineup.

]

.pull-right-center[

```{r}
set.seed(10131)
mod$gen_lineup(300, k = 20, pos = 8) %>%
  filter(null != FALSE) %>%
  bind_rows(ori_dat %>% mutate(k = 8, null = FALSE)) %>%
  VI_MODEL$plot_lineup(theme = theme_light(base_size = 12),
                       remove_grid_line = TRUE,
                       remove_axis = TRUE)
```
.center[
.caption[
Fig. 4: _A lineup of 20 residual plots of a simple linear regression. (Plot No.8 is Fig.3) Can you find the most different one?_
]
]

]


---

# Visual inference

What is visual inference?

Underline that it is a valid inferential framework. Highlights the difference from reading a residual plot.

---

# Integrate visual tests into regression diagnostics

(Still use non-linearity as the example)

How to perform a visual test in the context of regression diagnostics. 

Show the $p$-value by assuming the responses.


---

# Limitations of visual inference

Discuss the limitations of visual inference.

---

# Computer vision models

Briefly mention the potential solution to the problem.

---

# A compartative study

Provide the motivation and main objective of conducting such an experiment.

---

# Experiment design

Outlines the model used to simulate the experiment data.

---

# Effect size

Describe the effect size calculation.

---

# $P$-value calculation

Briefly discuss the $p$-value calculation.

---

# Power estimation

Write down the model used to estimate the power.

---

# Study website

Provide screenshots/examples of the study website.

---

# Results

Provide an overview of the collated data.

---

# Power comparison of the tests

---

# Comparison of test decisions based on $p$-values

---

# Effect of amount of non-linearity

---

# Effect of shape of heteroskedasticity

---

# Effect of fitted value distributions



---

# Timetable
