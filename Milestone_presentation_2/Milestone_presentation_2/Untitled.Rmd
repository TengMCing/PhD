---
title: "Advances in Artificial Intelligence for Data Visualization: Automated Reading of Residual Plots with Computer Vision"
subtitle: ""  
author: 
  - "Weihao (Patrick) Li"
date: '`r format(Sys.Date(), format="%B %d, %Y")`'
output:
  xaringan::moon_reader:
    seal: false
    css: [xaringan-themer.css, mine.css]
    nature:
      countdown: 55000
      beforeInit: "scripts/my_macro.js"
      countIncrementalSlides: false
      slideNumberFormat: "<%current%>"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=5, fig.height=5, fig.retina=3,
  out.width = "100%",
  cache = FALSE,
  echo = FALSE,
  message = FALSE, 
  warning = FALSE,
  hiline = TRUE
)
```


```{r}
set.seed(10086)
library(RefManageR)
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "apa",
           style = "Bibtex",
           # max.names = 3,
           longnamesfirst = FALSE,
           hyperlink = FALSE,
           dashed = FALSE)
myBib <- ReadBib("./Visual Inference.bib", check = FALSE)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
library(tidyverse)
library(visage)
style_solarized_light(
  background_color = "#FFFFFF",
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Montserrat", "300", "300i", "400i", "600"),
  code_font_google   = google_font("Fira Mono"),
  text_color = "#000000",
  text_font_size = "1.0rem",
  header_h1_font_size = "2.0rem",
  colors = c(myblue = "#006DAE", mywhite = "#FFFFFF")
)
```


count: false

<!-- need a backaground image -->

.pull-left-full[
<h2 class="myblue"> Advances in Artificial Intelligence for Data Visualization: Automated Reading of Residual Plots with Computer Vision </h2>

<h3 class="myblue"> Progress Review Presentation </h3>

<br>
<br>

<h4 class="myblue"> Weihao (Patrick) Li </h3>

<h4 class="myblue"> Supervised by Di Cook, Emi Tanaka and Susan VanderPlas </h3>

<!-- <h3 class="myblue"> `r format(Sys.Date(), format="%B %d, %Y")` </h3> -->
]

.pull-right[

<br>

![](images/505.png)
]

---

.center[
# üìöThesis Structureüìö
]

<br>

#### 1. **Exploring the application of visual inference in regression diagnostics and comparing it with conventional hypothesis tests.**

#### 2. Designing an automated visual inference system to assess lineups of residual plots of classical normal linear regression model.

#### 3. Deploying the automatic visual inference system as an online application and publishing the relevant open-source software.

<br>
<br>

This presentation will be focused on the **first project**. Parts of the second and third project have been done and will be mentioned later.

---

class: center, middle

# A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol

#### Weihao Li, Dianne Cook, Emi Tanaka and Susan VanderPlas (2023)


---

.center[

# üîçRegression Diagnosticsüîç

]

--


**Diagnostics** are the key to determining whether there is anything **importantly wrong** with a model.

--

**Residuals** summarise what is **not captured by the regression model**.

--

**Residual plots** are commonly used to diagnose **non-linearity** and **heteroskedasticity**. **Non-normality** is usually harder to detect from a residual plot. A favourable graphical summary for this task is the **quantile-quantile plot**.

--

.image-bottom-0[

```{r fig.height = 2.5, fig.width = 10}
set.seed(10086)

# Base model
mod <- poly_model(include_z = FALSE, sigma = 0.25)

# Base data
dat <- mod$gen(300)

bind_rows(
  dat %>%
    mutate(type = "(A) Good residuals"),
  mod$set_prm("include_z", TRUE)$
    gen(300, computed = select(dat, x, e)) %>%
    mutate(type = "(B) Non-linearity"),
  heter_model(b = 64)$
    gen(300, computed = select(dat, x, e)) %>%
    mutate(type = "(C) Heteroskedasticity"),
  heter_model(b = 0, e = rand_lognormal(sigma = 0.5))$
    gen(300, computed = select(dat, x)) %>%
    mutate(type = "(D) Non-normality")
) %>%
  mod$plot(remove_grid_line = TRUE, theme = theme_light(base_size = 12)) +
  facet_wrap(~type, ncol = 4, scales = "free") +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank()) +
  xlab("Fitted values") +
  ylab("Residuals")
```

]

.center[
.caption[
Fig. 1: _Example residual plots: (A) classically good looking residuals, (B) non-linear pattern indicates that the model has not captured a non-linear association, (C) heteroskedasticity indicating that variance around the fitted model is not uniform, and (D) non-normality where the residual distribution is not symmetric around 0._
]
]


---

.center[
# üîçRegression Diagnosticsüîç
]

--

Many different **residual-based hypothesis tests** are available to detect specific model defects.

--

.pull-left-33p[

Non-linearity: 

- **F-test**

- **RESET test** (Ramsey 1969)

]

--

.pull-left-33p[

Heteroskedasticity: 


- **White test** (White 1980)

- **BP test** (Breusch and Pagan 1979)
  
]

--

.pull-left-33p[

Non-normality: 

- **SW test** (Shapiro and Wilk 1965)

- **Jarque‚ÄìBera test** (Jarque and Bera 1980)
  
]

--

.float-left[
But there are **drawbacks** of using them.

- Most residual-based tests for particular types of departure are also sensitive to **other types of departures**, resulting in a phenomenon known as the "**Type III error**" (Cook and Weisberg 1982).

- Other problems such as **outliers** can trigger the rejection (Cook and Weisberg 1999).

]


---

.pull-left-center-80[

.image-bottom-0[

```{r}
set.seed(10086)
# Base model
mod <- poly_model(include_z = FALSE, sigma = 0.25)
# Base data
dat <- mod$gen(300)
bind_rows(
  dat %>%
    mutate(type = "(A) Good residuals"),
  mod$set_prm("include_z", TRUE)$
    gen(300, computed = select(dat, x, e)) %>%
    mutate(type = "(B) Non-linearity"),
  heter_model(b = 64)$
    gen(300, computed = select(dat, x, e)) %>%
    mutate(type = "(C) Heteroskedasticity"),
  heter_model(b = 0, e = rand_lognormal(sigma = 0.5))$
    gen(300, computed = select(dat, x)) %>%
    mutate(type = "(D) Non-normality")
) %>%
  mod$plot(remove_grid_line = TRUE, theme = theme_light(base_size = 12)) +
  facet_wrap(~type, ncol = 2, scales = "free") +
  theme(axis.text = element_blank()) +
  xlab("Fitted values") +
  ylab("Residuals")
```

]

.center[
.caption[
Fig. 1: _Example residual plots: (A) classically good looking residuals, (B) non-linear pattern indicates that the model has not captured a non-linear association, (C) heteroskedasticity indicating that variance around the fitted model is not uniform, and (D) non-normality where the residual distribution is not symmetric around 0._
]
]

]

.pull-right-120[

# üîçRegression Diagnosticsüîç

<br>

BP and SW tests reject the residual plots exhibiting structure that **they weren‚Äôt designed for** (**type III error**).

<br>


```{r}
set.seed(10086)
# Base model
mod <- poly_model(include_z = FALSE, sigma = 0.25)
# Base data
dat0 <- mod$gen(300)
# Replicate data in Figure 1
dat1 <- mod$set_prm("include_z", TRUE)$gen(300, computed = select(dat0, x, e))
dat2 <- heter_model(b = 64)$gen(300, computed = select(dat0, x, e))
dat3 <- heter_model(b = 0, e = rand_lognormal(sigma = 0.5))$
               gen(300, computed = select(dat0, x))
dat_list <- list(dat0, dat1, dat2, dat3)
table_dat <- data.frame(plot = c("A", "B", "C", "D"), 
                        model = c("None", 
                                  "Non-linearity", 
                                  "Heteroskedasticity", 
                                  "Non-normality"),
                        r = map_dbl(dat_list, 
                                    ~POLY_MODEL$test(.x, 
                                                     test = "RESET", 
                                                     power = 2:4)$p_value),
                        b = map_dbl(dat_list, 
                                    ~HETER_MODEL$test(.x)$p_value),
                        
                        # SW test has not been included by visage
                        s = map_dbl(dat_list, 
                                    ~shapiro.test(.x$.resid)$p.value)) %>%
  
  # 3 decimal points
  mutate(across(r:s, ~ format(round(.x, digits = 3), nsmall = 3))) %>%
  
  # Italic if reject
  mutate(across(r:s, ~ kableExtra::cell_spec(.x, italic = as.numeric(.x) <= 0.05, color = ifelse(as.numeric(.x) <= 0.05, "red", "black"))))
  table_dat %>%
  knitr::kable(col.names = c("Plot", 
                             "Departures", 
                             "RESET", 
                             "BP", 
                             "SW"),
               align = "llrrr",
               escape = FALSE,
               format = "html",
               booktabs = TRUE)
```

.center[
.caption[
Tab. 1: _Statistical significance testing for departures from good residuals. Shown are the \\(p\\)-values calculated for the RESET, the BP and the SW tests._
]
]

]

---

.pull-right-center[

.image-bottom-0[

```{r}
set.seed(10086)

# Base model
mod <- poly_model(sigma = 8)
dat <- mod$gen(1000)
this_p_value <- mod$test(dat, test = "RESET", power = 2:4)
dat %>%
mod$plot(remove_grid_line = TRUE, theme = theme_light(base_size = 12)) +
  theme(axis.text = element_blank()) +
  xlab("Fitted values") +
  ylab("Residuals")
```

]

.center[
.caption[
Fig. 2: _One classically good looking residual plot but rejected by the RESET test with $p\text{-value} = `r format(round(this_p_value$p_value, digits = 3), nsmall = 3)`$. The model is misspecified but the departure from the model assumption is small._
]
]

]

.pull-left[

# üîçRegression Diagnosticsüîç

<br>
<br>

With **large sample sizes**, hypothesis tests may reject a residual plot when there is only a **slight departure** (Belsley, Kuh, and Welsch 1980). 

<!-- - While such rejections may be **statistically correct**, their **sensitivity** may render the results **impractical**. **Minor defects** in the model are **unlikely** to have a **material impact** and may be best disregarded for practical purposes.  -->

Residual plot diagnostics:
  - **Identify** potential issues that could lead to **incorrect conclusions or errors in subsequent analyses**.

]


---

.center[
# üìúLiteature of Regression Diagnosticsüìú
]

### Grahpical approaches (plots) are the recommended methods for diagnosing model fits. 

- Draper and Smith (1998) and Belsley, Kuh, and Welsch (1980):
> Residual plots are usually revealing when the assumptions are violated.

- Cook and Weisberg (1982):
> Formal tests and graphical procedures are complementary and both have a place in residual analysis, but graphical methods are easier to use.

- Montgomery and Peck (1982):
> Residual plots are more informative in most practical situations than the corresponding conventional hypothesis tests.

---

.pull-left-center[

.image-bottom-0[

```{r}
set.seed(10131)
mod <- heter_model(b = 0, x = rand_lognormal())
ori_dat <- mod$gen(300)

ori_dat %>%
  VI_MODEL$plot(theme = theme_light(base_size = 12)) +
  xlab("Fitted values") +
  ylab("Residuals")
```

]

.center[
.caption[
Fig. 3: _Residual plot of a correctly specified model exhibiting a heteroskedasticity pattern (triangle shape)._
]
]

]

.pull-right[

# ü§îFalse Visual Discoveriesü§î

<br>
<br>

Can you find the evidence on heteroskedasticity?

- Vertical spread of the points varies with the fitted values.

However, the residuals are actually obtained from a **correctly specified classical normal linear model**!

**Unconfirmed** visual discoveries could result in **over or under-interpretations of the data**.

]

---

.pull-left[

# üî¨Visual Inferenceüî¨

<br>
<br>

If we embed the residual plot in **a matrix of plots containing residuals simulated from the fitted model**, we will find that it is **not uncommon** for residual plots to exhibit a triangle shape.

- Can you find the **most different plot**? 

- Is it the residual plot presented at the previous page?

- If it is not, then the visual pattern is **over-interpreted**! 

### The visual discovery is calibrated via comparison.

]

.pull-right-center[

```{r}
set.seed(10131)
mod$gen_lineup(300, k = 20, pos = 8) %>%
  filter(null != FALSE) %>%
  bind_rows(ori_dat %>% mutate(k = 8, null = FALSE)) %>%
  VI_MODEL$plot_lineup(theme = theme_light(base_size = 12),
                       remove_grid_line = TRUE,
                       remove_axis = TRUE)
```
.center[
.caption[
Fig. 4: _A lineup of 20 residual plots of a simple linear regression. (Plot No.8 is Fig.3) Can you find the most different one?_
]
]

]

---

.pull-left[

# üî¨Visual Inferenceüî¨

<br>
<br>

This procedure is called **visual inference**. It was introduced by Buja, et al. (2009) as an inferential framework to extend confirmatory statistics to visual discoveries.

A **lineup** consists of $m$ randomly placed plots, where one plot is the **data plot** and the remaining $m ‚àí 1$ plots (**null plots**) contain data consistent with the null hypothesis.

To perform a **visual test**, observer(s) will be asked to select the **most different plot(s)** from the lineup.

]

.pull-right-center[

```{r}
set.seed(10131)
mod$gen_lineup(300, k = 20, pos = 8) %>%
  filter(null != FALSE) %>%
  bind_rows(ori_dat %>% mutate(k = 8, null = FALSE)) %>%
  VI_MODEL$plot_lineup(theme = theme_light(base_size = 12),
                       remove_grid_line = TRUE,
                       remove_axis = TRUE)
```
.center[
.caption[
Fig. 4: _A lineup of 20 residual plots of a simple linear regression. (Plot No.8 is Fig.3) Can you find the most different one?_
]
]

]

---

.center[
# üé≤Simulate Residuals from the Assumed Modelüé≤
]

<br>

--

Data used in the $m ‚àí 1$ null plots needs to be simulated.

--

For classical normal linear regression model, the **residual rotation** technique (Buja, et al. 2009) can be applied:

<br>

--


<p> 1. Generate independent random draws \(w_i, i=1,...,n\) from \(N(0, 1)\). </p>

--

<br>

<p> 2. Regress \(w\) on \(x\) and obtain the residuals \(r_i, i=1,...,n\). </p>

--

<br>

<p> 3. Rescale \(r_i\) by \(\sqrt{RSS_{old}/RSS_{new}}\) to obtain the simulated residuals, where \(RSS_{old}\) is the residual sum of square of the original regression, and \(RSS_{new}\) is the residual sum of square of the regression fitted on step 2. </p>


---

.center[
# üìàStatistical Significanceüìà
]

<br>
<br>

--

Under the null hypothesis, it is expected that the data plot would have **no distinguishable difference** with the null plots. 

<br>

--

Suppose observers are allowed to **select only one plot**. The probability of the observer correctly picks the actual data plot is $1/m$.

<br>

--

However, if we involve $K$ **independent observers** in a visual test, and show them the **same lineup**, there will be possible **dependencies** in the visual test due to **repeated evaluations** of the same lineup.

---

.pull-left[

```{r}
alpha_sample <- rgamma(10, 1, 1)
data.frame(x = 0, y = 0, k = 1:20, alpha = alpha_sample/sum(alpha_sample)) %>%
ggplot() +
  geom_text(aes(x, y, label = paste0("theta[", k, "]~'='~", round(alpha, 2))), parse = TRUE, size = 5) +
  facet_wrap(~k) +
  theme_light(base_size = 12) +
  theme(panel.grid = element_blank(),
        axis.line = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())
```

.center[
.caption[
Fig. 5: _Example of the probability of each plot being selected \\(\theta_i\\) under the null hypothesis with parameter \\(\alpha = 1\\)._
]
]

]

.pull-right[

# üìàStatistical Significanceüìà

<br>

VanderPlas et al. (2021) addresses this by modelling the probability of a plot $i$ being selected from a lineup as $\theta_i$: 

$$\theta_i \sim Dirichlet(\alpha) \text{ for } i=1,...,m \text{ and } \alpha > 0.$$ 

- This assumes the **attractiveness distribution** of each plot.

For **small** $\alpha$:
- Only **a few plots** are attractive and tend to be selected. 

For **large** $\alpha$:
- The distribution of the probability of each plot being selected is more **even**.

]

---


.pull-left[

```{r}
data.frame(k = 1:20, 
           ci = c(1, 0, 0.25, 0, 0, 0.2, 0.45, 0, 5.95, 0, 0, 0, 0, 1.7, 0, 0.2, 0, 1, 0, 0.25)) %>%
ggplot() +
  geom_text(aes(0, 0, label = paste0("c[", k, "]~'='~", ci)), parse = TRUE, size = 5) +
  facet_wrap(~k) +
  theme_light(base_size = 12) +
  theme(panel.grid = element_blank(),
        axis.line = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())
```

.center[
.caption[
Fig. 5: _Example of the number of times a plot being selected \\(c_i\\). The sum of all \\(c_i\\) is 11 because the lineup is evaluated by 11 subjects._
]
]

]


.pull-right[

# üìàStatistical Significanceüìà

<br>
<br>

The **number of times** plot $i$ being selected in $K$ evaluations is denoted as $c_i$. 

- In case subject $j$ makes **multiple selections**, $1/s_j$ will be added to $c_i$ instead of one, where $s_j$ is the **number of plots subject $j$ selected** for $j=1,...K$. 
- This ensures $\sum_{i}c_i=K$.

]

---


.center[
# üìàStatistical Significanceüìà
]

<br>

Since we are only interested in the **selections of the data plot $i$**, the **marginal model** can be simplified to a **beta-binomial model**. VanderPlas et al. (2021) derives the visual $p$-value as

$$P(C \geq c_i) = \sum_{x=c_i}^{K}{K \choose x}\frac{B(x + \alpha, K - x + (m - 1)\alpha)}{B(\alpha, (m-1)\alpha)},\text{ for } c_i \in \mathbb{Z}_0^+$$

where $B(.)$ is the beta function defined as

$$B(a, b) = \int_{0}^{1}t^{\alpha - 1}(1-t)^{b-1}dt,\text{ where } a,b>0.$$
We extend the equation to **non-negative real number $c_i$** by applying a linear approximation

$$
P(C \geq c_i) = P(C \geq \lceil c_i \rceil) + (\lceil c_i \rceil - c_i) P(C = \lfloor c_i \rfloor), \text{ for } c_i \in \mathbb{R}_0^+.
$$

---

# Integrate visual tests into regression diagnostics

(Still use non-linearity as the example)

How to perform a visual test in the context of regression diagnostics. 

Show the $p$-value by assuming the responses.


---

# Limitations of visual inference

Discuss the limitations of visual inference.

---

# Computer vision models

Briefly mention the potential solution to the problem.

---

# A compartative study

Provide the motivation and main objective of conducting such an experiment.

---

# Experiment design

Outlines the model used to simulate the experiment data.

---

# Effect size

Describe the effect size calculation.

---

# $P$-value calculation

Briefly discuss the $p$-value calculation.

---

# Power estimation

Write down the model used to estimate the power.

---

# Study website

Provide screenshots/examples of the study website.

---

# Results

Provide an overview of the collated data.

---

# Power comparison of the tests

---

# Comparison of test decisions based on $p$-values

---

# Effect of amount of non-linearity

---

# Effect of shape of heteroskedasticity

---

# Effect of fitted value distributions



---

# Timetable
