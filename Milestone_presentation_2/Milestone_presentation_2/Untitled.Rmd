---
title: "Advances in Artificial Intelligence for Data Visualization: Automated Reading of Residual Plots with Computer Vision"
subtitle: ""  
author: 
  - "Weihao (Patrick) Li"
date: '`r format(Sys.Date(), format="%B %d, %Y")`'
output:
  xaringan::moon_reader:
    seal: false
    css: [xaringan-themer.css, mine.css]
    nature:
      countdown: 55000
      beforeInit: "scripts/my_macro.js"
      countIncrementalSlides: false
      slideNumberFormat: "<%current%>"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=5, fig.height=5, fig.retina=3,
  out.width = "100%",
  cache = FALSE,
  echo = FALSE,
  message = FALSE, 
  warning = FALSE,
  hiline = TRUE
)
```


```{r}
set.seed(10086)
library(RefManageR)
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "apa",
           style = "Bibtex",
           # max.names = 3,
           longnamesfirst = FALSE,
           hyperlink = FALSE,
           dashed = FALSE)
myBib <- ReadBib("./Visual Inference.bib", check = FALSE)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
library(tidyverse)
library(visage)
style_solarized_light(
  background_color = "#FFFFFF",
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Montserrat", "300", "300i", "400i", "600"),
  code_font_google   = google_font("Fira Mono"),
  text_color = "#000000",
  text_font_size = "1.0rem",
  header_h1_font_size = "2.0rem",
  colors = c(myblue = "#006DAE", mywhite = "#FFFFFF")
)
```


count: false

<!-- need a backaground image -->

.pull-left-full[
<h2 class="myblue"> Advances in Artificial Intelligence for Data Visualization: Automated Reading of Residual Plots with Computer Vision </h2>

<h3 class="myblue"> Progress Review Presentation </h3>

<br>
<br>

<h4 class="myblue"> Weihao (Patrick) Li </h3>

<h4 class="myblue"> Supervised by Di Cook, Emi Tanaka and Susan VanderPlas </h3>

<!-- <h3 class="myblue"> `r format(Sys.Date(), format="%B %d, %Y")` </h3> -->
]

.pull-right[

<br>

![](images/505.png)
]

---

.center[
# üìöThesis Structureüìö
]

<br>

#### 1. **Exploring the application of visual inference in regression diagnostics and comparing it with conventional hypothesis tests.**

#### 2. Designing an automated visual inference system to assess lineups of residual plots of classical normal linear regression model.

#### 3. Deploying the automatic visual inference system as an online application and publishing the relevant open-source software.

<br>
<br>

This presentation will be focused on the **first project**. Parts of the second and third project have been done and will be mentioned later.

---

class: center, middle

# A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol

#### Weihao Li, Dianne Cook, Emi Tanaka and Susan VanderPlas (2023)


---

.center[

# üîçRegression Diagnosticsüîç

]

--


**Diagnostics** are the key to determining whether there is anything **importantly wrong** with a model.

--

**Residuals** summarise what is **not captured by the regression model**.

--

**Residual plots** are commonly used to diagnose **non-linearity** and **heteroskedasticity**. **Non-normality** is usually harder to detect from a residual plot. A favourable graphical summary for this task is the **quantile-quantile plot**.

--

.image-top-bottom-0[

```{r fig.height = 2.5, fig.width = 10}
set.seed(10086)

# Base model
mod <- poly_model(include_z = FALSE, sigma = 0.25)

# Base data
dat <- mod$gen(300)

bind_rows(
  dat %>%
    mutate(type = "(A) Good residuals"),
  mod$set_prm("include_z", TRUE)$
    gen(300, computed = select(dat, x, e)) %>%
    mutate(type = "(B) Non-linearity"),
  heter_model(b = 64)$
    gen(300, computed = select(dat, x, e)) %>%
    mutate(type = "(C) Heteroskedasticity"),
  heter_model(b = 0, e = rand_lognormal(sigma = 0.5))$
    gen(300, computed = select(dat, x)) %>%
    mutate(type = "(D) Non-normality")
) %>%
  mod$plot(remove_grid_line = TRUE, theme = theme_light(base_size = 12)) +
  facet_wrap(~type, ncol = 4, scales = "free") +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank()) +
  xlab("Fitted values") +
  ylab("Residuals")
```

]

.center[
.caption[
Fig. 1: _Example residual plots: (A) classically good looking residuals, (B) non-linear pattern indicates that the model has not captured a non-linear association, (C) heteroskedasticity indicating that variance around the fitted model is not uniform, and (D) non-normality where the residual distribution is not symmetric around 0._
]
]


---

.center[
# üîçRegression Diagnosticsüîç
]

--

Many different **residual-based hypothesis tests** are available to detect specific model defects.

--

.pull-left-33p[

Non-linearity: 

- **F-test**

- **RESET test** (Ramsey 1969)

]

--

.pull-left-33p[

Heteroskedasticity: 


- **White test** (White 1980)

- **BP test** (Breusch and Pagan 1979)
  
]

--

.pull-left-33p[

Non-normality: 

- **SW test** (Shapiro and Wilk 1965)

- **Jarque‚ÄìBera test** (Jarque and Bera 1980)
  
]

--

.float-left[
But there are **drawbacks** of using them.

- Most residual-based tests for particular types of departure are also sensitive to **other types of departures**, resulting in a phenomenon known as the "**Type III error**" (Cook and Weisberg 1982).

- Other problems such as **outliers** can trigger the rejection (Cook and Weisberg 1999).

]


---

.pull-left-center-80[

.image-top-bottom-0[

```{r}
set.seed(10086)
# Base model
mod <- poly_model(include_z = FALSE, sigma = 0.25)
# Base data
dat <- mod$gen(300)
bind_rows(
  dat %>%
    mutate(type = "(A) Good residuals"),
  mod$set_prm("include_z", TRUE)$
    gen(300, computed = select(dat, x, e)) %>%
    mutate(type = "(B) Non-linearity"),
  heter_model(b = 64)$
    gen(300, computed = select(dat, x, e)) %>%
    mutate(type = "(C) Heteroskedasticity"),
  heter_model(b = 0, e = rand_lognormal(sigma = 0.5))$
    gen(300, computed = select(dat, x)) %>%
    mutate(type = "(D) Non-normality")
) %>%
  mod$plot(remove_grid_line = TRUE, theme = theme_light(base_size = 12)) +
  facet_wrap(~type, ncol = 2, scales = "free") +
  theme(axis.text = element_blank()) +
  xlab("Fitted values") +
  ylab("Residuals")
```

]

.center[
.caption[
Fig. 1: _Example residual plots: (A) classically good looking residuals, (B) non-linear pattern indicates that the model has not captured a non-linear association, (C) heteroskedasticity indicating that variance around the fitted model is not uniform, and (D) non-normality where the residual distribution is not symmetric around 0._
]
]

]

.pull-right-120[

# üîçRegression Diagnosticsüîç

<br>

BP and SW tests reject the residual plots exhibiting structure that **they weren‚Äôt designed for** (**type III error**).

<br>


```{r}
set.seed(10086)
# Base model
mod <- poly_model(include_z = FALSE, sigma = 0.25)
# Base data
dat0 <- mod$gen(300)
# Replicate data in Figure 1
dat1 <- mod$set_prm("include_z", TRUE)$gen(300, computed = select(dat0, x, e))
dat2 <- heter_model(b = 64)$gen(300, computed = select(dat0, x, e))
dat3 <- heter_model(b = 0, e = rand_lognormal(sigma = 0.5))$
               gen(300, computed = select(dat0, x))
dat_list <- list(dat0, dat1, dat2, dat3)
table_dat <- data.frame(plot = c("A", "B", "C", "D"), 
                        model = c("None", 
                                  "Non-linearity", 
                                  "Heteroskedasticity", 
                                  "Non-normality"),
                        r = map_dbl(dat_list, 
                                    ~POLY_MODEL$test(.x, 
                                                     test = "RESET", 
                                                     power = 2:4)$p_value),
                        b = map_dbl(dat_list, 
                                    ~HETER_MODEL$test(.x)$p_value),
                        
                        # SW test has not been included by visage
                        s = map_dbl(dat_list, 
                                    ~shapiro.test(.x$.resid)$p.value)) %>%
  
  # 3 decimal points
  mutate(across(r:s, ~ format(round(.x, digits = 3), nsmall = 3))) %>%
  
  # Italic if reject
  mutate(across(r:s, ~ kableExtra::cell_spec(.x, italic = as.numeric(.x) <= 0.05, color = ifelse(as.numeric(.x) <= 0.05, "red", "black"))))
  table_dat %>%
  knitr::kable(col.names = c("Plot", 
                             "Departures", 
                             "RESET", 
                             "BP", 
                             "SW"),
               align = "llrrr",
               escape = FALSE,
               format = "html",
               booktabs = TRUE)
```

.center[
.caption[
Tab. 1: _Statistical significance testing for departures from good residuals. Shown are the \\(p\\)-values calculated for the RESET, the BP and the SW tests._
]
]

]

---

.pull-right-center[

.image-top-bottom-0[

```{r}
set.seed(10086)

# Base model
mod <- poly_model(sigma = 8)
dat <- mod$gen(1000)
this_p_value <- mod$test(dat, test = "RESET", power = 2:4)
dat %>%
mod$plot(remove_grid_line = TRUE, theme = theme_light(base_size = 12)) +
  theme(axis.text = element_blank()) +
  xlab("Fitted values") +
  ylab("Residuals")
```

]

.center[
.caption[
Fig. 2: _One classically good looking residual plot but rejected by the RESET test with $p\text{-value} = `r format(round(this_p_value$p_value, digits = 3), nsmall = 3)`$. The model is misspecified but the departure from the model assumption is small._
]
]

]

.pull-left[

# üîçRegression Diagnosticsüîç

<br>
<br>

With **large sample sizes**, hypothesis tests may reject a residual plot when there is only a **slight departure** (Belsley, Kuh, and Welsch 1980). 

<!-- - While such rejections may be **statistically correct**, their **sensitivity** may render the results **impractical**. **Minor defects** in the model are **unlikely** to have a **material impact** and may be best disregarded for practical purposes.  -->

Residual plot diagnostics:
  - **Identify** potential issues that could lead to **incorrect conclusions or errors in subsequent analyses**.

]


---

.center[
# üìúLiteature of Regression Diagnosticsüìú
]

### Grahpical approaches (plots) are the recommended methods for diagnosing model fits. 

- Draper and Smith (1998) and Belsley, Kuh, and Welsch (1980):
> Residual plots are usually revealing when the assumptions are violated.

- Cook and Weisberg (1982):
> Formal tests and graphical procedures are complementary and both have a place in residual analysis, but graphical methods are easier to use.

- Montgomery and Peck (1982):
> Residual plots are more informative in most practical situations than the corresponding conventional hypothesis tests.

---

.pull-left-center[

.image-top-bottom-0[

```{r}
set.seed(10131)
mod <- heter_model(b = 0, x = rand_lognormal())
ori_dat <- mod$gen(300)

ori_dat %>%
  VI_MODEL$plot(theme = theme_light(base_size = 12)) +
  xlab("Fitted values") +
  ylab("Residuals")
```

]

.center[
.caption[
Fig. 3: _Residual plot of a correctly specified model exhibiting a heteroskedasticity pattern (triangle shape)._
]
]

]

.pull-right[

# ü§îFalse Visual Discoveriesü§î

<br>
<br>

Can you find the evidence on heteroskedasticity?

- Vertical spread of the points varies with the fitted values.

However, the residuals are actually obtained from a **correctly specified classical normal linear model**!

**Unconfirmed** visual discoveries could result in **over or under-interpretations of the data**.

]

---

.pull-left[

# üî¨Visual Inferenceüî¨

<br>
<br>

If we embed the residual plot in **a matrix of plots containing residuals simulated from the fitted model**, we will find that it is **not uncommon** for residual plots to exhibit a triangle shape.

- Can you find the **most different plot**? 

- Is it the residual plot presented at the previous page?

- If it is not, then the visual pattern is **over-interpreted**! 

### The visual discovery is calibrated via comparison.

]

.pull-right-center[

```{r}
set.seed(10131)
mod$gen_lineup(300, k = 20, pos = 8) %>%
  filter(null != FALSE) %>%
  bind_rows(ori_dat %>% mutate(k = 8, null = FALSE)) %>%
  VI_MODEL$plot_lineup(theme = theme_light(base_size = 12),
                       remove_grid_line = TRUE,
                       remove_axis = TRUE)
```
.center[
.caption[
Fig. 4: _A lineup of 20 residual plots of a simple linear regression. (Plot No.8 is Fig.3) Can you find the most different one?_
]
]

]

---

.pull-left[

# üî¨Visual Inferenceüî¨

<br>
<br>

This procedure is called **visual inference**. It was introduced by Buja, et al. (2009) as an inferential framework to extend confirmatory statistics to visual discoveries.

A **lineup** consists of $m$ randomly placed plots, where one plot is the **data plot** and the remaining $m ‚àí 1$ plots (**null plots**) contain data consistent with the null hypothesis.

To perform a **visual test**, observer(s) will be asked to select the **most different plot(s)** from the lineup.

]

.pull-right-center[

```{r}
set.seed(10131)
mod$gen_lineup(300, k = 20, pos = 8) %>%
  filter(null != FALSE) %>%
  bind_rows(ori_dat %>% mutate(k = 8, null = FALSE)) %>%
  VI_MODEL$plot_lineup(theme = theme_light(base_size = 12),
                       remove_grid_line = TRUE,
                       remove_axis = TRUE)
```
.center[
.caption[
Fig. 4: _A lineup of 20 residual plots of a simple linear regression. (Plot No.8 is Fig.3) Can you find the most different one?_
]
]

]

---

.center[
# üé≤Simulate Residuals from the Assumed Modelüé≤
]

<br>

--

Data used in the $m ‚àí 1$ null plots needs to be simulated.

--

For classical normal linear regression model, the **residual rotation** technique (Buja, et al. 2009) can be applied:

<br>

--


<p> 1. Generate independent random draws \(w_i, i=1,...,n\) from \(N(0, 1)\). </p>

--

<br>

<p> 2. Regress \(w\) on \(x\) and obtain the residuals \(r_i, i=1,...,n\). </p>

--

<br>

<p> 3. Rescale \(r_i\) by \(\sqrt{RSS_{old}/RSS_{new}}\) to obtain the simulated residuals, where \(RSS_{old}\) is the residual sum of square of the original regression, and \(RSS_{new}\) is the residual sum of square of the regression fitted on step 2. </p>


---

.center[
# üìàStatistical Significanceüìà
]

<br>
<br>

--

Under the null hypothesis, it is expected that the data plot would have **no distinguishable difference** with the null plots. 

<br>

--

Suppose observers are allowed to **select only one plot**. The probability of the observer correctly picks the actual data plot is $1/m$.

<br>

--

However, if we involve $K$ **independent observers** in a visual test, and show them the **same lineup**, there will be possible **dependencies** in the visual test due to **repeated evaluations** of the same lineup.

---

.pull-left[

```{r}
alpha_sample <- rgamma(10, 1, 1)
data.frame(x = 0, y = 0, k = 1:20, alpha = alpha_sample/sum(alpha_sample)) %>%
ggplot() +
  geom_text(aes(x, y, label = paste0("theta[", k, "]~'='~", round(alpha, 2))), parse = TRUE, size = 5) +
  facet_wrap(~k) +
  theme_light(base_size = 12) +
  theme(panel.grid = element_blank(),
        axis.line = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())
```

.center[
.caption[
Fig. 5: _Example of the probability of each plot being selected \\(\theta_i\\) under the null hypothesis with parameter \\(\alpha = 1\\)._
]
]

]

.pull-right[

# üìàStatistical Significanceüìà

<br>

VanderPlas et al. (2021) addresses this by modelling the probability of a plot $i$ being selected from a lineup as $\theta_i$: 

$$\theta_i \sim Dirichlet(\alpha) \text{ for } i=1,...,m \text{ and } \alpha > 0.$$ 

- This assumes the **attractiveness distribution** of each plot.

For **small** $\alpha$:
- Only **a few plots** are attractive and tend to be selected. 

For **large** $\alpha$:
- The distribution of the probability of each plot being selected is more **even**.

]

---


.pull-left[

```{r}
data.frame(k = 1:20, 
           ci = c(1, 0, 0.25, 0, 0, 0.2, 0.45, 0, 5.95, 0, 0, 0, 0, 1.7, 0, 0.2, 0, 1, 0, 0.25)) %>%
ggplot() +
  geom_text(aes(0, 0, label = paste0("c[", k, "]~'='~", ci)), parse = TRUE, size = 5) +
  facet_wrap(~k) +
  theme_light(base_size = 12) +
  theme(panel.grid = element_blank(),
        axis.line = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())
```

.center[
.caption[
Fig. 5: _Example of the number of times a plot being selected \\(c_i\\). The sum of all \\(c_i\\) is 11 because the lineup is evaluated by 11 subjects._
]
]

]


.pull-right[

# üìàStatistical Significanceüìà

<br>
<br>

The **number of times** plot $i$ being selected in $K$ evaluations is denoted as $c_i$. 

- In case subject $j$ makes **multiple selections**, $1/s_j$ will be added to $c_i$ instead of one, where $s_j$ is the **number of plots subject $j$ selected** for $j=1,...K$. 
- This ensures $\sum_{i}c_i=K$.

]

---


.center[
# üìàStatistical Significanceüìà
]

<br>

--

Since we are only interested in the **selections of the data plot $i$**, the **marginal model** can be simplified to a **beta-binomial model**. VanderPlas et al. (2021) derives the visual $p$-value as

$$P(C \geq c_i) = \sum_{x=c_i}^{K}{K \choose x}\frac{B(x + \alpha, K - x + (m - 1)\alpha)}{B(\alpha, (m-1)\alpha)},\text{ for } c_i \in \mathbb{Z}_0^+$$

where $B(.)$ is the beta function defined as

$$B(a, b) = \int_{0}^{1}t^{\alpha - 1}(1-t)^{b-1}dt,\text{ where } a,b>0.$$

--

We extend the equation to **non-negative real number $c_i$** by applying a linear approximation

$$
P(C \geq c_i) = P(C \geq \lceil c_i \rceil) + (\lceil c_i \rceil - c_i) P(C = \lfloor c_i \rfloor), \text{ for } c_i \in \mathbb{R}_0^+.
$$

---

.center[
# üí™Power of Visual Testsüí™
]

--

<br>

The power of a visual test may depend on the **ability of the particular subject** (Majumder, Hofmann, and Cook 2013).

--

- We assume the **individual skill has negligible effect** on the variation of the power to **simplify the model structure**, thereby **obviate a costly large-scale experiment** to estimate complex covariance matrices.

<br>

--

We use the **logistic regression** to estimate the power:

$$Pr(\text{reject}~H_0|H_1,E) = \Lambda\left(log\left(\frac{0.05}{0.95}\right) + \beta_1 E\right),$$

where $\Lambda(.)$ is the standard logistic function given as $\Lambda(z) = exp(z)/(1+exp(z))$. 

- The **effect size $E$** is the only predictor.
- The intercept is fixed to $log(0.05/0.95)$ so that $\hat{Pr}(\text{reject}~H_0|H_1,E = 0) = 0.05$.

---

.center[
# üß™Experimental Designüß™
]

<br>
<br>

--

An experiment is conducted to investigate the difference between **conventional hypothesis testing** and **visual testing** in the application of **linear regression diagnostics**.

--

<br>

We focus on two types of residual departures - **Non-linearity** and **Heteroskedasticity**.

--

<br>

Overall, we collected **7974 evaluations** on **1152 unique lineups** performed by **443 subjects** throughout three data collection periods.

---

.center[
# üß™Experimental Designüß™
]

**Non-linearity model**:

$$\begin{aligned} \boldsymbol{y} &= 1 + \boldsymbol{x} + \boldsymbol{z} + \boldsymbol{\varepsilon},\\ \boldsymbol{x} &= g(\boldsymbol{x}_{raw}, 1), \\ \boldsymbol{z} &= g(\boldsymbol{z}_{raw}, 1), \\ \boldsymbol{z}_{raw} &= He_j(g(\boldsymbol{x}, 2)), \end{aligned}$$
where $\boldsymbol{y}$, $\boldsymbol{x}$, $\boldsymbol{\varepsilon}$, $\boldsymbol{x}_{raw}$, $\boldsymbol{z}_{raw}$ are length $n$ vectors, $He_{j}(.)$ is the $j$th-order probabilist's Hermite polynomials, $\varepsilon \sim N(\boldsymbol{0}, \sigma^2\boldsymbol{I}_n)$, and $g(\boldsymbol{x}, k)$ is a scaling function to enforce the support of the random vector to be $[-k, k]^n$ defined as

$$g(\boldsymbol{x}, k) = (\boldsymbol{x} - min(\boldsymbol{x}))/max(\boldsymbol{x} - min(\boldsymbol{x}))2k - k, \text{ for }  k > 0. $$

The null regression model used to fit the realizations generated by the above model is formulated as

$$\boldsymbol{y} = \beta_0 + \beta_1 \boldsymbol{x} + \boldsymbol{u},$$

where $\boldsymbol{u} \sim N(\boldsymbol{0}, \sigma^2\boldsymbol{I}_n)$.

---


.center[
# üß™Experimental Designüß™
]

**Heteroskedasticity model**:

$$\begin{aligned} \label{eq:heter-model} \boldsymbol{y} &= 1 + \boldsymbol{x} + \boldsymbol{\varepsilon},\\ \boldsymbol{x} &= g(\boldsymbol{x}_{raw}, 1),\\ \boldsymbol{\varepsilon} &\sim N(\boldsymbol{0}, 1 + (2 - |a|)(\boldsymbol{x} - a)^2b \boldsymbol{I}), \end{aligned}$$

where $\boldsymbol{y}$, $\boldsymbol{x}$, $\boldsymbol{x}_{raw}$, $\boldsymbol{\varepsilon}$ are length $n$ vectors and $g(.)$ is the scaling function defined in the previous slide.


The null regression model is also provided in the previous slide.

---

```{r}
magick::image_read_pdf("images/different-shape-of-herimite-1.pdf", pages = 1)
magick::image_read_pdf("images/different-sigma-1.pdf", pages = 1)
```

.center[
.caption[
Fig. 5: _Non-linearity forms generated for the residual plots are controlled by the parameter \\(j\\). And the strength of the signal of the non-linearity model is controlled by \\(\sigma\\)._
]
]

---

.image-center[

```{r out.width = "70%", fig.height = 2.67, fig.width = 8}
set.seed(10086)

stand_dist <- function(x) (x - min(x))/max(x - min(x)) * 2 - 1

a_labels <- c("left-triangle (a = -1)", "butterfly (a = 0)", "right-triangle (a = 1)")

# Generate data for a = -1
dat_a_n1 <- heter_model(a = -1, 
                        x = {
                          raw_x <- rand_uniform(-1, 1);
                          closed_form(~stand_dist(raw_x))
                          },
                        b = 128)$gen(300) %>%
  mutate(a = a_labels[1])

# Generate data for other a
map(c(0, 1), function(a) {
  heter_model(a = a,
              x = {
                raw_x <- rand_uniform(-1, 1); 
                closed_form(~stand_dist(raw_x))
                }, 
              b = 128)$
    gen(300, computed = select(dat_a_n1, x, e)) %>%
    mutate(a = a_labels[a + 2])
}) %>%
  
  # Combined with data for a = -1
  bind_rows(dat_a_n1) %>%
  mutate(a = factor(a, levels = a_labels)) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light()) +
  facet_wrap(~a, scales = "free", ncol = 3) +
  xlab("Fitted values") +
  ylab("Residuals")
```

]

```{r}
magick::image_read_pdf("images/different-b-1.pdf", pages = 1)
```


.center[
.caption[
Fig. 5: _Heteroskedasticity forms generated for the residual plots are controlled by the parameter \\(a\\). And the strength of the signal of the heteroskedasticity model is controlled by \\(b\\)._
]
]

---

```{r}
magick::image_read_pdf("images/different-dist-1.pdf", pages = 1)
```

.image-center[

```{r out.width = "70%"}
magick::image_read_pdf("images/different-n-1.pdf", pages = 1)
```

]

.center[
.caption[
Fig. 5: _Four different distribution of fitted values that might affect perception of residual plots are used. Three differnet values of \\(n\\) are used to control the signal strength._
]
]

---

.center[
# üìèEffect sizeüìè
]

--

We have chosen to use an approach based on **Kullback-Leibler divergence** (Kullback and Leibler 1951).

--

The effect size of the **non-linearity model** is

$$E = \frac{1}{2}\left(\boldsymbol{\mu}_z'(diag(\boldsymbol{R}\sigma^2))^{-1}\boldsymbol{\mu}_z\right),$$

where $diag(.)$ is the diagonal matrix constructed from the diagonal elements of a matrix,
$\boldsymbol{R} = \boldsymbol{I}_n - \boldsymbol{H}$ is the residual operator, $\boldsymbol{H} = \boldsymbol{X}(\boldsymbol{X}'\boldsymbol{X})^{-1}\boldsymbol{X}'$ is the hat matrix, $\boldsymbol{\mu}_z = \boldsymbol{R}\boldsymbol{Z}\boldsymbol{\beta}_z$ is the expected values of residuals with $\boldsymbol{Z}$ be any higher order terms of $\boldsymbol{X}$ leave out by the regression equation and $\boldsymbol{\beta}_z$ be the corresponding coefficients, and $\sigma^2\boldsymbol{I}$ is the assumed covariance matrix of the error term when $H_0$ is true.

--

And the effect size of the **heteroskedasticity model** is

$$E = \frac{1}{2}\left(log\frac{|diag(\boldsymbol{R}\boldsymbol{V}\boldsymbol{R}')|}{|diag(\boldsymbol{R})|} - n + tr(diag(\boldsymbol{R}\boldsymbol{V}\boldsymbol{R}')^{-1}diag(\boldsymbol{R}))\right),$$
where $\boldsymbol{V}$ is the actual covariance matrix of the error term.

---

.center[
# üõ†Ô∏èExperimental Setupüõ†Ô∏è
]

We recruited 443 subjects from an crowd-sourcing platform called **Prolific** (Palan and Schitter 2018) throughout **three data collection periods**. 
- 160 subjects for period I
- 160 subjects for period II
- 123 subjects for period III

--

During the experiment, every subject is presented with **a block of 20 lineups**.

--

The subject is asked to:
- Select **one or more** plots that are **most different** from others.
- Provide **a reason** for their selections.
- Evaluate **how different** they think the selected plots are from others. 

--

If there is **no noticeable difference** between plots in a lineup, subjects are permitted to **select zero plots** without providing the reason.

--

A subject‚Äôs submission is only accepted if the data plot is identified for **at least one attention check**.

---

![](images/lineup1.png)

.center[
.caption[
Fig. 5: _Screenshot of the study website._
]
]

---

class: center, middle

# ‚öñÔ∏èResults - Power Comparison of the Tests‚öñÔ∏è

---

.image-top-bottom-0[

.image-center[

```{r out.width = "80%"}
knitr::include_graphics("images/polypower-1.png")
```

]

]

.center[
.caption[
Fig. 5: _Comparison of power between different tests for non-linear patterns (uniform fitted values only). The horizontal lines of dots represent non-reject and reject results from visual tests for each lineup. The visual test has multiple power curves estimated from bootstrap samples. The row of scatterplots at the bottom are examples of residual plots corresponding to the specific effect sizes marked by vertical lines in the main plot._
]
]

---

.image-top-bottom-0[

.image-center[

```{r out.width = "80%"}
knitr::include_graphics("images/heterpower-1.png")
```

]

]

.center[
.caption[
Fig. 5: _Comparison of power between different tests for heteroskedasticity patterns (uniform fitted values only). The horizontal lines of dots represent non-reject and reject results from visual tests for each lineup. The visual test has multiple power curves estimated from bootstrap samples. The row of scatterplots at the bottom are examples of residual plots corresponding to the specific effect sizes marked by vertical lines in the main plot._
]
]

---

# Integrate visual tests into regression diagnostics

(Still use non-linearity as the example)

How to perform a visual test in the context of regression diagnostics. 

Show the $p$-value by assuming the responses.


---

# Limitations of visual inference

Discuss the limitations of visual inference.

---

# Computer vision models

Briefly mention the potential solution to the problem.

---

# A compartative study

Provide the motivation and main objective of conducting such an experiment.

---

# Experiment design

Outlines the model used to simulate the experiment data.

---

# Effect size

Describe the effect size calculation.

---

# $P$-value calculation

Briefly discuss the $p$-value calculation.

---

# Power estimation

Write down the model used to estimate the power.

---

# Study website

Provide screenshots/examples of the study website.

---

# Results

Provide an overview of the collated data.

---

# Power comparison of the tests

---

# Comparison of test decisions based on $p$-values

---

# Effect of amount of non-linearity

---

# Effect of shape of heteroskedasticity

---

# Effect of fitted value distributions



---

# Timetable
