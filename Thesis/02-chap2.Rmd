---
chapter: 2
knit: "bookdown::render_book"
---

<!-- # Automatic Visual Statistical Inference, with Application to Linear Regression Diagnostics {#ch:paper1} -->

<!-- ## Abstract -->

<!-- ## Introduction -->

<!-- ### Model Diagnostics -->

<!-- [ET: suggestion: A model can be fitted to data with no guarantee of a meaningful interpretation. Model diagnostics play an important role in assessing the appropriateness of the model. The assessment can involve examining the goodness of fit, checking if there are potential violations of model assumptions and validating models with external information.] -->

<!-- Model diagnostics is the part of data analysis, preceded by the fit of a model, whose primary objectives are to examine the goodness of fit and reveal potential violations of model assumptions.  -->

<!-- [ET: model fit is more than just goodness of fit and checking model assumptions. It's too reductive to say this because you could have a model with good fit (according to some metric) and no model violation but if the way that the data were collected was flawed then scientific interpretation of the model is rendered useless. Diagnostics involve also the domain knowledge checks as well.] -->


<!-- In these diagnostics, though numeric summaries are mostly available and some are even endorsed by finite or asymptotic properties, graphical representation of data is still preferred, or at least needed, due to its intuitiveness and the possibility to provide unexpected discoveries which may be abstract and -->
<!-- unquantifiable.  -->

<!-- [ET: Generally, your sentences are too long. Break it up into smaller sentences. The generally idea is to make sentences that _continue an idea from the preceding sentence_ so it leads from one to the next naturally. E.g. Today is cloudy. Cloudy days are rare. Perhaps today will be different to other days!] -->

<!-- However, unlike confirmatory data analysis built upon rigorous statistical procedures, e.g., hypothesis testing, visual diagnostics relies on graphical perception - humanâ€™s ability to interpret and decode the information embedded in the graph [@cleveland_graphical_1984], which is to some extent subjective. Further, visual discovery suffers from its unsecured and unconfirmed nature where the degree of the presence of the visual features typically can not be measured quantitatively and objectively, which may lead to over or under-interpretations of the data. One such example is finding a separation between gene groups in a two-dimensional projection from a linear discriminant analysis where there is no difference in the expression levels between the gene groups [@roy_chowdhury_using_2015]. -->

<!-- [ET: Confirmatory data analysis is well characterised by a rigorous procedure to discern particular hypothesis. The most widespread form of confirmatory data analysis are the use of $p$-values in testing hypothesis in a frequentist framework. More specifically, hypothesis testing in a frequentist framework involve stating a well-defined hypotheses; summarising the evidence as a test statistic; and calculating the probability of observing a statistic as extreme as the observed test statistic under the null hypothesis. This rigour, however, is often not present when inferences are drawn from a plot.  -->

<!-- Something about model diagnostics with a plot being the common thing to do..] -->

<!-- ### Visual Inference -->

<!-- Visual inference was first introduced by @buja_statistical_2009 as an inferential framework to extend confirmatory statistics to visual discoveries. This framework redefines the test statistics, tests, null distribution, significance levels and $p$-value for visual discovery modelled on the confirmatory statistical testing. Figure \@ref(fig:fparallelism) outlines the parallelism between conventional tests and visual discovery.  -->

<!-- [ET: note use Rmd syntax for figures references! So it's easy to use it for HTML later if you want to do something like [Earo](https://github.com/earowang/thesis) and have PDF + HTML thesis. ] -->




<!-- ![(ref:parallelism) \label{fig:parallelism}](figures/rsta2009012001.jpg){width=450 height=341} -->


<!-- (ref:parallelism) Parallelism between multiple quantitative testing and visual discovery [@buja_statistical_2009]. -->

<!-- In visual inference, a visual discovery is defined as a rejection of a null hypothesis, and the same null hypothesis can be rejected by many different visual discoveries [@buja_statistical_2009]. For model diagnostics, the null hypothesis would be the assumed model, while the visual discoveries would be any findings that are inconsistent with the hypothesis. The same assumed model, such as classical linear regression model, can be rejected by both nonlinearity and heteroskedasticity with the residual plot as shown in Figure \@ref(fig:nonlinearityheter).  -->

<!-- ### Pre-specification of Visual Discoverable Features -->

<!-- As discussed in @buja_statistical_2009, in the practice of model diagnostics, the range of possible visual discoveries is not pre-specified. In other words, people do not explicitly specify which one or more visual features they are looking for before the read of the diagnostic plot. This is concerning since conventional hypothesis testing always requires the pre-specification of the parameter space $\Theta$ of the parameter of interest $\theta \in \Theta$ to form a valid inferential procedure. To address this issue, a collection of test statistics $T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)$ is defined, where $\boldsymbol{\mathrm{y}}$ is the data and $\boldsymbol{I}$ is a set of all possible visual features. @buja_statistical_2009 described each of the test statistics $T^{(i)}(\boldsymbol{\mathrm{y}})$ as a measurement of the degree of presence of a visual feature. Alternatively, @majumder_validation_2013 avoids the use of visual features and defined the visual statistics $T(.)$ as a mapping from a dataset to a data plot. Both definitions of visual test statistics are valid, but in the rest of the paper, the first definition will be used as it covered some details needed by this work.  -->

<!-- The size of the collection $T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)$ depends on the size of the set $I$. Thus, if one can define $I$ comprehensively, i.e, pre-specify all the visual discoverable features, the validity issue will be solved. Unfortunately, to our knowledge, there is no such a way to list all visual features. In linear regression diagnostics, possible visual features of a residual plot may be outliers, shapes and clusters. But this is an incomplete list which does not enumerate all the visual features. -->

<!-- Similarly, @wilkinson_graph-theoretic_2005 proposed the work called graph theoretic scagnostics, which adopted the idea of "scagnostics" - scatter plot diagnostics from (can't find the 1984 citation). It includes 9 computable scagnostics measures defined on planar proximity graphs: "Outlying", "Convex", "Skinny", "Stringy", "Straight", "Monotonic", "Skewed", "Clumpy" and "Striated" which attempts to describe outliers, shape, density, trend and coherence of the data. This approach is inspiring but it still does not give the complete list of visual discoverable features. In fact, it is possible that such a list will never be complete as suggested in @buja_statistical_2009. -->

<!-- Thinking out of the box, @buja_statistical_2009 argued that there is actually no need for pre-specification of visual discoverable features. In model diagnostics, when the null hypothesis is rejected, the reasons for rejecting the hypothesis will also be known. This is because observers can not only point out the fact that visual discoveries have been found, but also describe the particular visual features they observed. Those features will correspond to the subset of the collection of visual test statistics $T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)$ which resulted in rejection. This argument helps justifies the validity of visual inference. -->


<!-- ### Lineup Protocol -->

<!-- With the validity of visual inference being justified, another aspect of hypothesis testing that needs to be addressed is the control of false positive rate or Type I error. Any visual statistic $T^{(i)}(\boldsymbol{\mathrm{y}})$ needs to pair with a critical value $c^{(i)}$ to form a hypothesis test. When a visual feature $i$ is discovered by the observer from a plot, the corresponding visual statistic $T^{(i)}(\boldsymbol{\mathrm{y}})$ may not be known as there is no general agreement on the measurement of the degree of presence of a visual feature. It is only the event that $T^{(i)}(\boldsymbol{\mathrm{y}}) > c^{(i)}$ is confirmed. Similarly, if any visual discovery is found by the observer, we say, there exists $i \in I:~T^{(i)}(\boldsymbol{\mathrm{y}}) > c^{(i)}$ [@buja_statistical_2009]. -->

<!-- Using the above definition, the family-wise Type I error can be controlled if one can provide the collection of critical values $c^{(i)}~(i \in I)$ such that $P(\mathrm{there~exists~} i \in I: T^{(i)}(\boldsymbol{\mathrm{y}}) > c^{(i)}|\boldsymbol{\mathrm{y}}) \leq \alpha$, where $\alpha$ is the significance level. However, since the quantity of $T^{(i)}(\boldsymbol{\mathrm{y}})$ may not be known, such collection of critical values can not be provided. -->

<!-- @buja_statistical_2009 proposed the lineup protocol as a visual test to calibrate the Type I error issue without the specification of $c^{(i)}~(i \in I)$. It is inspired by the "police lineup" or "identity parade" which is the act of asking the eyewitness to identify criminal suspect from a group of irrelevant people. The protocol consists of $m$ randomly placed data plots, where $1$ plot is the actual data plot, and $m-1$ null plots are produced by plotting data simulate from the null distribution which is consistent with the null hypothesis. Then, an observer who have not seen the actual data plot will be asked to point out the most different plot from the lineup. -->

<!-- Under the null hypothesis, it is expected that the actual data plot would have no distinguishable difference with the null plots, and the probability of the observer correctly picks the actual data plot is $1/m$ due to randomness. If we reject the null hypothesis as the observer correctly picks the actual data plot, then the Type I error of this test is $1/m$. -->

<!-- This provides us with an mechanism to control the Type I error, because $m$ - the number of plots in a lineup can be chosen. Further, if we involve $K$ independent observers in a visual test, and let $X$ be a random variable denoting the number of observers correctly picking the actual data plot. Then, under the null hypothesis $X \sim \mathrm{Binom}_{K,1/m}$, and therefore, the $p$-value of a lineup of size $m$ evaluated by $K$ observer is given as -->

<!-- $$P(X \geq x) = \sum_{i=x}^{K}{{K}\choose{i}}\left(\frac{1}{m}\right)^i\left(\frac{m-1}{m}\right)^{k-i},$$ -->
<!-- where $x$ is the realization of number of observers correctly picking the actual data plot [@majumder_validation_2013]. -->







<!-- ### Visual Inference Applied to Linear Regression -->



<!-- How people used visual inference in linear regression? -->


<!-- ### Limitation of the Visual Inference  -->

<!-- What are the limitations? -->

<!-- ### Computer Vision Model -->

<!-- What is computer vision model? -->

<!-- ### Contribution -->

<!-- What has been done by this paper? -->

<!-- ### Structure of This Paper -->

<!-- What is the structure of the paper? -->




<!-- Model diagnostics is the part of data analysis whose primary objectives are to examine the goodness of the model fit and reveal potential violations of the assumptions. Graphical approaches   -->

<!-- For regression diagnostics, it may includes the needs of    -->

<!-- Linear regression is an modelling approach to describe the relationship between an response variable and one or more explanatory variable. It has been widely used for both generative modeling and predictive modelling.    -->

<!-- Regression diagnostics is needed  -->

<!-- 1. to check whether the assumptions has been violated -->
<!-- 2. to check whether the line fit the data -->



<!-- Model diagnostics for linear regression is well developed    -->
