---
chapter: 2
knit: "bookdown::render_book"
---

# Automatic Visual Statistical Inference, with Application to Linear Regression Diagnostics {#ch:paper1}

## Abstract

## Introduction

### Model Diagnostics

Model diagnostics is the part of data analysis, preceded by the fit of a model, whose primary objectives are to examine the goodness of fit and reveal potential violations of model assumptions. 
In these diagnostics, though numeric summaries are mostly available and some are even endorsed by finite or asymptotic properties, graphic representation of data is still preferred, or at least needed, due to its intuitiveness and the possibility to provide unexpected discoveries which may be abstract and
unquantifiable. 

However, unlike confirmatory data analysis built upon rigorous statistical procedures, e.g., hypothesis testing, visual diagnostics relies on graphical perception - humanâ€™s ability to interpret and decode the information embedded in the graph [@cleveland_graphical_1984], which is to some extent subjective. Further, visual discovery suffers from its unsecured and unconfirmed nature where the degree of the presence of the visual features typically can not be measured quantitatively and objectively, which may lead to over or under-interpretations of the data. One such example is finding a separation between gene groups in a two-dimensional projection from a linear discriminant analysis where there is no difference in the expression levels between the gene groups [@roy_chowdhury_using_2015].

### Visual Inference

Visual inference was first introduced by @buja_statistical_2009 as an inferential framework to extend confirmatory statistics to visual discoveries. This framework redefines the test statistics, tests, null distribution, significance levels and $p$-value for visual discovery modelled on the confirmatory statistical testing. Figure \ref{fig:parallelism} outlines the parallelism between conventional tests and visual discovery. 

![(ref:parallelism) \label{fig:parallelism}](figures/rsta2009012001.jpg){width=450 height=341}


(ref:parallelism) Parallelism between multiple quantitative testing and visual discovery [@buja_statistical_2009].

In visual inference, a visual discovery is defined as a rejection of a null hypothesis, and the same null hypothesis can be rejected by many different visual discoveries [@buja_statistical_2009]. For model diagnostics, the null hypothesis would be the assumed model, while the visual discoveries would be any findings that are inconsistent with the hypothesis. The same assumed model, such as classical linear regression model, can be rejected by both nonlinearity and heteroskedasticity with the residual plot as shown in Figure \ref{fig:nonlinearityheter}. 

### Pre-specification of Visual Discoverable Features

As discussed in @buja_statistical_2009, in the practice of model diagnostics, the range of possible visual discoveries is not pre-specified. In other words, people do not explicitly specify which one or more visual features they are looking for before the read of the diagnostic plot. This is concerning since conventional hypothesis testing always requires the pre-specification of the parameter space $\Theta$ of the parameter of interest $\theta \in \Theta$ to form a valid inferential procedure. To address this issue, a collection of test statistics $T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)$ is defined, where $\boldsymbol{\mathrm{y}}$ is the data and $\boldsymbol{I}$ is a set of all possible visual features. @buja_statistical_2009 described each of the test statistics $T^{(i)}(\boldsymbol{\mathrm{y}})$ as a measurement of the degree of presence of a visual feature. Alternatively, @majumder_validation_2013 avoids the use of visual features and defined the visual statistics $T(.)$ as a mapping from a dataset to a data plot. Both definitions of visual test statistics are valid, but in the rest of the paper, the first definition will be used as it covered some details needed by this work. 

The size of the collection $T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)$ depends on the size of the set $I$. Thus, if one can define $I$ comprehensively, i.e, pre-specify all the visual discoverable features, the validity issue will be solved. Unfortunately, to our knowledge, there is no such a way to list all visual features. In linear regression diagnostics, possible visual features of a residual plot may be outliers, shapes and clusters. But this is an incomplete list which does not enumerate all the visual features.

Similarly, @wilkinson_graph-theoretic_2005 proposed the work called graph theoretic scagnostics, which adopted the idea of "scagnostics" - scatter plot diagnostics from (can't find the 1984 citation). It includes 9 computable scagnostics measures defined on planar proximity graphs: "Outlying", "Convex", "Skinny", "Stringy", "Straight", "Monotonic", "Skewed", "Clumpy" and "Striated" which attempts to describe outliers, shape, density, trend and coherence of the data. This approach is inspiring but it still does not give the complete list of visual discoverable features. In fact, it is possible that such a list will never be complete as suggested in @buja_statistical_2009.

Thinking out of the box, @buja_statistical_2009 argued that there is actually no need for pre-specification of visual discoverable features. In model diagnostics, when the null hypothesis is rejected, the reasons for rejecting the hypothesis will also be known. This is because observers not only can point out the fact that visual discoveries have been found, but also can describe the particular features they observed. Those features will correspond to the subset of the collection of visual test statistics $T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)$ which resulted in rejection. 

```{r nonlinearityheter, fig.cap="test"}
library(tidyverse)

set.seed(10086)
cm <- visage::cubic_model(a = 0, b = 100, c = 1)

cm$gen(1000, fit_model = TRUE) %>%
cm$plot() +
  ggtitle("Residuals against fitted values plot of a classical linear regression model") +
  theme_light()
```

### Lineup Protocol

#### Type-I error

#### Type-II error









### Visual Inference Applied to Linear Regression



How people used visual inference in linear regression?


### Limitation of the Visual Inference 

What are the limitations?

### Computer Vision Model

What is computer vision model?

### Contribution

What has been done by this paper?

### Structure of This Paper

What is the structure of the paper?




Model diagnostics is the part of data analysis whose primary objectives are to examine the goodness of the model fit and reveal potential violations of the assumptions. Graphical approaches  

For regression diagnostics, it may includes the needs of   

Linear regression is an modelling approach to describe the relationship between an response variable and one or more explanatory variable. It has been widely used for both generative modeling and predictive modelling.   

Regression diagnostics is needed 

1. to check whether the assumptions has been violated
2. to check whether the line fit the data



Model diagnostics for linear regression is well developed   
