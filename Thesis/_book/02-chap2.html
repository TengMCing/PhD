<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Advances in Artificial Intelligence for Data Visualization: Developing Computer Vision Models to Automate Reading of Data Plots, with Application to Regression Diagnostics - 2&nbsp; A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./03-chap3.html" rel="next">
<link href="./01-chap1.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><link href="https://fonts.googleapis.com/css?family=Fira+Sans%7CMerriweather%7CSource%20Code%20Pro" rel="stylesheet">
<script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script><script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script><script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02-chap2.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Advances in Artificial Intelligence for Data Visualization: Developing Computer Vision Models to Automate Reading of Data Plots, with Application to Regression Diagnostics</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Front matter</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-chap1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-chap2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-chap3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Automated assessment of residual plots with computer vision models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./refs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliography</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A-appA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Appendix to “A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol”</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title"><b>Sections</b></h2>
   
  <ul class="collapse">
<li><a href="#sec-introduction" id="toc-sec-introduction" class="nav-link active" data-scroll-target="#sec-introduction"><span class="header-section-number">2.1</span> Introduction</a></li>
  <li><a href="#sec-background" id="toc-sec-background" class="nav-link" data-scroll-target="#sec-background"><span class="header-section-number">2.2</span> Background</a></li>
  <li><a href="#sec-significance-calculation" id="toc-sec-significance-calculation" class="nav-link" data-scroll-target="#sec-significance-calculation"><span class="header-section-number">2.3</span> Calculation of Statistical Significance and Test Power</a></li>
  <li><a href="#sec-experimental-design" id="toc-sec-experimental-design" class="nav-link" data-scroll-target="#sec-experimental-design"><span class="header-section-number">2.4</span> Experimental Design</a></li>
  <li><a href="#sec-results" id="toc-sec-results" class="nav-link" data-scroll-target="#sec-results"><span class="header-section-number">2.5</span> Results</a></li>
  <li><a href="#limitations-and-practicality" id="toc-limitations-and-practicality" class="nav-link" data-scroll-target="#limitations-and-practicality"><span class="header-section-number">3</span> Limitations and Practicality</a></li>
  <li><a href="#conclusions" id="toc-conclusions" class="nav-link" data-scroll-target="#conclusions"><span class="header-section-number">4</span> Conclusions</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span id="paper-1" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><p>Regression experts consistently recommend plotting residuals for model diagnosis, despite the availability of many numerical hypothesis test procedures designed to use residuals to assess problems with a model fit. Here we provide evidence for why this is good advice using data from a visual inference experiment. We show how conventional tests are too sensitive, which means that too often the conclusion would be that the model fit is inadequate. The experiment uses the lineup protocol which puts a residual plot in the context of null plots. This helps generate reliable and consistent reading of residual plots for better model diagnosis. It can also help in an obverse situation where a conventional test would fail to detect a problem with a model due to contaminated data. The lineup protocol also detects a range of departures from good residuals simultaneously. Supplemental materials for the article are available online.</p>
<section id="sec-introduction" class="level2" data-number="2.1"><h2 data-number="2.1" class="anchored" data-anchor-id="sec-introduction">
<span class="header-section-number">2.1</span> Introduction</h2>
<blockquote class="blockquote">
<p><em>“Since all models are wrong the scientist must be alert to what is importantly wrong.”</em> <span class="citation" data-cites="box1976science">(<a href="refs.html#ref-box1976science" role="doc-biblioref">Box 1976</a>)</span></p>
</blockquote>
<p>Diagnosing a model is an important part of building an appropriate model. In linear regression analysis, studying the residuals from a model fit is a common diagnostic activity. Residuals summarise what is not captured by the model, and thus provide the capacity to identify what might be wrong.</p>
<p>We can assess residuals in multiple ways. To examine the univariate distribution, residuals may be plotted as a histogram or normal probability plot. Using the classical normal linear regression model as an example, if the distribution is symmetric and unimodal, we would consider it to be well-behaved. However, if the distribution is skewed, bimodal, multimodal, or contains outliers, there would be cause for concern. We can also inspect the distribution by conducting a goodness-of-fit test, such as the Shapiro-Wilk normality test <span class="citation" data-cites="shapiro1965analysis">(<a href="refs.html#ref-shapiro1965analysis" role="doc-biblioref">Shapiro and Wilk 1965</a>)</span>.</p>
<p>Scatterplots of residuals against the fitted values, and each of the explanatory variables, are commonly used to scrutinize their relationships. If there are any visually discoverable associations, the model is potentially inadequate or incorrectly specified. We can also potentially discover patterns not directly connected to a linear model assumption from these residual plots, such as the discreteness or skewness of the fitted values, and outliers. To read residual plots, one looks for noticeable departures from the model such as non-linear pattern or heteroskedasticity. A non-linear pattern would suggest that the model needs to have some additional non-linear terms. Heteroskedasticity suggests that the error is dependent on the predictors, and hence violates the independence assumption. Statistical tests were developed to provide objective assessment, for example, of non-linear patterns <span class="citation" data-cites="ramsey1969tests">(e.g. <a href="refs.html#ref-ramsey1969tests" role="doc-biblioref">Ramsey 1969</a>)</span>, and heteroskedasticity <span class="citation" data-cites="breusch1979simple">(e.g. <a href="refs.html#ref-breusch1979simple" role="doc-biblioref">Breusch and Pagan 1979</a>)</span>.</p>
<p>The common wisdom of experts is that plotting the residuals is indispensable for diagnosing model fits <span class="citation" data-cites="draper1998applied cook1982residuals montgomery1982introduction">(<a href="refs.html#ref-cook1982residuals" role="doc-biblioref">Cook and Weisberg 1982</a>; <a href="refs.html#ref-draper1998applied" role="doc-biblioref">Draper and Smith 1998</a>; <a href="refs.html#ref-montgomery1982introduction" role="doc-biblioref">Montgomery et al. 1982</a>)</span>. The lack of empirical evidence for the ubiquitous advice is <em>curious</em>, and is what this article tackles.</p>
<p>Additionally, relying solely on the subjective assessment of a single plot can be problematic. People will almost always see a pattern <span class="citation" data-cites="kahneman2011thinking">(see <a href="refs.html#ref-kahneman2011thinking" role="doc-biblioref">Kahneman 2011</a>)</span>, so the question that really needs answering is whether any pattern perceived is consistent with randomness, or sampling variability, or noise. Correctly judging whether <em>no</em> pattern exists in a residual plot is a difficult task. <span class="citation" data-cites="loy2021bringing">Loy (<a href="refs.html#ref-loy2021bringing" role="doc-biblioref">2021</a>)</span> emphasizes that this is especially difficult to teach to new analysts and students, and advocates to the broader use of the lineup protocol <span class="citation" data-cites="bujastatistical2009">(<a href="refs.html#ref-bujastatistical2009" role="doc-biblioref">Buja et al. 2009a</a>)</span>.</p>
<p>The lineup protocol places a data plot in a field of null plots, allowing for a comparison of patterns due purely by chance to what is perceived in the data plot. For residual analysis this is especially helpful for gauging whether there is <em>no</em> pattern. (<a href="#fig-first-example-lineup">Figure&nbsp;<span>2.1</span></a> shows an example of a lineup of residual plots.) In its strict use, one would insist that the data plot is not seen before seeing the lineup, so that the observer does not know which is the true plot. When used this way, it provides an objective test for data plots. <span class="citation" data-cites="majumdervalidation2013">Majumder et al. (<a href="refs.html#ref-majumdervalidation2013" role="doc-biblioref">2013a</a>)</span> validated that results from lineups assessed by human observers performed similarly to conventional tests. One would not use a lineup when a conventional test exists and is adequate because it is more manually expensive to conduct. However, where no adequate conventional test exists, it is invaluable, as shown by <span class="citation" data-cites="loy2013diagnostic">Loy and Hofmann (<a href="refs.html#ref-loy2013diagnostic" role="doc-biblioref">2013</a>)</span>. Here we use the lineup as a vehicle to rigorously explore why experts advise that residual plots are indispensable despite the prevalence of numerical tests.</p>
<p>The paper is structured as follows. <a href="#sec-background"><span>Section&nbsp;2.2</span></a> describes the background on the types of departures that one expects to detect, and outlines a formal statistical process for reading residual plots, called visual inference. <a href="#sec-significance-calculation"><span>Section&nbsp;2.3</span></a> describes the calculation of the statistical significance and power of the test. <a href="#sec-experimental-design"><span>Section&nbsp;2.4</span></a> details the experimental design to compare the decisions made by formal hypothesis testing, and how humans would read diagnostic plots. The results are reported in <a href="#sec-results"><span>Section&nbsp;2.5</span></a>. We conclude with a discussion of the presented work, and ideas for future directions.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-first-example-lineup" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="02-chap2_files/figure-html/fig-first-example-lineup-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2.1: Visual testing is conducted using a lineup, as in the example here. The residual plot computed from the observed data is embedded among 19 null plots, where the residuals are simulated from a standard error model. Computing the <span class="math inline">p</span>-value requires that the lineup be examined by a number of human judges, each asked to select the most different plot. A small <span class="math inline">p</span>-value would result from a substantial number selecting the data plot (at position <span class="math inline">6</span>, exhibiting non-linearity).</figcaption></figure>
</div>
</div>
</div>
</section><section id="sec-background" class="level2" data-number="2.2"><h2 data-number="2.2" class="anchored" data-anchor-id="sec-background">
<span class="header-section-number">2.2</span> Background</h2>
<section id="departures-from-good-residual-plots" class="level3" data-number="2.2.1"><h3 data-number="2.2.1" class="anchored" data-anchor-id="departures-from-good-residual-plots">
<span class="header-section-number">2.2.1</span> Departures from Good Residual Plots</h3>
<p>Graphical summaries where residuals are plotted against fitted values, or other functions of the predictors (expected to be approximately orthogonal to the residuals) are considered to be the most important residual plots by <span class="citation" data-cites="cook1999applied">Cook and Weisberg (<a href="refs.html#ref-cook1999applied" role="doc-biblioref">1999</a>)</span>. <a href="#fig-residual-plot-common-departures">Figure&nbsp;<span>2.2</span></a>A shows an example of an ideal residual plot where points are symmetrically distributed around the horizontal zero line (red), with no discernible patterns. There can be various types of departures from this ideal pattern. Non-linearity, heteroskedasticity and non-normality, shown in <a href="#fig-residual-plot-common-departures">Figure&nbsp;<span>2.2</span></a>B, <a href="#fig-residual-plot-common-departures">Figure&nbsp;<span>2.2</span></a>C, and <a href="#fig-residual-plot-common-departures">Figure&nbsp;<span>2.2</span></a>D, respectively, are three commonly checked departures.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-residual-plot-common-departures" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="02-chap2_files/figure-html/fig-residual-plot-common-departures-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2.2: Example residual vs fitted value plots (horizontal line indicates 0): (A) classically good looking residuals, (B) non-linear pattern indicates that the model has not captured a non-linear association, (C) heteroskedasticity indicating that variance around the fitted model is not uniform, and (D) non-normality where the residual distribution is not symmetric around 0. The latter pattern might best be assessed using a univariate plot of the residuals, but patterns B and C need to be assessed using a residual vs fitted value plot.</figcaption></figure>
</div>
</div>
</div>
<p>Model misspecification occurs if functions of predictors that needed to accurately describe the relationship with the response are incorrectly specified. This includes instances where a higher-order polynomial term of a predictor is wrongfully omitted. Any non-linear pattern visible in the residual plot could be indicative of this problem. An example residual plot containing visual pattern of non-linearity is shown in <a href="#fig-residual-plot-common-departures">Figure&nbsp;<span>2.2</span></a>B. One can clearly observe the “S-shape” from the residual plot, which corresponds to the cubic term that should have been included in the model.</p>
<p>Heteroskedasticity refers to the presence of non-constant error variance in a regression model. It indicates that the distribution of residuals depends on the predictors, violating the independence assumption. This can be seen in a residual plot as an inconsistent spread of the residuals relative to the fitted values or predictors. An example is the “butterfly” shape shown in <a href="#fig-residual-plot-common-departures">Figure&nbsp;<span>2.2</span></a>C, or a “left-triangle” and “right-triangle” shape where the smallest variance occurs at one side of the horizontal axis.</p>
<p><a href="#fig-residual-plot-common-departures">Figure&nbsp;<span>2.2</span></a>D shows a scatterplot where the residuals have a skewed distribution, as seen by the uneven vertical spread. Unlike non-linearity and heteroskedasticity, non-normality is usually detected with a different type of residual plot: a histogram or a normal probability plot. Because we focus on scatterplots, non-normality is not one of the departures examined in depth in this paper. <span class="citation" data-cites="loy2016variations">(<a href="refs.html#ref-loy2016variations" role="doc-biblioref">Loy et al. 2016</a> discuss related work on non-normality checking.)</span></p>
</section><section id="conventionally-testing-for-departures" class="level3" data-number="2.2.2"><h3 data-number="2.2.2" class="anchored" data-anchor-id="conventionally-testing-for-departures">
<span class="header-section-number">2.2.2</span> Conventionally Testing for Departures</h3>
<p>Many different hypothesis tests are available to detect specific model defects. For example, the presence of heteroskedasticity can usually be tested by applying the White test <span class="citation" data-cites="white1980heteroskedasticity">(<a href="refs.html#ref-white1980heteroskedasticity" role="doc-biblioref">White 1980</a>)</span> or the Breusch-Pagan (BP) test <span class="citation" data-cites="breusch1979simple">(<a href="refs.html#ref-breusch1979simple" role="doc-biblioref">Breusch and Pagan 1979</a>)</span>, which are both derived from the Lagrange multiplier test <span class="citation" data-cites="silvey1959lagrangian">(<a href="refs.html#ref-silvey1959lagrangian" role="doc-biblioref">Silvey 1959</a>)</span> principle that relies on the asymptotic properties of the null distribution. To test specific forms of non-linearity, one may apply the F-test as a model structural test to examine the significance of a specific polynomial and non-linear forms of the predictors, or the significance of proxy variables as in the Ramsey Regression Equation Specification Error Test (RESET) <span class="citation" data-cites="ramsey1969tests">(<a href="refs.html#ref-ramsey1969tests" role="doc-biblioref">Ramsey 1969</a>)</span>. The Shapiro-Wilk (SW) normality test <span class="citation" data-cites="shapiro1965analysis">(<a href="refs.html#ref-shapiro1965analysis" role="doc-biblioref">Shapiro and Wilk 1965</a>)</span> is the most widely used test of non-normality included by many of the statistical software programs. The Jarque-Bera test <span class="citation" data-cites="jarque1980efficient">(<a href="refs.html#ref-jarque1980efficient" role="doc-biblioref">Jarque and Bera 1980</a>)</span> is also used to directly check whether the sample skewness and kurtosis match a normal distribution.</p>
<p><a href="#tbl-example-residual-plot-table">Table&nbsp;<span>2.1</span></a> displays the <span class="math inline">p</span>-values from the RESET, BP and SW tests applied to the residual plots in <a href="#fig-residual-plot-common-departures">Figure&nbsp;<span>2.2</span></a>. The RESET test and BP test were computed using the <code>resettest</code> and <code>bptest</code> functions from the R package <code>lmtest</code>, respectively. The SW test was computed using the <code>shapiro.test</code> from the core R package <code>stats</code>. <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> The RESET test requires the selection of a power parameter. <span class="citation" data-cites="ramsey1969tests">Ramsey (<a href="refs.html#ref-ramsey1969tests" role="doc-biblioref">1969</a>)</span> recommends a power of four, which we adopted in our analysis.</p>
<p>For residual plots in <a href="#fig-residual-plot-common-departures">Figure&nbsp;<span>2.2</span></a>, we would expect the RESET test for non-linearity to reject residual plot B, the BP test for heteroskedasticity to reject the residual plot C, and the SW test for non-normality to reject residual plot D, which they all do and all tests also correctly fail to reject residual plot A. Interestingly, the BP and SW tests also reject the residual plots exhibiting structure that they were not designed for. <span class="citation" data-cites="cook1982residuals">Cook and Weisberg (<a href="refs.html#ref-cook1982residuals" role="doc-biblioref">1982</a>)</span> explain that most residual-based tests for a particular departure from the model assumptions are also sensitive to other types of departures. This could be considered a Type III error <span class="citation" data-cites="kimball1957errors">(<a href="refs.html#ref-kimball1957errors" role="doc-biblioref">Kimball 1957</a>)</span>, where the null hypothesis of good residuals is correctly rejected but for the wrong reason. Also, some types of departure can have elements of other types of departure, for example, non-linearity can appear like heteroskedasticity. Additionally, other data problems such as outliers can trigger rejection (or not) of the null hypothesis <span class="citation" data-cites="cook1999applied">(<a href="refs.html#ref-cook1999applied" role="doc-biblioref">Cook and Weisberg 1999</a>)</span>.</p>
<p>With large sample sizes, hypothesis tests may reject the null hypothesis when there is only a small effect. (A good discussion can be found in <span class="citation" data-cites="kirk1996practical">Kirk (<a href="refs.html#ref-kirk1996practical" role="doc-biblioref">1996</a>)</span>.) While such rejections may be statistically correct, their sensitivity may render the results impractical. A key goal of residual plot diagnostics is to identify potential issues that could lead to incorrect conclusions or errors in subsequent analyses, but minor defects in the model are unlikely to have a significant impact and may be best disregarded for practical purposes. The experiment discussed in this paper specifically addresses this tension between statistical significance and practical significance.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="tbl-example-residual-plot-table" class="anchored">
<table data-quarto-postprocess="true" class="table table-sm table-striped small">
<caption>Table&nbsp;2.1: Statistical significance testing for departures from good residuals for plots in <a href="#fig-residual-plot-common-departures">Figure&nbsp;<span>2.2</span></a>. Shown are the <span class="math inline">p</span>-values calculated for the RESET, the BP and the SW tests. The good residual plot (A) is judged a good residual plot, as expected, by all tests. The non-linearity (B) is detected by all tests, as might be expected given the extreme structure.</caption>
<thead><tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">Plot</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Departures</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">RESET</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">BP</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">SW</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">A</td>
<td style="text-align: left;">None</td>
<td style="text-align: right;"><span style="     ">0.779</span></td>
<td style="text-align: right;"><span style="     ">0.133</span></td>
<td style="text-align: right;"><span style="     ">0.728</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">B</td>
<td style="text-align: left;">Non-linearity</td>
<td style="text-align: right;"><span style="  font-style: italic;   ">0.000</span></td>
<td style="text-align: right;"><span style="  font-style: italic;   ">0.000</span></td>
<td style="text-align: right;"><span style="  font-style: italic;   ">0.039</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">C</td>
<td style="text-align: left;">Heteroskedasticity</td>
<td style="text-align: right;"><span style="     ">0.658</span></td>
<td style="text-align: right;"><span style="  font-style: italic;   ">0.000</span></td>
<td style="text-align: right;"><span style="  font-style: italic;   ">0.000</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">D</td>
<td style="text-align: left;">Non-normality</td>
<td style="text-align: right;"><span style="     ">0.863</span></td>
<td style="text-align: right;"><span style="     ">0.736</span></td>
<td style="text-align: right;"><span style="  font-style: italic;   ">0.000</span></td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
</section><section id="sec-visual-test-procedure-based-on-lineups" class="level3" data-number="2.2.3"><h3 data-number="2.2.3" class="anchored" data-anchor-id="sec-visual-test-procedure-based-on-lineups">
<span class="header-section-number">2.2.3</span> Visual Test Procedure based on Lineups</h3>
<p>The examination of data plots to infer signals or patterns (or lack thereof) is fraught with variation in the human ability to interpret and decode the information embedded in a graph <span class="citation" data-cites="cleveland1984graphical">(<a href="refs.html#ref-cleveland1984graphical" role="doc-biblioref">Cleveland and McGill 1984</a>)</span>. In practice, over-interpretation of a single plot is common. For instance, <span class="citation" data-cites="roy2015using">Roy Chowdhury et al. (<a href="refs.html#ref-roy2015using" role="doc-biblioref">2015</a>)</span> described a published example where authors over-interpreted separation between gene groups from a two-dimensional projection of a linear discriminant analysis even when there were no differences in the expression levels between the gene groups.</p>
<p>One solution to over-interpretation is to examine the plot in the context of natural sampling variability assumed by the model, called the lineup protocol, as proposed in <span class="citation" data-cites="buja2009statistical">Buja et al. (<a href="refs.html#ref-buja2009statistical" role="doc-biblioref">2009b</a>)</span>. <span class="citation" data-cites="majumder2013validation">Majumder et al. (<a href="refs.html#ref-majumder2013validation" role="doc-biblioref">2013b</a>)</span> showed that the lineup protocol is analogous to the null hypothesis significance testing framework. The protocol consists of <span class="math inline">m</span> randomly placed plots, where one plot is the data plot, and the remaining <span class="math inline">m - 1</span> plots, referred to as the <em>null plots</em>, are constructed using the same graphical procedure as the data plot but the data is replaced with null data that is generated in a manner consistent with the null hypothesis, <span class="math inline">H_0</span>. Then, an observer who has not seen the data plot is asked to point out the most different plot from the lineup. Under <span class="math inline">H_0</span>, it is expected that the data plot would have no distinguishable difference from the null plots, and the probability that the observer correctly picks the data plot is <span class="math inline">1/m</span>. If one rejects <span class="math inline">H_0</span> as the observer correctly picks the data plot, then the Type I error of this test is <span class="math inline">1/m</span>. This protocol requires a priori specification of <span class="math inline">H_0</span> (or at least a null data generating mechanism), much like the requirement of knowing the sampling distribution of the test statistic in null hypothesis significance testing framework.</p>
<p>Figure <a href="#fig-first-example-lineup">Figure&nbsp;<span>2.1</span></a> is an example of a lineup protocol. If the data plot at position <span class="math inline">6</span> is identifiable, then it is evidence for the rejection of <span class="math inline">H_0</span>. In fact, the actual residual plot is obtained from a misspecified regression model with missing non-linear terms.</p>
<p>Data used in the <span class="math inline">m - 1</span> null plots needs to be simulated. In regression diagnostics, sampling data consistent with <span class="math inline">H_0</span> is equivalent to sampling data from the assumed model. As <span class="citation" data-cites="buja2009statistical">Buja et al. (<a href="refs.html#ref-buja2009statistical" role="doc-biblioref">2009b</a>)</span> suggested, <span class="math inline">H_0</span> is usually a composite hypothesis controlled by nuisance parameters. Since regression models can have various forms, there is no general solution to this problem, but it sometimes can be reduced to a so called “reference distribution” by applying one of the three methods: (i) sampling from a conditional distribution given a minimal sufficient statistic under <span class="math inline">H_0</span>, (ii) parametric bootstrap sampling with nuisance parameters estimated under <span class="math inline">H_0</span>, and (iii) Bayesian posterior predictive sampling. The conditional distribution given a minimal sufficient statistic is the best justified reference distribution among the three <span class="citation" data-cites="buja2009statistical">(<a href="refs.html#ref-buja2009statistical" role="doc-biblioref">Buja et al. 2009b</a>)</span>. Under this method, the null residuals can essentially be simulated by independent drawing from a standard normal random distribution, then regressing the draws on the predictors, and then re-scaling it by the ratio of the residual sum of square in two regressions.</p>
<p>The effectiveness of lineup protocol for regression analysis has been validated by <span class="citation" data-cites="majumder2013validation">Majumder et al. (<a href="refs.html#ref-majumder2013validation" role="doc-biblioref">2013b</a>)</span> under relatively simple settings with up to two predictors. Their results suggest that visual tests are capable of testing the significance of a single predictor with a similar power to a t-test, though they express that in general it is unnecessary to use visual inference if there exists a corresponding conventional test, and they do not expect the visual test to perform equally well as the conventional test. In their third experiment, where the contamination of the data violate the assumptions of the conventional test, visual test outperforms the conventional test by a large margin. This supports the use of visual inference in situations where there are no existing numerical testing procedures. Visual inference has also been integrated into diagnostics for hierarchical linear models where the lineup protocol is used to judge the assumptions of linearity, normality and constant error variance for both the level-1 and level-2 residuals <span class="citation" data-cites="loy2013diagnostic loy2014hlmdiag loy2015you">(<a href="refs.html#ref-loy2013diagnostic" role="doc-biblioref">Loy and Hofmann 2013</a>, <a href="refs.html#ref-loy2014hlmdiag" role="doc-biblioref">2014</a>, <a href="refs.html#ref-loy2015you" role="doc-biblioref">2015</a>)</span>.</p>
</section></section><section id="sec-significance-calculation" class="level2" data-number="2.3"><h2 data-number="2.3" class="anchored" data-anchor-id="sec-significance-calculation">
<span class="header-section-number">2.3</span> Calculation of Statistical Significance and Test Power</h2>
<section id="what-is-being-tested" class="level3" data-number="2.3.1"><h3 data-number="2.3.1" class="anchored" data-anchor-id="what-is-being-tested">
<span class="header-section-number">2.3.1</span> What is Being Tested?</h3>
<p>In diagnosing a model fit using the residuals, we are generally interested in testing whether “<em>the regression model is correctly specified</em>” (<span class="math inline">H_0</span>) against the broad alternative “<em>the regression model is misspecified</em>” (<span class="math inline">H_a</span>). However, it is practically impossible to test this broad <span class="math inline">H_0</span> with conventional tests, because they need specific structure causing the departure to be quantifiable in order to be computable. For example, the RESET test for detecting non-linear departures is formulated by fitting <span class="math inline">y = \tau_0 + \sum_{i=1}^{p}\tau_px_p +\gamma_1\hat{y}^2 + \gamma_2\hat{y}^3 + \gamma_3\hat{y}^4 + u, ~~u \sim N(0, \sigma_u^2)</span> in order to test <span class="math inline">H_0:\gamma_1 = \gamma_2 = \gamma_3 = 0</span> against <span class="math inline">H_a: \gamma_1 \neq 0 \text{ or } \gamma_2 \neq 0 \text{ or } \gamma_3 \neq 0</span>. Similarly, the BP test is designed to specifically test <span class="math inline">H_0:</span> <em>error variances are all equal</em> (<span class="math inline">\zeta_i=0 \text{ for } i=1,..,p</span>) versus the alternative <span class="math inline">H_a:</span> <em>that the error variances are a multiplicative function of one or more variables</em> (<span class="math inline">\text{at least one } \zeta_i\neq 0</span>) from <span class="math inline">e^2 = \zeta_0 + \sum_{i=1}^{p}\zeta_i x_i + u, ~ u\sim N(0,\sigma_u^2)</span>.</p>
<p>While a battery of conventional tests for different types of departures could be applied, this is intrinsic to the lineup protocol. The lineup protocol operates as an omnibus test, able to detect a range of departures from good residuals in a single application.</p>
</section><section id="statistical-significance" class="level3" data-number="2.3.2"><h3 data-number="2.3.2" class="anchored" data-anchor-id="statistical-significance">
<span class="header-section-number">2.3.2</span> Statistical Significance</h3>
<p>In hypothesis testing, a <span class="math inline">p</span>-value is defined as the probability of observing test results at least as extreme as the observed result assuming <span class="math inline">H_0</span> is true. Conventional hypothesis tests usually have an existing method to derive or compute the <span class="math inline">p</span>-value based on the null distribution. The method to estimate a <span class="math inline">p</span>-value for a visual test essentially follows the process detailed by <span class="citation" data-cites="vanderplas2021statistical">VanderPlas et al. (<a href="refs.html#ref-vanderplas2021statistical" role="doc-biblioref">2021</a>)</span>. Details are given in Appendix <a href="A-appA.html#sec-appendix-a-1"><span>A.1</span></a>.</p>
</section><section id="power-of-the-tests" class="level3" data-number="2.3.3"><h3 data-number="2.3.3" class="anchored" data-anchor-id="power-of-the-tests">
<span class="header-section-number">2.3.3</span> Power of the Tests</h3>
<p>The power of a model misspecification test is the probability that <span class="math inline">H_0</span> is rejected given the regression model is misspecified in a specific way. It is an important indicator when one is concerned about whether model assumptions have been violated. In practice, one might be more interested in knowing how much the residuals deviate from the model assumptions, and whether this deviation is of practical significance.</p>
<p>The power of a conventional hypothesis test is affected by both the true parameters <span class="math inline">\boldsymbol{\theta}</span> and the sample size <span class="math inline">n</span>. These two can be quantified in terms of effect size <span class="math inline">E</span> to measure the strength of the residual departures from the model assumptions. Details about the calculation of effect size are provided in <a href="#sec-effect-size"><span>Section&nbsp;2.4.2</span></a> after the introduction of the simulation model used in our experiment. The theoretical power of a test is sometimes not a trivial solution, but it can be estimated if the data generating process is known. We use a predefined model to generate a large set of simulated data under different effect sizes, and record if the conventional test rejects <span class="math inline">H_0</span>. The probability of the conventional test rejects <span class="math inline">H_0</span> is then fitted by a logistic regression formulated as</p>
<p><span id="eq-logistic-regression-1-1"><span class="math display">
Pr(\text{reject}~H_0|H_1,E) = \Lambda\left(\log\left(\frac{0.05}{0.95}\right) + \beta_1 E\right),
\tag{2.1}</span></span></p>
<p>where <span class="math inline">\Lambda(.)</span> is the standard logistic function given as <span class="math inline">\Lambda(z) = \exp(z)(1+\exp(z))^{-1}</span>. The effect size <span class="math inline">E</span> is the only predictor and the intercept is fixed to <span class="math inline">\log(0.05/0.95)</span> so that <span class="math inline">\hat{Pr}(\text{reject}~H_0|H_1,E = 0) = 0.05</span>, the desired significance level.</p>
<p>The power of a visual test on the other hand, may additionally depend on the ability of the particular participant, as the skill of each individual may affect the number of observers who identify the data plot from the lineup <span class="citation" data-cites="majumder2013validation">(<a href="refs.html#ref-majumder2013validation" role="doc-biblioref">Majumder et al. 2013b</a>)</span>. To address this issue, <span class="citation" data-cites="majumder2013validation">Majumder et al. (<a href="refs.html#ref-majumder2013validation" role="doc-biblioref">2013b</a>)</span> models the probability of participant <span class="math inline">j</span> correctly picking the data plot from lineup <span class="math inline">l</span> using a mixed-effect logistic regression, with participants treated as random effects. Then, the estimated power of a visual test evaluated by a single participant is the predicted value obtained from the mixed effects model. However, this mixed effects model does not work with scenario where participants are asked to select one or more most different plots. In this scenario, having the probability of a participant <span class="math inline">j</span> correctly picking the data plot from a lineup <span class="math inline">l</span> is insufficient to determine the power of a visual test because it does not provide information about the number of selections made by the participant for the calculation of the <span class="math inline">p</span>-value. Therefore, we directly estimate the probability of a lineup being rejected by assuming that individual skill has negligible effect on the variation of the power. This assumption essentially averages out the subject ability and helps to simplify the model structure, thereby obviating a costly large-scale experiment to estimate complex covariance matrices. The same model given in Equation <a href="#eq-logistic-regression-1-1">Equation&nbsp;<span>2.1</span></a> is applied to model the power of a visual test.</p>
<p>To study various factors contributing to the power of both tests, the same logistic regression model is fit on different subsets of the collated data grouped by levels of factors. These include the distribution of the fitted values, type of the simulation model and the shape of the residual departures.</p>
</section></section><section id="sec-experimental-design" class="level2" data-number="2.4"><h2 data-number="2.4" class="anchored" data-anchor-id="sec-experimental-design">
<span class="header-section-number">2.4</span> Experimental Design</h2>
<p>Our experiment was conducted over three data collection periods to investigate the difference between conventional hypothesis testing and visual inference in the application of linear regression diagnostics. Two types of departures, non-linearity and heteroskedasticity, were collected during data collection periods I and II. The data collection period III was designed primarily to measure human responses to null lineups so that the visual <span class="math inline">p</span>-values can be estimated. Additional lineups for both non-linearity and heteroskedasticity, using uniform fitted value distributions, were included for additional data, and to avoid participant frustration of too many difficult tasks.</p>
<p>During the experiment, every participant recruited from the Prolific crowd-sourcing platform <span class="citation" data-cites="palan2018prolific">(<a href="refs.html#ref-palan2018prolific" role="doc-biblioref">Palan and Schitter 2018</a>)</span> was presented with a block of 20 lineups. A lineup consisted of a randomly placed data plot and 19 null plots, which were all residual plots drawn with raw residuals on the y-axis and fitted values on the x-axis. An additional horizontal red line was added at <span class="math inline">y = 0</span> as a visual reference. The data in the data plot was simulated from one of two models described in <a href="#sec-simulating-departures-from-good-residuals"><span>Section&nbsp;2.4.1</span></a>, while the data of the remaining 19 null plots were generated by the residual rotation technique discussed in Section <a href="#sec-visual-test-procedure-based-on-lineups"><span>Section&nbsp;2.2.3</span></a>.</p>
<p>In each lineup evaluation, the participant was asked to select one or more plots that are most different from others, provide a reason for their selections, and evaluate how different they think the selected plots are from others. If there is no noticeable difference between plots in a lineup, participants had the option to select zero plots without the need to provide a reason. During the process of recording the responses, a zero selection was considered to be equivalent to selecting all 20 plots. No participant was shown the same lineup twice. Information about preferred pronouns, age group, education, and previous experience in visual experiments were also collected. A participant’s submission was only included in the analysis if the data plot is identified for at least one attention check.</p>
<p>Overall, we collected 7974 evaluations on 1152 unique lineups performed by 443 participants. A summary of the factors used in the experiment can be found in <a href="#tbl-model-factor-table">Table&nbsp;<span>2.2</span></a>. There were four levels of the non-linear structure, and three levels of heteroskedastic structure. The signal strength was controlled by error variance (<span class="math inline">\sigma</span>) for the non-linear pattern, and by a ratio (<span class="math inline">b</span>) parameter for the heteroskedasticity. Additionally, three levels of sample size (<span class="math inline">n</span>) and four different fitted value distributions were incorporated.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="tbl-model-factor-table" class="anchored">
<table data-quarto-postprocess="true" class="table table-sm table-striped small">
<caption>Table&nbsp;2.2: Levels of the factors used in data collection periods I, II, and III.</caption>
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th colspan="2" data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Non-linearity
</div></th>
<th colspan="2" data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Heteroskedasticity
</div></th>
<th colspan="2" data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Common
</div></th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Poly Order (j)
</div></th>
<th data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
SD (σ)
</div></th>
<th data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Shape (a)
</div></th>
<th data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Ratio (b)
</div></th>
<th data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Size (n)
</div></th>
<th data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Distribution of the fitted values
</div></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">2</td>
<td style="text-align: right;">0.25</td>
<td style="text-align: right;">-1</td>
<td style="text-align: right;">0.25</td>
<td style="text-align: right;">50</td>
<td style="text-align: center;">Uniform</td>
</tr>
<tr class="even">
<td style="text-align: right;">3</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">100</td>
<td style="text-align: center;">Normal</td>
</tr>
<tr class="odd">
<td style="text-align: right;">6</td>
<td style="text-align: right;">2.00</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">4.00</td>
<td style="text-align: right;">300</td>
<td style="text-align: center;">Skewed</td>
</tr>
<tr class="even">
<td style="text-align: right;">18</td>
<td style="text-align: right;">4.00</td>
<td style="text-align: right;"></td>
<td style="text-align: right;">16.00</td>
<td style="text-align: right;"></td>
<td style="text-align: center;">Discrete</td>
</tr>
<tr class="odd">
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;">64.00</td>
<td style="text-align: right;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<section id="sec-simulating-departures-from-good-residuals" class="level3" data-number="2.4.1"><h3 data-number="2.4.1" class="anchored" data-anchor-id="sec-simulating-departures-from-good-residuals">
<span class="header-section-number">2.4.1</span> Simulating Departures from Good Residuals</h3>
<section id="non-linearity-and-heteroskedasticity" class="level4"><h4 class="anchored" data-anchor-id="non-linearity-and-heteroskedasticity">Non-linearity and Heteroskedasticity</h4>
<p>Data collection period I was designed to study the ability of participants to detect non-linearity departures from residual plots. The non-linearity departure was constructed by omitting a <span class="math inline">j</span>th order Hermite polynomial <span class="citation" data-cites="hermite1864nouveau de1820theorie">(<a href="refs.html#ref-hermite1864nouveau" role="doc-biblioref">Hermite 1864</a>; originally by <a href="refs.html#ref-de1820theorie" role="doc-biblioref">Laplace 1820</a>)</span> term of the predictor from the simple linear regression equation. Four different values of <span class="math inline">j = 2, 3, 6, 18</span> were chosen so that distinct shapes of non-linearity were included in the residual plots. These include “U”, “S”, “M” and “triple-U” shape as shown in <a href="#fig-different-shape-of-herimite">Figure&nbsp;<span>2.3</span></a>. A greater value of <span class="math inline">j</span> will result in a curve with more turning points. It is expected that the “U” shape will be the easiest to detect, and as the shape gets more complex it will be harder to perceive in a scatterplot, particularly when there is noise. <a href="#fig-different-sigma">Figure&nbsp;<span>2.4</span></a> shows the “U” shape for different amounts of noise (<span class="math inline">\sigma</span>).</p>
<p>Data collection period II was similar to period I but focuses on heteroskedasticity departures. We generated the heteroskedasticity departures by setting the variance-covariance matrix of the error term as a function of the predictor, but fitted the data with the simple linear regression model, intentionally violated the constant variance assumption. Visual patterns of heteroskedasticity are simulated using three different shapes (<span class="math inline">a</span> = -1, 0, 1) including “left-triangle”, “butterfly” and “right-triangle” shapes as displayed in <a href="#fig-different-shape-of-heter">Figure&nbsp;<span>2.5</span></a>. <a href="#fig-different-b">Figure&nbsp;<span>2.6</span></a> shows the butterfly shape as the ratio parameter (<span class="math inline">b</span>) is changed. More details about the simulation process are provided in Appendix <a href="A-appA.html#sec-appendix-a-2"><span>A.2</span></a>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-different-shape-of-herimite" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="02-chap2_files/figure-html/fig-different-shape-of-herimite-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2.3: Polynomial forms generated for the residual plots used to assess detecting non-linearity. The four shapes are generated by varying the order of polynomial given by <span class="math inline">j</span> in <span class="math inline">He_j(.)</span>.</figcaption></figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-different-sigma" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="02-chap2_files/figure-html/fig-different-sigma-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2.4: Examining the effect of <span class="math inline">\sigma</span> on the signal strength in the non-linearity detection, for <span class="math inline">n=300</span>, uniform fitted value distribution and the “U” shape. As <span class="math inline">\sigma</span> increases the signal strength decreases, to the point that the “U” is almost unrecognisable when <span class="math inline">\sigma=4</span>.</figcaption></figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-different-shape-of-heter" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="02-chap2_files/figure-html/fig-different-shape-of-heter-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2.5: Heteroskedasticity forms used in the experiment. Three different shapes (<span class="math inline">a = -1, 0, 1</span>) are used in the experiment to create “left-triangle”, “butterfly” and “right-triangle” shapes, respectively.</figcaption></figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-different-b" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="02-chap2_files/figure-html/fig-different-b-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2.6: Five different values of <span class="math inline">b</span> are used in heteroskedasticity simulation to control the strength of the signal. Larger values of <span class="math inline">b</span> yield a bigger difference in variation, and thus stronger heteroskedasticity signal.</figcaption></figure>
</div>
</div>
</div>
</section><section id="factors-common-to-both-data-collection-periods" class="level4"><h4 class="anchored" data-anchor-id="factors-common-to-both-data-collection-periods">Factors Common to both Data Collection Periods</h4>
<p>Fitted values are a function of the independent variables (or predictors), and the distribution of the observed values affects the distribution of the fitted values. Ideally, we would want the fitted values to have a uniform coverage across the range of observed values or have a uniform distribution across all of the predictors. This is not always present in the collected data. Sometimes the fitted values are discrete because one or more predictors were measured discretely. It is also common to see a skewed distribution of fitted values if one or more of the predictors has a skewed distribution. This latter problem is usually corrected before modelling, using a variable transformation. Our simulation assess this by using four different distributions to represent fitted values, constructed by different sampling of the predictor, including <span class="math inline">U(-1, 1)</span> (uniform), <span class="math inline">N(0, 0.3^2)</span> (normal), <span class="math inline">\text{lognormal}(0, 0.6^2)/3</span> (skewed) and <span class="math inline">U\{-1, 1\}</span> (discrete).</p>
<p><a href="#fig-different-dist">Figure&nbsp;<span>2.7</span></a> shows the non-linear pattern, a “U” shape, with the different fitted value distributions. We would expect that structure in residual plots would be easier to perceive when the fitted values are uniformly distributed.</p>
<p>Three different sample sizes were used in our experiment: <span class="math inline">n = 50, 100, 300</span>. <a href="#fig-different-n">Figure&nbsp;<span>2.8</span></a> shows the non-linear “S” shape for different sample sizes. We expect signal strength to decline in the simulated data plots with smaller <span class="math inline">n</span>. We chose 300 as the upper limit, because it is typically enough for structure to be visible in a scatterplot reliably. Beyond 300, the scatterplot should probably be used with transparency or replaced with a density or binned plot as scatterplots suffer from over-plotting.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-different-dist" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="02-chap2_files/figure-html/fig-different-dist-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2.7: Variations in fitted values, that might affect perception of residual plots. Four different distributions are used.</figcaption></figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-different-n" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="02-chap2_files/figure-html/fig-different-n-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2.8: Examining the effect of signal strength for the three different values of <span class="math inline">n</span> used in the experiment, for non-linear structure with fixed <span class="math inline">\sigma = 1.5</span>, uniform fitted value distribution, and “S” shape. For these factor levels, only when <span class="math inline">n = 300</span> is the “S” shape clearly visible.</figcaption></figure>
</div>
</div>
</div>
</section></section><section id="sec-effect-size" class="level3" data-number="2.4.2"><h3 data-number="2.4.2" class="anchored" data-anchor-id="sec-effect-size">
<span class="header-section-number">2.4.2</span> Effect Size</h3>
<p>The lineups are allocated to participants in a manner that uniformly covers the combination of experimental factors in <a href="#tbl-model-factor-table">Table&nbsp;<span>2.2</span></a>. In addition, we use effect size to measure the signal strength, which helps in assigning a set of lineups with a range of difficulties to each participant.</p>
<p>Effect size in statistics measures the strength of the signal relative to the noise. It is surprisingly difficult to quantify, even for simulated data as used in this experiment.</p>
<p>For the non-linearity model, the key items defining effect size are sample size (<span class="math inline">n</span>) and the noise level (<span class="math inline">\sigma^2</span>), and so effect size would be roughly calculated as <span class="math inline">\sqrt{n}/{\sigma}</span>. Increasing sample size tends to boost the effect size, while heightened noise diminishes it. However, it is not clear how the additional parameter for the model polynomial order, <span class="math inline">j</span>, should be incorporated. Intuitively, the large <span class="math inline">j</span> means more complex pattern, which likely means effect size would decrease. Similarly, in the heteroskedasticity model, effect size relies on sample size (<span class="math inline">n</span>) and the ratio of the largest to smallest variance, <span class="math inline">b</span>. Larger values of both would produce higher effect size, but the role of the additional shape parameter, <span class="math inline">a</span>, in this context is unclear.</p>
<p>For the purposes of our calculations we have chosen to use an approach based on Kullback-Leibler divergence <span class="citation" data-cites="kullback1951information">(<a href="refs.html#ref-kullback1951information" role="doc-biblioref">Kullback and Leibler 1951</a>)</span>. This formulation defines effect size to be</p>
<p><span class="math display">E = \frac{1}{2}\left(\log\frac{|\text{diag}(\boldsymbol{R}\boldsymbol{V}\boldsymbol{R}')|}{|\text{diag}(\boldsymbol{R}\sigma^2)|} - n + \text{tr}(\text{diag}(\boldsymbol{R}\boldsymbol{V}\boldsymbol{R}')^{-1}\text{diag}(\boldsymbol{R}\sigma^2)) + \boldsymbol{\mu}_z'(\boldsymbol{R}\boldsymbol{V}\boldsymbol{R}')^{-1}\boldsymbol{\mu}_z\right),</span></p>
<p>where <span class="math inline">\text{diag}(.)</span> is the diagonal matrix constructed from the diagonal elements of a matrix, <span class="math inline">\boldsymbol{X}</span> is the design matrix, <span class="math inline">\boldsymbol{V}</span> is the actual covariance matrix of the error term, <span class="math inline">\boldsymbol{R} = \boldsymbol{I}_n - \boldsymbol{X}(\boldsymbol{X}'\boldsymbol{X})^{-1}\boldsymbol{X}'</span> is the residual operator, <span class="math inline">\boldsymbol{\mu}_z = \boldsymbol{R}\boldsymbol{Z}\boldsymbol{\beta}_z</span> is the expected values of residuals where <span class="math inline">\boldsymbol{Z}</span> contains any higher order terms of <span class="math inline">\boldsymbol{X}</span> left out of the regression equation, <span class="math inline">\boldsymbol{\beta}_z</span> contains the corresponding coefficients, and <span class="math inline">\sigma^2\boldsymbol{I}_n</span> is the assumed covariance matrix of the error term when <span class="math inline">H_0</span> is true. More details about the effect size derivation are provided in Appendix <a href="A-appA.html#sec-appendix-a-1"><span>A.1</span></a>.</p>
</section></section><section id="sec-results" class="level2" data-number="2.5"><h2 data-number="2.5" class="anchored" data-anchor-id="sec-results">
<span class="header-section-number">2.5</span> Results</h2>
<p>Data collection used a total of 1152 lineups, and resulted in a total of 7974 evaluations from 443 participants. Roughly half corresponded to the two models, non-linearity and heteroskedasticiy, and the three collection periods had similar numbers of evaluations. Each participant received two of the 24 attention check lineups which were used to filter results of participants who were clearly not making an honest effort (only 11 of 454). To estimate <span class="math inline">\alpha</span> for calculating statistical significance (see Appendix <a href="A-appA.html#sec-appendix-a-1"><span>A.1</span></a>) there were 720 evaluations of 36 null lineups. Neither the attention checks nor null lineups were used in the subsequent analysis. The de-identified data, <code>vi_survey</code>, is made available in the R package, <code>visage</code>.</p>
<p>The data was collected on lineups constructed from four different fitted value distributions that stem from the corresponding predictor distribution: uniform, normal, skewed and discrete. Henceforth, we refer to these four different fitted value distributions with respect to their predictor distribution. More data was collected on the uniform distribution (each evaluated by 11 participants) than the others (each evaluated by 5 participants). The analysis in <a href="#sec-power-analysis"><span>Section&nbsp;2.5.1</span></a>–<a href="#sec-hetero-analysis"><span>Section&nbsp;2.5.4</span></a> uses only results from lineups with uniform distribution, for a total 3069 lineup evaluations. This allows us to compare the conventional and visual test performance in an optimal scenario. <a href="#sec-effect-of-fitted-value-distributions"><span>Section&nbsp;2.5.5</span></a> examines how the results may be affected if the fitted value distribution was different.</p>
<section id="sec-power-analysis" class="level3" data-number="2.5.1"><h3 data-number="2.5.1" class="anchored" data-anchor-id="sec-power-analysis">
<span class="header-section-number">2.5.1</span> Power Comparison of the Tests</h3>
<p><a href="#fig-nonlinearheterpower">Figure&nbsp;<span>2.9</span></a> present the power curves of various tests plotted against the effect size in the residuals for non-linearity and heteroskedasticity. In each case the power of visual test is calculated for multiple bootstrap samples leading to the many (solid orange) curves. The effect size was computed at a 5% significance level and plotted on a natural logarithmic scale. To facilitate visual calibration of effect size values with the corresponding diagnostic plots, a sequence of example residual plots with increasing effect sizes is provided at the bottom of these figures. These plots serve as a visual aid to help readers understand how different effect size values translate to changes in the diagnostic plots. The horizontal lines of dots at 0 and 1 represent the non-rejection or rejection decisions made by visual tests for each lineup.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-nonlinearheterpower" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="02-chap2_files/figure-html/fig-nonlinearheterpower-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2.9: Comparison of power between different tests for (A) non-linear and (B) heteroskedasticity patterns (uniform fitted values only). Main plot shows the power curves, with dots indicating non-reject and reject in visual testing of lineups. The multiple lines for the visual test arise from estimating the power on many bootstrap samples. The row of scatterplots at the bottom are examples of residual plots corresponding to the specific effect sizes marked by vertical lines in the main plot.</figcaption></figure>
</div>
</div>
</div>
<p><a href="#fig-nonlinearheterpower">Figure&nbsp;<span>2.9</span></a>A compares the power for the different tests for non-linear structure in the residuals. The test with the uniformly higher power is the RESET test, one that specifically tests for non-linearity. Note that the BP and SW tests have much lower power, which is expected because they are not designed to detect non-linearity. The bootstrapped power curves for the visual test are effectively a right shift from that of the RESET test. This means that the RESET test will reject at a lower effect size (less structure) than the visual test, but otherwise the performance will be similar. In other words, the RESET test is more sensitive than the visual test. This is not necessarily a good feature for the purposes of diagnosing model defects: if we scan the residual plot examples at the bottom, we might argue that the non-linearity is not sufficiently problematic until an effect size of around 3 or 3.5. The RESET test would reject closer to an effect size of 2, but the visual test would reject closer to 3.25, for a significance level of 0.05. The visual test matches the robustness of the model to (minor) violations of assumptions much better.</p>
<p>For the heteroskedasticity pattern, the power of BP test, designed for detecting heteroskedasticity, is uniformly higher than the other tests. The visual test power curve shifts to the right. This shows a similar story to the power curves for non-linearity pattern: the conventional test is more sensitive than the visual test. From the example residual plots at the bottom we might argue that the heteroskedasticity becomes noticeably visible around an effect size of 3 or 3.5. However the BP test would reject at around effect size 2.5. Interestingly, the power curve for the SW test (for non-normality) is only slightly different to that of the visual test, suggesting that it performs reasonably well for detecting heteroskedasticity, too. The power curve for the BP test suggests it is not useful for detecting heteroskedasticity, as expected.</p>
<p>Overall, the results show that the conventional tests are more sensitive than the visual test. The conventional tests do have higher power for the patterns they are designed to detect, but they typically fail to detect other patterns unless those patterns are particularly strong. The visual test does not require specifying the pattern ahead of time, relying purely on whether the observed residual plot is detectably different from “good” residual plots. They will perform equally well regardless of the type of model defect. This aligns with the advice of experts on residual analysis, who consider residual plot analysis to be an indispensable tool for diagnosing model problems. What we gain from using a visual test for this purpose is the removal of any subjective arguments about whether a pattern is visible or not. The lineup protocol provides the calibration for detecting patterns: if the pattern in the data plot cannot be distinguished from the patterns in good residual plots, then no discernible problem with the model exists.</p>
</section><section id="sec-p-value" class="level3" data-number="2.5.2"><h3 data-number="2.5.2" class="anchored" data-anchor-id="sec-p-value">
<span class="header-section-number">2.5.2</span> Comparison of Test Decisions Based on <span class="math inline">p</span>-values</h3>
<p>The power comparison demonstrates that the appropriate conventional tests will reject more aggressively than visual tests, but we do not know how the decisions for each lineup would agree or disagree. Here we compare the reject or fail to reject decisions of these tests, across all the lineups. <a href="#fig-p-value-comparison">Figure&nbsp;<span>2.10</span></a> shows the agreement of the conventional and visual tests using a mosaic plot for both non-linearity patterns and heteroskedasticity patterns. For both patterns the lineups resulting in a rejection by the visual test are <em>all</em> also rejected by the conventional test, except for one from the heteroskedasticity model. This reflects exactly the story from the previous section, that the conventional tests reject more aggressively than the visual test.</p>
<p>For non-linearity lineups, conventional tests and visual tests reject 69% and 32% of the time, respectively. Of the lineups rejected by the conventional test, 46% are rejected by the visual test, that is, approximately half as many as the conventional test. There are no lineups that are rejected by the visual test but not by the conventional test.</p>
<p>In heteroskedasticity lineups, 76% are rejected by conventional tests, while 56% are rejected by visual tests. Of the lineups rejected by the conventional test, the visual test rejects more than two-thirds of them, too.</p>
<p>Surprisingly, the visual test rejects 1 of the 33 (3%) of lineups where the conventional test does not reject. <a href="#fig-heter-example">Figure&nbsp;<span>2.11</span></a> shows this lineup. The data plot in position seventeen displays a relatively strong heteroskedasticity pattern, and has a strong effect size (<span class="math inline">\log_e(E)=4.02</span>), which is reflected by the visual test <span class="math inline">p\text{-value} = 0.026</span>. But the BP test <span class="math inline">p\text{-value} = 0.056</span>, is slightly above the significance cutoff of <span class="math inline">0.05</span>. This lineup was evaluated by 11 participants, it has experimental factors <span class="math inline">a = 0</span> (“butterfly” shape), <span class="math inline">b = 64</span> (large variance ratio), <span class="math inline">n = 50</span> (small sample size), and a uniform distribution for the predictor. It may have been the small sample size and the presence of a few outliers that may have resulted in the lack of detection by the conventional test.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-p-value-comparison" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="02-chap2_files/figure-html/fig-p-value-comparison-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2.10: Rejection rate (<span class="math inline">p</span>-value <span class="math inline">\leq0.05</span>) of visual test conditional on the conventional test decision on non-linearity (left) and heteroskedasticity (right) lineups (uniform fitted values only) displayed using a mosaic plot. The visual test rejects less frequently than the conventional test, and (almost) only rejects when the conventional test does. Surprisingly, one lineup in the heteroskedasticity group is rejected by the visual test but NOT the conventional test.</figcaption></figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-heter-example" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="02-chap2_files/figure-html/fig-heter-example-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2.11: The single heteroskedasticity lineup that is rejected by the visual test but not by the BP test. The data plot (position 17) contains a “butterfly” shape. It visibly displays heteroskedasticity, making it somewhat surprising that it is not detected by the BP test.</figcaption></figure>
</div>
</div>
</div>
<p>Because the power curve of the visual tests are a shift to the right of the conventional test (<a href="#fig-nonlinearheterpower">Figure&nbsp;<span>2.9</span></a>) we examined whether adjusting the significance level (to .001, .0001, .00001, …) of the conventional test would generate similar decisions to that of the visual test. Interestingly, it does not: despite resulting in less rejections, neither the RESET or BP tests come to complete agreement with the visual test (see Appendix <a href="A-appA.html#sec-appendix-a-1"><span>A.1</span></a>).</p>
</section><section id="sec-nonlin-analysis" class="level3" data-number="2.5.3"><h3 data-number="2.5.3" class="anchored" data-anchor-id="sec-nonlin-analysis">
<span class="header-section-number">2.5.3</span> Effect of Amount of Non-linearity</h3>
<p>The order of the polynomial is a primary factor contributing to the pattern produced by the non-linearity model. <a href="#fig-poly-power-uniform-j">Figure&nbsp;<span>2.12</span></a> explores the relationship between polynomial order and power of the tests. The conventional tests have higher power for lower orders of Hermite polynomials, and the power drops substantially for the “triple-U” shape. To understand why this is, we return to the application of the RESET test, which requires a parameter indicating degree of fitted values to test for, and the recommendation is to generically use four <span class="citation" data-cites="ramsey1969tests">(<a href="refs.html#ref-ramsey1969tests" role="doc-biblioref">Ramsey 1969</a>)</span>. However, the “triple-U” shape is constructed from the Hermite polynomials using power up to 18. If the RESET test had been applied using a higher power of no less than six, the power curve of “triple-U” shape will be closer to other power curves. This illustrates the sensitivity of the conventional test to the parameter choice, and highlights a limitation: it helps to know the data generating process to set the parameters for the test, which is unrealistic in practice. However, we examined this in more detail (see Appendix <a href="A-appA.html#sec-appendix-a-1"><span>A.1</span></a>) and found that there is no harm in setting the parameter higher than four on the tests’ operation for lower order polynomial shapes. Using a parameter value of six, instead of four, yields higher power regardless of generating process, and is recommended.</p>
<p>For visual tests, we expect the “U” shape to be detected more readily, followed by the “S”, “M” and “triple-U” shape. From <a href="#fig-poly-power-uniform-j">Figure&nbsp;<span>2.12</span></a>, it can be observed that the power curves mostly align with these expectations, except for the “M” shape, which is as easily detected as the “S” shape. This suggests a benefit of the visual test: knowing the shape ahead of time is <em>not</em> needed for its application.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-poly-power-uniform-j" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="02-chap2_files/figure-html/fig-poly-power-uniform-j-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2.12: The effect of the order of the polynomial on the power of conventional and visual tests. Deeper colour indicates higher order. The default RESET tests under-performs significantly in detecting the “triple-U” shape. To achieve a similar power as other shapes, a higher order polynomial parameter needs to be used for the RESET test, but this higher than the recommended value.</figcaption></figure>
</div>
</div>
</div>
</section><section id="sec-hetero-analysis" class="level3" data-number="2.5.4"><h3 data-number="2.5.4" class="anchored" data-anchor-id="sec-hetero-analysis">
<span class="header-section-number">2.5.4</span> Effect of Shape of Heteroskedasticity</h3>
<p><a href="#fig-heter-power-uniform-a">Figure&nbsp;<span>2.13</span></a> examines the impact of the shape of the heteroskedasticity on the power of of both tests. The butterfly shape has higher power on both types of tests. The “left-triangle” and the “right-triangle” shapes are functionally identical, and this is observed for the conventional test, where the power curves are identical. Interestingly there is a difference for the visual test: the power curve of the “left-triangle” shape is slightly higher than that of the “right-triangle” shape. This indicates a bias in perceiving heteroskedasticity depending on the direction, and may be worth investigating further.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-heter-power-uniform-a" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="02-chap2_files/figure-html/fig-heter-power-uniform-a-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2.13: The effect of heteroskedasticity shape (parameter <span class="math inline">a</span>) on the power of conventional and visual tests. The butterfly has higher power in both tests. Curiously, the visual test has a slightly higher power for the <code>left-triangle" than the</code>right-triangle” shape, when it would be expected that they should be similar, which is observed in conventional testing.</figcaption></figure>
</div>
</div>
</div>
</section><section id="sec-effect-of-fitted-value-distributions" class="level3" data-number="2.5.5"><h3 data-number="2.5.5" class="anchored" data-anchor-id="sec-effect-of-fitted-value-distributions">
<span class="header-section-number">2.5.5</span> Effect of Fitted Value Distributions</h3>
<p>In regression analysis, predictions are conditional on the observed values of the predictors, that is, the conditional mean of the dependent variable <span class="math inline">Y</span> given the value of the independent variable <span class="math inline">X</span>, <span class="math inline">\text{E}(Y|X)</span>. This is an often forgotten element of regression analysis but it is important. Where <span class="math inline">X</span> is observed, the distribution of the <span class="math inline">X</span> values in the sample, or consequently <span class="math inline">\hat{Y}</span>, may affect the ability to read any patterns in the residual plots. The effect of fitted value distribution on test performance is assess using four different distributions of fitted values stemming from the predictor distributions: uniform, normal, discrete and lognormal (skewed). We expect that if all predictors have a uniform distribution, it is easier to read the relationship with the residuals.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-different-x-dist-poly-power" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="02-chap2_files/figure-html/fig-different-x-dist-poly-power-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2.14: Comparison of power on lineups with different fitted value distributions for conventional and visual tests (columns) for non-linearity and heteroskedasticity patterns (rows). The power curves of conventional tests for non-linearity and heteroskedasticity patterns are produced by RESET tests and BP tests, respectively. Power curves of visual tests are estimated using five evaluations on each lineup. For lineups with a uniform fitted value distribution, the five evaluations are repeatedly sampled from the total eleven evaluations to give multiple power curves (solid grey). Surprisingly, the fitted value distribution has produces more variability in the power of conventional tests than visual tests. Uneven distributions, normal and skewed distributions, tend to yield lower power.</figcaption></figure>
</div>
</div>
</div>
<p><a href="#fig-different-x-dist-poly-power">Figure&nbsp;<span>2.14</span></a> examines the impact of the fitted value distribution on the power of conventional (left) and visual (right) tests for both the non-linearity (top) and heteroskedasticity (bottom) patterns. For conventional tests, only the power curves of appropriate tests are shown: RESET tests for non-linearity and BP tests for heteroskedasticity. For visual tests, more evaluations on lineups with uniform fitted value distribution were collected, so to have a fair comparison, we randomly sample five from the 11 total evaluations to estimate the power curves, producing the multiple curves for the uniform condition, and providing an indication of the variability in the power estimates.</p>
<p>Perhaps surprisingly, the visual tests have more consistent power across the different fitted value distributions: for the non-linear pattern, there is almost no power difference, and for the heteroskedastic pattern, uniform and discrete have higher power than normal and skewed. The likely reason is that these latter two have fewer observations in the tails where the heteroskedastic pattern needs to be detected.</p>
<p>The variation in power in the conventional tests is at first sight, shocking. However, it is discussed, albeit rarely, in the testing literature. See, for example, <span class="citation" data-cites="jamshidian2007study">Jamshidian et al. (<a href="refs.html#ref-jamshidian2007study" role="doc-biblioref">2007</a>)</span>, <span class="citation" data-cites="olvera2019relationship">Olvera Astivia et al. (<a href="refs.html#ref-olvera2019relationship" role="doc-biblioref">2019</a>)</span> and <span class="citation" data-cites="zhang2018practical">Zhang and Yuan (<a href="refs.html#ref-zhang2018practical" role="doc-biblioref">2018</a>)</span> which show derivations and use simulation to assess the effect of the observed distribution of the predictors on test power. The big differences in the power curves seen in <a href="#fig-different-x-dist-poly-power">Figure&nbsp;<span>2.14</span></a> is echoed in the results reported in these articles.</p>
</section></section><section id="limitations-and-practicality" class="level1" data-number="3"><h1 data-number="3">
<span class="header-section-number">3</span> Limitations and Practicality</h1>
<p>One of the primary limitations of the lineup protocol lies in its reliance on human judgements. In this context, the effectiveness of a single lineup evaluation can be dependent on the perceptual ability and visual skills of the individual. However, when results from multiple individuals are combined the outcome is encouragingly high-quality and robust. For simple plots and strong patterns just a few individuals are needed to arrive at a clear answer, but more individuals will be needed when the plot design is complex, or the signal strength is weak.</p>
<p>Using a lineup protocol removes subjectiveness in interpreting patterns in plots. A plot is compared with draws from a null model, in much the same way as a test statistic is compared to its sampling distribution. It is important to remove plot elements that might introduce bias, such as axis labels, text and legends, or to make them generic.</p>
<p>The lineup protocol can be used cheaply and informally with the R package <code>nullabor</code>. There is evidence that it is being used fairly broadly, based on software download rates and citations of the original papers. For residual plot analysis we recommend that the lineup be the default first plot so that the data plot is only seen in the context of null plots. When a rigorous test is needed, we recommend using a crowd-sourcing service, as done in gene expression experiment described in <span class="citation" data-cites="RNAseq2013">Yin et al. (<a href="refs.html#ref-RNAseq2013" role="doc-biblioref">2013</a>)</span>. While it takes extra effort it is not difficult today, and costs are tiny compared to the overall costs of conducting a scientific experiment. We do also expect that at some point a computer vision model can be developed to take over the task of employing people to evaluate residual plots.</p>
<p>For this study, simulated data was used to provide a precisely controlled environment within which to compare results from conventional testing to those from visual testing. We also explored only the most commonly used, the residual vs fitted value plots. However, we expect the behaviour of the conventional test and the visual test to be similar when observed residuals are diagnosed with this type of plot or other residual plots. The conventional tests will be more sensitive to small departures from the null. They will also fail to detect departures when residuals have some contamination, like outliers or anomalies, as is often encountered when working with data. The lineup approach is well-suited for generally interpreting data plots, and also detecting unexpected patterns not related to the model. This is supported by earlier research <span class="citation" data-cites="loy2016variations loy2015you roy2015using VanderPlas2015 wickham2010">(e.g. <a href="refs.html#ref-loy2016variations" role="doc-biblioref">Loy et al. 2016</a>; <a href="refs.html#ref-loy2015you" role="doc-biblioref">Loy and Hofmann 2015</a>; <a href="refs.html#ref-roy2015using" role="doc-biblioref">Roy Chowdhury et al. 2015</a>; <a href="refs.html#ref-VanderPlas2015" role="doc-biblioref">VanderPlas and Hofmann 2016</a>; <a href="refs.html#ref-wickham2010" role="doc-biblioref">Wickham et al. 2010</a>)</span>.</p>
</section><section id="conclusions" class="level1" data-number="4"><h1 data-number="4">
<span class="header-section-number">4</span> Conclusions</h1>
<p>This paper has described experimental evidence providing support for the advice of regression analysis experts <em>that residual plots are indispensable methods for assessing model fit</em>, using the formal framework of the lineup protocol. We conducted a perceptual experiment on scatterplots of residuals vs fitted values, with two primary departures from good residuals: non-linearity and heteroskedasticity. We found that conventional residual-based statistical tests are more sensitive to weak departures from model assumptions than visual tests. That is, a conventional test concludes there are problems with the model fit almost twice as often as a human. Conventional tests often reject the null hypothesis when departures in the form of non-linearity and heteroskedasticity are not visibly different from null residual plots.</p>
<p>While it might be argued that the conventional tests are correctly detecting small but real effects, this can also be seen as the conventional tests are rejecting unnecessarily. Many of these rejections happen even when downstream analysis and results would not be significantly affected by the small departures from a good fit. The results from human evaluations provide a more practical solution, which reinforces the statements from regression experts that residual plots are an indispensable method for model diagnostics. Further work would be needed to <em>quantify</em> how much departure from good residuals is too much.</p>
<p>It is important to emphasize that this work also supports a change in common practice, which is to deliver residual plots as a lineup, embedded in a field of null plots, rather than be viewed out of context. A residual plot may contain many visual features, but some are caused by the characteristics of the predictors and the randomness of the error, not by the violation of the model assumptions. These irrelevant visual features have a chance to be filtered out by participants with a comparison to null plots, resulting in more accurate reading. The lineup enables a careful calibration for reading structure in residual plots, and also provides the potential to discover interesting and important features in the data not directly connected to linear model assumptions.</p>
<p>Human evaluation of residuals is expensive, time-consuming and laborious. This is possibly why residual plot analysis is often not done in practice. However, with the emergence of effective computer vision, it is hoped this work helps to lay the foundation for automated residual plot assessment.</p>
<p>The experiment also revealed some interesting results. For the most part, the visual test performed similarly to the appropriate conventional test with a shift in the power curve. Unlike conventional tests, where one needs to specifically test for non-linearity or heteroskedasticity the visual test operated effectively across the range of departures from good residuals. If the fitted value distribution is not uniform, there is a small loss of power in the visual test. Surprisingly, there is a big difference in power of the conventional test across fitted value distributions. Another unexpected finding was that the direction of heteroskedasticity appears to affect the ability to visually detect it: both triangles being more difficult to detect than the butterfly, and a small difference in detection between left- and right-triangle.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-box1976science" class="csl-entry" role="listitem">
Box, G. E. (1976), <span>“Science and statistics,”</span> <em>Journal of the American Statistical Association</em>, Taylor &amp; Francis, 71, 791–799.
</div>
<div id="ref-breusch1979simple" class="csl-entry" role="listitem">
Breusch, T. S., and Pagan, A. R. (1979), <span>“A simple test for heteroscedasticity and random coefficient variation,”</span> <em>Econometrica: Journal of the Econometric Society</em>, JSTOR, 1287–1294.
</div>
<div id="ref-buja2009statistical" class="csl-entry" role="listitem">
Buja, A., Cook, D., Hofmann, H., Lawrence, M., Lee, E.-K., Swayne, D. F., and Wickham, H. (2009b), <span>“Statistical inference for exploratory data analysis and model diagnostics,”</span> <em>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</em>, The Royal Society Publishing, 367, 4361–4383.
</div>
<div id="ref-bujastatistical2009" class="csl-entry" role="listitem">
Buja, A., Cook, D., Hofmann, H., Lawrence, M., Lee, E.-K., Swayne, D. F., and Wickham, H. (2009a), <span>“Statistical inference for exploratory data analysis and model diagnostics,”</span> <em>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</em>, 367, 4361–4383. <a href="https://doi.org/10.1098/rsta.2009.0120">https://doi.org/10.1098/rsta.2009.0120</a>.
</div>
<div id="ref-cleveland1984graphical" class="csl-entry" role="listitem">
Cleveland, W. S., and McGill, R. (1984), <span>“Graphical perception: Theory, experimentation, and application to the development of graphical methods,”</span> <em>Journal of the American Statistical Association</em>, Taylor &amp; Francis, 79, 531–554.
</div>
<div id="ref-cook1982residuals" class="csl-entry" role="listitem">
Cook, R. D., and Weisberg, S. (1982), <em>Residuals and influence in regression</em>, New York: Chapman; Hall.
</div>
<div id="ref-cook1999applied" class="csl-entry" role="listitem">
Cook, R. D., and Weisberg, S. (1999), <em>Applied regression including computing and graphics</em>, John Wiley &amp; Sons.
</div>
<div id="ref-draper1998applied" class="csl-entry" role="listitem">
Draper, N. R., and Smith, H. (1998), <em>Applied regression analysis</em>, John Wiley &amp; Sons.
</div>
<div id="ref-skedastic" class="csl-entry" role="listitem">
Farrar, T. J. (2020), <em>Skedastic: Heteroskedasticity diagnostics for linear regression models</em>, Bellville, South Africa: University of the Western Cape.
</div>
<div id="ref-hermite1864nouveau" class="csl-entry" role="listitem">
Hermite, M. (1864), <em>Sur un nouveau d<span>é</span>veloppement en s<span>é</span>rie des fonctions</em>, Imprimerie de Gauthier-Villars.
</div>
<div id="ref-jamshidian2007study" class="csl-entry" role="listitem">
Jamshidian, M., Jennrich, R. I., and Liu, W. (2007), <span>“A study of partial f tests for multiple linear regression models,”</span> <em>Computational Statistics &amp; Data Analysis</em>, Elsevier, 51, 6269–6284.
</div>
<div id="ref-jarque1980efficient" class="csl-entry" role="listitem">
Jarque, C. M., and Bera, A. K. (1980), <span>“Efficient tests for normality, homoscedasticity and serial independence of regression residuals,”</span> <em>Economics Letters</em>, Elsevier, 6, 255–259.
</div>
<div id="ref-kahneman2011thinking" class="csl-entry" role="listitem">
Kahneman, D. (2011), <em>Thinking, fast and slow</em>, macmillan.
</div>
<div id="ref-kimball1957errors" class="csl-entry" role="listitem">
Kimball, A. (1957), <span>“Errors of the third kind in statistical consulting,”</span> <em>Journal of the American Statistical Association</em>, Taylor &amp; Francis, 52, 133–142.
</div>
<div id="ref-kirk1996practical" class="csl-entry" role="listitem">
Kirk, R. E. (1996), <span>“Practical significance: A concept whose time has come,”</span> <em>Educational and psychological measurement</em>, Sage Publications Sage CA: Thousand Oaks, CA, 56, 746–759.
</div>
<div id="ref-kullback1951information" class="csl-entry" role="listitem">
Kullback, S., and Leibler, R. A. (1951), <span>“On information and sufficiency,”</span> <em>The Annals of Mathematical Statistics</em>, JSTOR, 22, 79–86.
</div>
<div id="ref-de1820theorie" class="csl-entry" role="listitem">
Laplace, P.-S. (1820), <em>Th<span>é</span>orie analytique des probabilit<span>é</span>s</em>, Courcier.
</div>
<div id="ref-loy2021bringing" class="csl-entry" role="listitem">
Loy, A. (2021), <span>“Bringing visual inference to the classroom,”</span> <em>Journal of Statistics and Data Science Education</em>, Taylor &amp; Francis, 29, 171–182.
</div>
<div id="ref-loy2016variations" class="csl-entry" role="listitem">
Loy, A., Follett, L., and Hofmann, H. (2016), <span>“Variations of q–q plots: The power of our eyes!”</span> <em>The American Statistician</em>, Taylor &amp; Francis, 70, 202–214.
</div>
<div id="ref-loy2013diagnostic" class="csl-entry" role="listitem">
Loy, A., and Hofmann, H. (2013), <span>“Diagnostic tools for hierarchical linear models,”</span> <em>Wiley Interdisciplinary Reviews: Computational Statistics</em>, Wiley Online Library, 5, 48–61.
</div>
<div id="ref-loy2014hlmdiag" class="csl-entry" role="listitem">
Loy, A., and Hofmann, H. (2014), <span>“HLMdiag: A suite of diagnostics for hierarchical linear models in r,”</span> <em>Journal of Statistical Software</em>, 56, 1–28.
</div>
<div id="ref-loy2015you" class="csl-entry" role="listitem">
Loy, A., and Hofmann, H. (2015), <span>“Are you normal? The problem of confounded residual structures in hierarchical linear models,”</span> <em>Journal of Computational and Graphical Statistics</em>, Taylor &amp; Francis, 24, 1191–1209.
</div>
<div id="ref-majumder2013validation" class="csl-entry" role="listitem">
Majumder, M., Hofmann, H., and Cook, D. (2013b), <span>“Validation of visual statistical inference, applied to linear models,”</span> <em>Journal of the American Statistical Association</em>, Taylor &amp; Francis, 108, 942–956.
</div>
<div id="ref-majumdervalidation2013" class="csl-entry" role="listitem">
Majumder, M., Hofmann, H., and Cook, D. (2013a), <span>“Validation of visual statistical inference, applied to linear models,”</span> <em>Journal of the American Statistical Association</em>, 108, 942–956. <a href="https://doi.org/10.1080/01621459.2013.808157">https://doi.org/10.1080/01621459.2013.808157</a>.
</div>
<div id="ref-montgomery1982introduction" class="csl-entry" role="listitem">
Montgomery, D. C., Peck, E. A., and Vining, G. G. (1982), <em>Introduction to linear regression analysis</em>, John Wiley &amp; Sons.
</div>
<div id="ref-olvera2019relationship" class="csl-entry" role="listitem">
Olvera Astivia, O. L., Gadermann, A., and Guhn, M. (2019), <span>“The relationship between statistical power and predictor distribution in multilevel logistic regression: A simulation-based approach,”</span> <em>BMC Medical Research Methodology</em>, BioMed Central, 19, 1–20.
</div>
<div id="ref-palan2018prolific" class="csl-entry" role="listitem">
Palan, S., and Schitter, C. (2018), <span>“Prolific. Ac—a subject pool for online experiments,”</span> <em>Journal of Behavioral and Experimental Finance</em>, Elsevier, 17, 22–27.
</div>
<div id="ref-ramsey1969tests" class="csl-entry" role="listitem">
Ramsey, J. B. (1969), <span>“Tests for specification errors in classical linear least-squares regression analysis,”</span> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>, Wiley Online Library, 31, 350–371.
</div>
<div id="ref-roy2015using" class="csl-entry" role="listitem">
Roy Chowdhury, N., Cook, D., Hofmann, H., Majumder, M., Lee, E.-K., and Toth, A. L. (2015), <span>“Using visual statistical inference to better understand random class separations in high dimension, low sample size data,”</span> <em>Computational Statistics</em>, Springer, 30, 293–316. <a href="https://doi.org/10.1007/s00180-014-0534-x">https://doi.org/10.1007/s00180-014-0534-x</a>.
</div>
<div id="ref-shapiro1965analysis" class="csl-entry" role="listitem">
Shapiro, S. S., and Wilk, M. B. (1965), <span>“An analysis of variance test for normality (complete samples),”</span> <em>Biometrika</em>, JSTOR, 52, 591–611.
</div>
<div id="ref-silvey1959lagrangian" class="csl-entry" role="listitem">
Silvey, S. D. (1959), <span>“The lagrangian multiplier test,”</span> <em>The Annals of Mathematical Statistics</em>, JSTOR, 30, 389–407.
</div>
<div id="ref-VanderPlas2015" class="csl-entry" role="listitem">
VanderPlas, S., and Hofmann, H. (2016), <span>“Spatial reasoning and data displays,”</span> <em>IEEE Transactions on Visualization and Computer Graphics</em>, 22, 459–468. <a href="https://doi.org/10.1109/TVCG.2015.2469125">https://doi.org/10.1109/TVCG.2015.2469125</a>.
</div>
<div id="ref-vanderplas2021statistical" class="csl-entry" role="listitem">
VanderPlas, S., Röttger, C., Cook, D., and Hofmann, H. (2021), <span>“Statistical significance calculations for scenarios in visual inference,”</span> <em>Stat</em>, Wiley Online Library, 10, e337.
</div>
<div id="ref-white1980heteroskedasticity" class="csl-entry" role="listitem">
White, H. (1980), <span>“A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity,”</span> <em>Econometrica: Journal of the Econometric Society</em>, JSTOR, 817–838.
</div>
<div id="ref-wickham2010" class="csl-entry" role="listitem">
Wickham, H., Cook, D., Hofmann, H., and Buja, A. (2010), <span>“Graphical inference for infovis,”</span> <em>IEEE Transactions on Visualization and Computer Graphics</em>, 16, 973–979. <a href="https://doi.org/10.1109/TVCG.2010.161">https://doi.org/10.1109/TVCG.2010.161</a>.
</div>
<div id="ref-RNAseq2013" class="csl-entry" role="listitem">
Yin, T., Majumder, M., Roy Chowdhury, N., Cook, D., Shoemaker, R., and Graham, M. (2013), <span>“Visual mining methods for RNA-seq data: Data structure, dispersion estimation and significance testing,”</span> <em>Journal of Data Mining in Genomics and Proteomics</em>, 4. <a href="https://doi.org/10.4172/2153-0602.1000139">https://doi.org/10.4172/2153-0602.1000139</a>.
</div>
<div id="ref-zhang2018practical" class="csl-entry" role="listitem">
Zhang, Z., and Yuan, K.-H. (2018), <em>Practical statistical power analysis using webpower and r</em>, Isdsa Press.
</div>
</div>
</section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>Although we did not use it, it is useful to know that the R package <code>skedastic</code> <span class="citation" data-cites="skedastic">(<a href="refs.html#ref-skedastic" role="doc-biblioref">Farrar 2020</a>)</span> also contains a large collection of functions to test for heteroskedasticity.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./01-chap1.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./03-chap3.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Automated assessment of residual plots with computer vision models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>