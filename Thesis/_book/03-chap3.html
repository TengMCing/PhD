<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>3&nbsp; Automated Assessment of Residual Plots with Computer Vision Models – Advances in Artificial Intelligence for Data Visualization: Developing Computer Vision Models to Automate Reading of Data Plots, with Application to Regression Diagnostics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./04-chap4.html" rel="next">
<link href="./02-chap2.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="site_libs/kePrint-0.0.1/kePrint.js"></script><link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Fira+Sans%7CMerriweather%7CSource%20Code%20Pro" rel="stylesheet">
<script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script><script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">
<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./03-chap3.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Automated Assessment of Residual Plots with Computer Vision Models</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Advances in Artificial Intelligence for Data Visualization: Developing Computer Vision Models to Automate Reading of Data Plots, with Application to Regression Diagnostics</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/TengMCing/PhD/tree/master/Thesis/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Advances-in-Artificial-Intelligence-for-Data-Visualization--Developing-Computer-Vision-Models-to-Automate-Reading-of-Data-Plots,-with-Application-to-Regression-Diagnostics.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Front matter</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-chap1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-chap2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-chap3.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Automated Assessment of Residual Plots with Computer Vision Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-chap4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Software for Automated Residual Plot Assessment: autovi and autovi.web</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./refs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliography</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A-appA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Appendix to “A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol”</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B-appB.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Appendix to “Automated Assessment of Residual Plots with Computer vision Models”</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title"><b>Sections</b></h2>
   
  <ul class="collapse">
<li><a href="#sec-model-introduction" id="toc-sec-model-introduction" class="nav-link active" data-scroll-target="#sec-model-introduction"><span class="header-section-number">3.1</span> Introduction</a></li>
  <li><a href="#sec-model-specifications" id="toc-sec-model-specifications" class="nav-link" data-scroll-target="#sec-model-specifications"><span class="header-section-number">3.2</span> Model Specifications</a></li>
  <li><a href="#sec-model-distance-between-residual-plots" id="toc-sec-model-distance-between-residual-plots" class="nav-link" data-scroll-target="#sec-model-distance-between-residual-plots"><span class="header-section-number">3.3</span> Distance from a Theoretically “Good” Residual Plot</a></li>
  <li><a href="#sec-model-distance-estimation" id="toc-sec-model-distance-estimation" class="nav-link" data-scroll-target="#sec-model-distance-estimation"><span class="header-section-number">3.4</span> Distance Estimation</a></li>
  <li><a href="#sec-model-statistical-testing" id="toc-sec-model-statistical-testing" class="nav-link" data-scroll-target="#sec-model-statistical-testing"><span class="header-section-number">3.5</span> Statistical testing</a></li>
  <li><a href="#sec-model-violations-index" id="toc-sec-model-violations-index" class="nav-link" data-scroll-target="#sec-model-violations-index"><span class="header-section-number">3.6</span> Model Violations Index</a></li>
  <li><a href="#sec-model-data-generation" id="toc-sec-model-data-generation" class="nav-link" data-scroll-target="#sec-model-data-generation"><span class="header-section-number">3.7</span> Data Generation</a></li>
  <li><a href="#sec-model-architecture" id="toc-sec-model-architecture" class="nav-link" data-scroll-target="#sec-model-architecture"><span class="header-section-number">3.8</span> Model Architecture</a></li>
  <li><a href="#sec-model-training" id="toc-sec-model-training" class="nav-link" data-scroll-target="#sec-model-training"><span class="header-section-number">3.9</span> Model Training</a></li>
  <li><a href="#sec-model-results" id="toc-sec-model-results" class="nav-link" data-scroll-target="#sec-model-results"><span class="header-section-number">3.10</span> Results</a></li>
  <li><a href="#sec-examples" id="toc-sec-examples" class="nav-link" data-scroll-target="#sec-examples"><span class="header-section-number">3.11</span> Examples</a></li>
  <li><a href="#limitations-and-future-work" id="toc-limitations-and-future-work" class="nav-link" data-scroll-target="#limitations-and-future-work"><span class="header-section-number">3.12</span> Limitations and Future Work</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">3.13</span> Conclusion</a></li>
  </ul><div class="toc-actions"><ul class="collapse"><li><a href="https://github.com/TengMCing/PhD/edit/master/Thesis/03-chap3.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span id="sec-second-paper" class="quarto-section-identifier"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Automated Assessment of Residual Plots with Computer Vision Models</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><p>Plotting residuals is a recommended practice to diagnose deviations from linear model assumptions such as non-linearity, heteroscedasticity, and non-normality. The presence or absence of structure in residual plots can be tested using the lineup protocol to do visual inference. As a statistical test, the lineup protocol is less sensitive and applies more broadly than available conventional tests. However, the lineup protocol relies on human judgment which limits its scalability. This work presents a solution by providing a computer vision model to automate the assessment of residual plots. It is trained to predict the distance measure that quantifies the disparity between the residual distribution of a fitted classical normal linear regression model and the reference distribution, based on Kullback-Leibler divergence. From extensive simulation studies, the computer vision model exhibits lower sensitivity than conventional tests but higher sensitivity than human visual tests. It is slightly less effective on non-linearity patterns. Several examples from classical papers and contemporary data illustrate the new procedures, highlighting its usefulness in automating the diagnostic process and supplementing existing methods.</p>
<section id="sec-model-introduction" class="level2" data-number="3.1"><h2 data-number="3.1" class="anchored" data-anchor-id="sec-model-introduction">
<span class="header-section-number">3.1</span> Introduction</h2>
<p>Plotting residuals is commonly regarded as a standard practice in linear regression diagnostics <span class="citation" data-cites="belsley1980regression cook1982residuals">(<a href="refs.html#ref-belsley1980regression" role="doc-biblioref">Belsley et al. 1980</a>; <a href="refs.html#ref-cook1982residuals" role="doc-biblioref">Cook and Weisberg 1982</a>)</span>. This visual assessment plays a crucial role in identifying whether model assumptions, such as linearity, homoscedasticity, and normality, are reasonable. It also helps in understanding the goodness of fit and various unexpected characteristics of the model.</p>
<p>Generating a residual plot in most statistical software is often as straightforward as executing a line of code or clicking a button. However, accurately interpreting a residual plot can be challenging. A residual plot can exhibit various visual features, but it is crucial to recognize that some may arise from the characteristics of predictors and the natural stochastic variation of the observational unit, rather than indicating a violation of model assumptions <span class="citation" data-cites="li2024plot">(<a href="refs.html#ref-li2024plot" role="doc-biblioref">Li et al. 2024</a>)</span>. Consider <a href="#fig-false-finding" class="quarto-xref">Figure&nbsp;<span>3.1</span></a> as an example, the residual plot displays a triangular left-pointing shape. The distinct difference in the spread of the residuals across the fitted values may result in the analyst suggesting that there may be heteroskedasticity, however, it is important to avoid over-interpreting this visual pattern. In this case, the fitted regression model is correctly specified, and the triangular shape is actually a result of the skewed distribution of the predictors, rather than indicating a flaw in the model.</p>
<p>The concept of visual inference, as proposed by <span class="citation" data-cites="buja2009statistical">Buja et al. (<a href="refs.html#ref-buja2009statistical" role="doc-biblioref">2009</a>)</span>, provides an inferential framework to assess whether residual plots indeed contain visual patterns inconsistent with the model assumptions. The fundamental idea involves testing whether the true residual plot visually differs significantly from null plots, where null plots are plotted with residuals generated from the residual rotation distribution <span class="citation" data-cites="langsrud2005rotation">(<a href="refs.html#ref-langsrud2005rotation" role="doc-biblioref">Langsrud 2005</a>)</span>, which is a distribution consistent with the null hypothesis <span class="math inline">H_0</span> that the linear regression model is correctly specified. Typically, the visual test is accomplished through the lineup protocol, where the true residual plot is embedded within a lineup alongside several null plots. If the true residual plot can be distinguished from the lineup, it provides evidence for rejecting <span class="math inline">H_0</span>.</p>
<p>The practice of delivering a residual plot as a lineup is generally regarded as a valuable approach. Beyond its application in residual diagnostics, the lineup protocol has been integrated into the analysis of diverse subjects. For instance, Loy and Hofmann <span class="citation" data-cites="loy2013diagnostic loy2014hlmdiag loy2015you">(<a href="refs.html#ref-loy2013diagnostic" role="doc-biblioref">2013</a>, <a href="refs.html#ref-loy2014hlmdiag" role="doc-biblioref">2014</a>, <a href="refs.html#ref-loy2015you" role="doc-biblioref">2015</a>)</span> illustrated its applicability in diagnosing hierarchical linear models. Additionally, <span class="citation" data-cites="widen2016graphical">Widen et al. (<a href="refs.html#ref-widen2016graphical" role="doc-biblioref">2016</a>)</span> and <span class="citation" data-cites="fieberg2024using">Fieberg et al. (<a href="refs.html#ref-fieberg2024using" role="doc-biblioref">2024</a>)</span> demonstrated its utility in geographical and ecology research respectively, while <span class="citation" data-cites="krishnan2021hierarchical">Krishnan and Hofmann (<a href="refs.html#ref-krishnan2021hierarchical" role="doc-biblioref">2021</a>)</span> explored its effectiveness in forensic examinations.</p>
<p>A practical limitation of the lineup protocol lies in its reliance on human judgements <span class="citation" data-cites="li2024plot">(see <a href="refs.html#ref-li2024plot" role="doc-biblioref">Li et al. 2024</a> about the practical limitations)</span>. Unlike conventional statistical tests that can be performed computationally in statistical software, the lineup protocol requires human evaluation of images. This characteristic makes it less suitable for large-scale applications, given the associated high labour costs and time requirements. There is a substantial need to develop an approach to substitute these human judgement with an automated reading of data plots using machines.</p>
<p>The utilization of computers to interpret data plots has a rich history, with early efforts such as “Scagnostics” by <span class="citation" data-cites="tukey1985computer">Tukey and Tukey (<a href="refs.html#ref-tukey1985computer" role="doc-biblioref">1985</a>)</span>, a set of numerical statistics that summarise features of scatter plots. <span class="citation" data-cites="wilkinson2005graph">Wilkinson et al. (<a href="refs.html#ref-wilkinson2005graph" role="doc-biblioref">2005</a>)</span> expanded on this work, introducing scagnostics based on computable measures applied to planar proximity graphs. These measures, including, but not limited to, “Outlying”, “Skinny”, “Stringy”, “Straight”, “Monotonic”, “Skewed”, “Clumpy”, and “Striated”, aimed to characterize outliers, shape, density, trend, coherence and other characteristics of the data. While this approach has been inspiring, there is a recognition <span class="citation" data-cites="buja2009statistical">(<a href="refs.html#ref-buja2009statistical" role="doc-biblioref">Buja et al. 2009</a>)</span> that it may not capture all the necessary visual features that differentiate true residual plots from null plots. A more promising alternative entails enabling machines to learn the function for extracting visual features from residual plots. Essentially, this means empowering computers to discern the crucial visual features for residual diagnostics and determining the method to extract them.</p>
<p>Modern computer vision models are well-suited for addressing this challenge. They rely on deep neural networks with convolutional layers <span class="citation" data-cites="fukushima1982neocognitron">(<a href="refs.html#ref-fukushima1982neocognitron" role="doc-biblioref">Fukushima and Miyake 1982</a>)</span>. These layers leverage hierarchical patterns in data, downsizing and transforming images by summarizing information in a small space. Numerous studies have demonstrated the efficacy of convolutional layers in addressing various vision tasks, including image recognition <span class="citation" data-cites="rawat2017deep">(<a href="refs.html#ref-rawat2017deep" role="doc-biblioref">Rawat and Wang 2017</a>)</span>. Despite the widespread use of computer vision models in fields like computer-aided diagnosis <span class="citation" data-cites="lee2015image">(<a href="refs.html#ref-lee2015image" role="doc-biblioref">Lee and Chen 2015</a>)</span>, pedestrian detection <span class="citation" data-cites="brunetti2018computer">(<a href="refs.html#ref-brunetti2018computer" role="doc-biblioref">Brunetti et al. 2018</a>)</span>, and facial recognition <span class="citation" data-cites="emami2012facial">(<a href="refs.html#ref-emami2012facial" role="doc-biblioref">Emami and Suciu 2012</a>)</span>, their application in reading data plots remains limited. While some studies have explored the use of computer vision models for tasks such as reading recurrence plots for time series regression <span class="citation" data-cites="ojeda2020multivariate">(<a href="refs.html#ref-ojeda2020multivariate" role="doc-biblioref">Ojeda et al. 2020</a>)</span>, time series classification <span class="citation" data-cites="chu2019automatic hailesilassie2019financial hatami2018classification zhang2020encoding">(<a href="refs.html#ref-chu2019automatic" role="doc-biblioref">Chu et al. 2019</a>; <a href="refs.html#ref-hailesilassie2019financial" role="doc-biblioref">Hailesilassie 2019</a>; <a href="refs.html#ref-hatami2018classification" role="doc-biblioref">Hatami et al. 2018</a>; <a href="refs.html#ref-zhang2020encoding" role="doc-biblioref">Zhang et al. 2020</a>)</span>, anomaly detection <span class="citation" data-cites="chen2020convolutional">(<a href="refs.html#ref-chen2020convolutional" role="doc-biblioref">Chen et al. 2020</a>)</span>, and pairwise causality analysis <span class="citation" data-cites="singh2017deep">(<a href="refs.html#ref-singh2017deep" role="doc-biblioref">Singh et al. 2017</a>)</span>, the application of reading residual plots with computer vision models is a new field of study.</p>
<p>In this chapter, we develop computer vision models and integrate them into the residual plots diagnostics workflow, addressing the need for an automated visual inference. The chapter is structured as follows. <a href="#sec-model-specifications" class="quarto-xref"><span>Section 3.2</span></a> discusses various specifications of the computer vision models. <a href="#sec-model-distance-between-residual-plots" class="quarto-xref"><span>Section 3.3</span></a> defines the distance measure used to detect model violations, while <a href="#sec-model-distance-estimation" class="quarto-xref"><span>Section 3.4</span></a> explains how the computer vision models estimate this distance measure. <a href="#sec-model-statistical-testing" class="quarto-xref"><span>Section 3.5</span></a> covers the statistical tests based on the estimated distance, and <a href="#sec-model-violations-index" class="quarto-xref"><span>Section 3.6</span></a> introduces a Model Violations Index, which offers a quicker and more convenient assessment. Sections <a href="#sec-model-data-generation" class="quarto-xref"><span>3.7</span></a>, <a href="#sec-model-architecture" class="quarto-xref"><span>3.8</span></a>, and <a href="#sec-model-training" class="quarto-xref"><span>3.9</span></a> detail the data preparation, model architecture, and training process, respectively. The results are presented in <a href="#sec-model-results" class="quarto-xref"><span>Section 3.10</span></a>. Example dataset applications are discussed in <a href="#sec-examples" class="quarto-xref"><span>Section 3.11</span></a>. Finally, we conclude with a discussion of our findings and propose ideas for future research directions.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-false-finding" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-false-finding-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-false-finding-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="384">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-false-finding-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.1: An example residual vs fitted values plot (red line indicates 0 corresponds to the x-intercept, i.e.&nbsp;<span class="math inline">y=0</span>). The vertical spread of the data points varies with the fitted values. This often indicates the existence of heteroskedasticity, however, here the result is due to skewed distribution of the predictors rather than heteroskedasticity. The Breusch-Pagan test rejects this residual plot at 95% significance level (<span class="math inline">p\text{-value} = 0.046</span>).
</figcaption></figure>
</div>
</div>
</div>
</section><section id="sec-model-specifications" class="level2" data-number="3.2"><h2 data-number="3.2" class="anchored" data-anchor-id="sec-model-specifications">
<span class="header-section-number">3.2</span> Model Specifications</h2>
<p>There are various specifications of the computer vision model that can be used to assess residual plots. We discuss these specifications below focusing on two key components of the model formula: the input and the output format.</p>
<section id="input-formats" class="level3" data-number="3.2.1"><h3 data-number="3.2.1" class="anchored" data-anchor-id="input-formats">
<span class="header-section-number">3.2.1</span> Input Formats</h3>
<p>Deep learning models are in general very sensitive to the input data. The quality and relevance of the input data greatly influence the model’s capacity to generate insightful and meaningful results. There are several designs of the input format that can be considered.</p>
<p>A straightforward design involves feeding a vector of residuals along with a vector of fitted values, essentially providing all the necessary information for creating a residuals vs fitted values plot. However, a drawback of this method is the dynamic input size, which changes based on the number of observations. For modern computer vision models implemented in mainstream software like TensorFlow <span class="citation" data-cites="abadi2016tensorflow">(<a href="refs.html#ref-abadi2016tensorflow" role="doc-biblioref">Abadi et al. 2016</a>)</span>, the input shape is typically fixed. One solution is to pad the input vectors with leading or trailing zeros when the input tensor expects longer vectors, but it may fail if the input vector surpasses the designed length.</p>
<p>Another strategy is to summarize the residuals and fitted values separately using histograms and utilize the counts as the input. By controlling the number of bins in the histograms, it becomes possible to provide fixed-length input vectors. Still, since histograms only capture the marginal distribution of residuals and fitted values respectively, they can not be used to differentiate visual patterns with same marginal distributions but different joint distributions.</p>
<p>Another design involves using an image as input. The primary advantage of this design, as opposed to the vector format, is the availability of the existing and sophisticated image processing architectures developed over the years, such as the VGG16 architecture proposed in <span class="citation" data-cites="simonyan2014very">Simonyan and Zisserman (<a href="refs.html#ref-simonyan2014very" role="doc-biblioref">2014</a>)</span>. These architectures can effectively capture and summarize spatial information from nearby pixels, which is less straightforward with vector input. The main considerations are the image resolution and the aesthetics of the residual plot. In general, a higher resolution provides more information to the model but comes with a trade-off of increased complexity and greater difficulty in training. As for the aesthetics of the residual plot, a practical solution is to consistently present residual plots in the same style to the model. This implies that the model can not accept arbitrary images as input but requires the use of the same pre-processing pipeline to convert residuals and fitted values into a standardized-style residual plot.</p>
<p>Providing multiple residual plots to the model, such as a pair of plots, a triplet or a lineup is also a possible option. <span class="citation" data-cites="chopra2005learning">Chopra et al. (<a href="refs.html#ref-chopra2005learning" role="doc-biblioref">2005</a>)</span> have shown that computer vision models designed for image comparison can assess whether a pair of images are similar or dissimilar. Applied to our specific problem, we can define null plots of a fitted regression model to be similar to each other, while considering true residual plots to be distinct from null plots of any fitted regression model. A triplet constitutes a set of three images, denoted as <span class="math inline">image_1</span>, <span class="math inline">image_2</span> and <span class="math inline">image_3</span>. It is often used to predict whether <span class="math inline">image_2</span> or <span class="math inline">image_3</span> is more similar to <span class="math inline">image_1</span>, proving particularly useful for establishing rankings between samples. For this setup, we can apply the same criteria to define similarity between images. However, it is important to note that these two approaches usually require additional considerations regarding the loss function and, at times, non-standard training processes due to shared weights between different convolutional blocks.</p>
<p>Presenting a lineup to a model aligns closely with the lineup protocol. However, as the number of residual plots in a lineup increases, the resolution of the input image grows rapidly, posing challenges in training the model. We experimented with this approach in a pilot study, but the performance of the trained model was sub-optimal.</p>
<p>Taking into account the implementation cost and the need for model interpretability, we used the single residual plot input format in this chapter.</p>
</section><section id="output-formats" class="level3" data-number="3.2.2"><h3 data-number="3.2.2" class="anchored" data-anchor-id="output-formats">
<span class="header-section-number">3.2.2</span> Output Formats</h3>
<p>Given that the input is a single residual plot represented as a fixed-resolution image, we can choose the output from the computer vision model to be either binary (classification) or numeric (regression).</p>
<p>The binary outcome can represent whether the input image is consistent with a null plot as determined by either (1) the data generating process or (2) the result of a visual test based on human judgement. Training a model following the latter option requires data from prior human subject experiments, presenting difficulties in controlling the quality of data due to variations in experimental settings across different studies. Additionally, some visual inference experiments are unrelated to linear regression models or residual plot diagnostics, resulting in a limited amount of available training data.</p>
<p>Alternatively, the output could be a meaningful and interpretable numerical measure useful for assessing residual plots, such as the strength of suspicious visual patterns reflecting the extent of model violations, or the difficulty index for identifying whether a residual plot has no issues. However, these numeric measures are often informally used in daily communication but are not typically formalized or rigorously defined. For the purpose of training a model, this numeric measure has to be quantifiable.</p>
<p>In this study, we chose to define and use a distance between a true residual plot and a theoretically “good” residual plot. This is further explained in <a href="#sec-model-distance-between-residual-plots" class="quarto-xref"><span>Section 3.3</span></a>. <span class="citation" data-cites="vo2016localizing">Vo and Hays (<a href="refs.html#ref-vo2016localizing" role="doc-biblioref">2016</a>)</span> have also demonstrated that defining a proper distance between images can enhance the matching accuracy in image search compared to a binary outcome model.</p>
</section><section id="auxiliary-information-with-scagnostics" class="level3" data-number="3.2.3"><h3 data-number="3.2.3" class="anchored" data-anchor-id="auxiliary-information-with-scagnostics">
<span class="header-section-number">3.2.3</span> Auxiliary Information with Scagnostics</h3>
<p>In <a href="#sec-model-introduction" class="quarto-xref"><span>Section 3.1</span></a>, we mentioned that scagnostics consist of a set of manually designed visual feature extraction functions. While our computer vision model will learn its own feature extraction function during training, leveraging additional information from scagnostics can enhance the model’s predictive accuracy.</p>
<p>For each residual plot used as an input image, we computed four scagnostics – “Monotonic”, “Sparse”, “Splines”, and “Striped” – using the <code>cassowaryr</code> R package <span class="citation" data-cites="mason2022cassowaryr">(<a href="refs.html#ref-mason2022cassowaryr" role="doc-biblioref">Mason et al. 2022</a>)</span>. These computed measures, along with the number of observations from the fitted model, were provided as the second input for the computer vision model. While other scagnostics provide valuable insights, they come with high computational costs and are not suitable for quick inference.</p>
</section></section><section id="sec-model-distance-between-residual-plots" class="level2" data-number="3.3"><h2 data-number="3.3" class="anchored" data-anchor-id="sec-model-distance-between-residual-plots">
<span class="header-section-number">3.3</span> Distance from a Theoretically “Good” Residual Plot</h2>
<p>To develop a computer vision model for assessing residual plots within the visual inference framework, it is important to precisely define a numerical measure of “difference” or “distance” between plots. This distance can take the form of a basic statistical operation on pixels, such as the sum of square differences, however, a pixel-to-pixel comparison makes little sense in comparing residual plots where the main interest would be structural patterns. Alternatively, it could involve established image similarity metrics like the Structural Similarity Index Measure <span class="citation" data-cites="wang2004image">(<a href="refs.html#ref-wang2004image" role="doc-biblioref">Wang et al. 2004</a>)</span> which compares images by integrating three perception features of an image: contrast, luminance, and structure (related to average, standard deviation and correlation of pixel values over a window, respectively). These image similarity metrics are tailored for image comparison in vastly different tasks to evaluating data plots, where only essential plot elements require assessment <span class="citation" data-cites="chowdhury2018measuring">(<a href="refs.html#ref-chowdhury2018measuring" role="doc-biblioref">Chowdhury et al. 2018</a>)</span>. We can alternatively define a notion of distance by integrating key plot elements (instead of key perception features like luminance, contrast, and structure), such as those captured by scagnostics mentioned in <a href="#sec-model-introduction" class="quarto-xref"><span>Section 3.1</span></a>, but the functional form still needs to be carefully refined to accurately reflect the extent of the violations.</p>
<p>In this section, we introduce a distance measure between a true residual plot and a theoretically ‘good’ residual plot. This measure quantifies the divergence between the residual distribution of a given fitted regression model and that of a correctly specified model. The computation assumes knowledge of the data generating processes for predictors and response variables. Since these processes are often unknown in practice, we will discuss a method to estimate this distance using a computer vision model in <a href="#sec-model-distance-estimation" class="quarto-xref"><span>Section 3.4</span></a>.</p>
<section id="residual-distribution" class="level3" data-number="3.3.1"><h3 data-number="3.3.1" class="anchored" data-anchor-id="residual-distribution">
<span class="header-section-number">3.3.1</span> Residual Distribution</h3>
<p>For a classical normal linear regression model, <span class="math inline">\boldsymbol{y} = \boldsymbol{X}\boldsymbol{\beta} + \boldsymbol{e}</span>, the residual <span class="math inline">\hat{\boldsymbol{e}}</span> are derived as the difference of the fitted values and observed values <span class="math inline">\boldsymbol{y}</span>. Suppose the data generating process is known and the regression model is correctly specified, by the Frisch-Waugh-Lowell theorem <span class="citation" data-cites="frisch1933partial">(<a href="refs.html#ref-frisch1933partial" role="doc-biblioref">Frisch and Waugh 1933</a>)</span>, residuals <span class="math inline">\hat{\boldsymbol{e}}</span> can also be treated as random variables and written as a linear transformation of the error <span class="math inline">\boldsymbol{e}</span> formulated as <span class="math inline">\hat{\boldsymbol{e}} = \boldsymbol{R}\boldsymbol{e}</span>, where <span class="math inline">\boldsymbol{R}=\boldsymbol{I}_n -\boldsymbol{X}(\boldsymbol{X}^\top\boldsymbol{X})^{-1}\boldsymbol{X}^\top</span> is the residual operator, <span class="math inline">\boldsymbol{I}_n</span> is a <span class="math inline">n</span> by <span class="math inline">n</span> identity matrix, and <span class="math inline">n</span> is the number of observations.</p>
<p>One of the assumptions of the classical normal linear regression model is that the error <span class="math inline">\boldsymbol{e}</span> follows a multivariate normal distribution with zero mean and constant variance, i.e., <span class="math inline">\boldsymbol{e} \sim N(\boldsymbol{0}_n,\sigma^2\boldsymbol{I}_n)</span>. It can be known that residuals <span class="math inline">\hat{\boldsymbol{e}}</span> also follow a certain probability distribution transformed from the multivariate normal distribution, which will be denoted as <span class="math inline">Q</span>. This reference distribution <span class="math inline">Q</span> summarizes what “good” residuals should follow given the design matrix <span class="math inline">\boldsymbol{X}</span> is known and fixed.</p>
<p>Suppose the design matrix <span class="math inline">\boldsymbol{X}</span> has linearly independent columns, the trace of the hat matrix <span class="math inline">\boldsymbol{H} = \boldsymbol{X}(\boldsymbol{X}^\top\boldsymbol{X})^{-1}\boldsymbol{X}^\top</span> will equal to the number of columns in <span class="math inline">\boldsymbol{X}</span> denoted as <span class="math inline">k</span>. As a result, the rank of <span class="math inline">\boldsymbol{R}</span> is <span class="math inline">n - k</span>, and <span class="math inline">Q</span> is a degenerate multivariate distribution. To capture the characteristics of <span class="math inline">Q</span>, such as moments, we can simulate a large numbers of <span class="math inline">\boldsymbol{\varepsilon}</span> and transform it to <span class="math inline">\boldsymbol{e}</span> to get the empirical estimates. For simplicity, in this study, we replaced the variance-covariance matrix of residuals <span class="math inline">\text{cov}(\boldsymbol{e}, \boldsymbol{e}) = \boldsymbol{R}\sigma^2\boldsymbol{R}^\top = \boldsymbol{R}\sigma^2</span> with a full-rank diagonal matrix <span class="math inline">\text{diag}(\boldsymbol{R}\sigma^2)</span>, where <span class="math inline">\text{diag}(.)</span> sets the non-diagonal entries of a matrix to zeros. The resulting distribution for <span class="math inline">Q</span> is <span class="math inline">N(\boldsymbol{0}_n, \text{diag}(\boldsymbol{R}\sigma^2))</span>.</p>
<p>Distribution <span class="math inline">Q</span> is derived from the correctly specified model. However, if the model is misspecified, then the actual distribution of residuals denoted as <span class="math inline">P</span>, will be different from <span class="math inline">Q</span>. For example, if the data generating process contains variables correlated with any column of <span class="math inline">\boldsymbol{X}</span> but missing from <span class="math inline">\boldsymbol{X}</span>, causing an omitted variable problem, <span class="math inline">P</span> will be different from <span class="math inline">Q</span> because the residual operator obtained from the fitted regression model will not be the same as <span class="math inline">\boldsymbol{R}</span>. Besides, if the <span class="math inline">\boldsymbol{\varepsilon}</span> follows a non-normal distribution such as a multivariate lognormal distribution, <span class="math inline">P</span> will usually be skewed and has a long tail.</p>
</section><section id="distance-of-p-from-q" class="level3" data-number="3.3.2"><h3 data-number="3.3.2" class="anchored" data-anchor-id="distance-of-p-from-q">
<span class="header-section-number">3.3.2</span> Distance of <span class="math inline">P</span> from <span class="math inline">Q</span>
</h3>
<p>Defining a proper distance between distributions is usually easier than defining a proper distance between data plots. Given the true residual distribution <span class="math inline">Q</span> and the reference residual distribution <span class="math inline">P</span>, we used a distance measure based on Kullback-Leibler divergence <span class="citation" data-cites="kullback1951information">(<a href="refs.html#ref-kullback1951information" role="doc-biblioref">Kullback and Leibler 1951</a>)</span> to quantify the difference between two distributions as</p>
<p><span id="eq-kl-0"><span class="math display">
D = \log\left(1 + D_{KL}\right),
\tag{3.1}</span></span></p>
<p>where <span class="math inline">D_{KL}</span> is defined as</p>
<p><span id="eq-kl-1"><span class="math display">
D_{KL} = \int_{\mathbb{R}^{n}}\log\frac{p(\boldsymbol{e})}{q(\boldsymbol{e})}p(\boldsymbol{e})d\boldsymbol{e},
\tag{3.2}</span></span></p>
<p>and <span class="math inline">p(.)</span> and <span class="math inline">q(.)</span> are the probability density functions for distribution <span class="math inline">P</span> and distribution <span class="math inline">Q</span>, respectively.</p>
<p>This distance measure was first proposed in <span class="citation" data-cites="li2024plot">Li et al. (<a href="refs.html#ref-li2024plot" role="doc-biblioref">2024</a>)</span>. It was mainly designed for measuring the effect size of non-linearity and heteroskedasticity in a residual plot. <span class="citation" data-cites="li2024plot">Li et al. (<a href="refs.html#ref-li2024plot" role="doc-biblioref">2024</a>)</span> have derived that, for a classical normal linear regression model that omits necessary higher-order predictors <span class="math inline">\boldsymbol{Z}</span> and the corresponding parameter <span class="math inline">\boldsymbol{\beta}_z</span>, and incorrectly assumes <span class="math inline">\boldsymbol{\varepsilon} \sim N(\boldsymbol{0}_n,\sigma^2\boldsymbol{I}_n)</span> while in fact <span class="math inline">\boldsymbol{\varepsilon} \sim N(\boldsymbol{0}_n, \boldsymbol{V})</span> where <span class="math inline">\boldsymbol{V}</span> is an arbitrary symmetric positive semi-definite matrix, <span class="math inline">Q</span> can be represented as <span class="math inline">N(\boldsymbol{R}\boldsymbol{Z}\boldsymbol{\beta}_z, \text{diag}(\boldsymbol{R}\boldsymbol{V}\boldsymbol{R}))</span>. Note that the variance-covariance matrix is replaced with the diagonal matrix to ensure it is a full-rank matrix.</p>
<p>Since both <span class="math inline">P</span> and <span class="math inline">Q</span> are adjusted to be multivariate normal distributions, <a href="#eq-kl-1" class="quarto-xref">Equation&nbsp;<span>3.2</span></a> can be further expanded to</p>
<p><span id="eq-kl-2"><span class="math display">
\begin{aligned}
D_{KL} &amp;= \frac{1}{2}\left(\log\frac{|\boldsymbol{W}|}{|\text{diag}(\boldsymbol{R}\sigma^2)|} - n + \text{tr}(\boldsymbol{W}^{-1}\text{diag}(\boldsymbol{R}\sigma^2)) + \boldsymbol{\mu}_z^\top\boldsymbol{W}^{-1}\boldsymbol{\mu}_z\right),
\end{aligned}
\tag{3.3}</span></span></p>
<p>where <span class="math inline">\boldsymbol{\mu}_z = \boldsymbol{R}\boldsymbol{Z}\boldsymbol{\beta}_z</span>, and <span class="math inline">\boldsymbol{W} = \text{diag}(\boldsymbol{R}\boldsymbol{V}\boldsymbol{R})</span>. The assumed error variance <span class="math inline">\sigma^2</span> is set to be <span class="math inline">\text{tr}(\boldsymbol{V})/n</span>, which is the expectation of the estimated variance.</p>
</section><section id="non-normal-p" class="level3" data-number="3.3.3"><h3 data-number="3.3.3" class="anchored" data-anchor-id="non-normal-p">
<span class="header-section-number">3.3.3</span> Non-normal <span class="math inline">P</span>
</h3>
<p>For non-normal error <span class="math inline">\boldsymbol{\varepsilon}</span>, the true residual distribution <span class="math inline">P</span> is unlikely to be a multivariate normal distribution. Thus, <a href="#eq-kl-2" class="quarto-xref">Equation&nbsp;<span>3.3</span></a> given in <span class="citation" data-cites="li2024plot">Li et al. (<a href="refs.html#ref-li2024plot" role="doc-biblioref">2024</a>)</span> will not be applicable to models violating the normality assumption.</p>
<p>To evaluate the Kullback-Leibler divergence of non-normal <span class="math inline">P</span> from <span class="math inline">Q</span>, the fallback is to solve <a href="#eq-kl-1" class="quarto-xref">Equation&nbsp;<span>3.2</span></a> numerically. However, since <span class="math inline">\boldsymbol{e}</span> is a linear transformation of non-normal random variables, it is very common that the general form of <span class="math inline">P</span> is unknown, meaning that we can not easily compute <span class="math inline">p(\boldsymbol{e})</span> using a well-known probability density function. Additionally, even if <span class="math inline">p(\boldsymbol{e})</span> can be calculated for any <span class="math inline">\boldsymbol{e} \in \mathbb{R}^n</span>, it will be very difficult to do numerical integration over the <span class="math inline">n</span>-dimensional space, because <span class="math inline">n</span> could be potentially very large.</p>
<p>In order to approximate <span class="math inline">D_{KL}</span> in a practically computable manner, the elements of <span class="math inline">\boldsymbol{e}</span> are assumed to be independent of each other. This assumption solves both of the issues mentioned above. First, we no longer need to integrate over <span class="math inline">n</span> random variables. The result of <a href="#eq-kl-1" class="quarto-xref">Equation&nbsp;<span>3.2</span></a> is now the sum of the Kullback-Leibler divergence evaluated for each individual residual due to the assumption of independence between observations. Second, it is not required to know the joint probability density <span class="math inline">p(\boldsymbol{e})</span> any more. Instead, the evaluation of Kullback-Leibler divergence for an individual residual relies on the knowledge of the marginal density <span class="math inline">p_i(e_i)</span>, where <span class="math inline">e_i</span> is the <span class="math inline">i</span>-th residual for <span class="math inline">i = 1, ..., n</span>. This is much easier to approximate through simulation. It is also worth mentioning that this independence assumption generally will not hold if <span class="math inline">\text{cov}(e_i, e_j) \neq 0</span> for any <span class="math inline">1 \leq i &lt; j \leq n</span>, but its existence is essential for reducing the computational cost.</p>
<p>Given <span class="math inline">\boldsymbol{X}</span> and <span class="math inline">\boldsymbol{\beta}</span>, the algorithm for approximating <a href="#eq-kl-1" class="quarto-xref">Equation&nbsp;<span>3.2</span></a> starts from simulating <span class="math inline">m</span> sets of observed values <span class="math inline">\boldsymbol{y}</span> according to the data generating process. The observed values are stored in a matrix <span class="math inline">\boldsymbol{A}</span> with <span class="math inline">n</span> rows and <span class="math inline">m</span> columns, where each column of <span class="math inline">\boldsymbol{A}</span> is a set of observed values. Then, we can get <span class="math inline">m</span> sets of realized values of <span class="math inline">\boldsymbol{e}</span> stored in the matrix <span class="math inline">\boldsymbol{B}</span> by applying the residual operator <span class="math inline">\boldsymbol{B} = \boldsymbol{R}\boldsymbol{A}</span>. Furthermore, kernel density estimation (KDE) with Gaussian kernel and optimal bandwidth selected by the Silverman’s rule of thumb <span class="citation" data-cites="silverman2018density">(<a href="refs.html#ref-silverman2018density" role="doc-biblioref">Silverman 2018</a>)</span> is applied on each row of <span class="math inline">\boldsymbol{B}</span> to estimate <span class="math inline">p_i(e_i)</span> for <span class="math inline">i = 1, ..., n</span>. The KDE computation can be done by the <code>density</code> function in R.</p>
<p>Since the Kullback-Leibler divergence can be viewed as the expectation of the log-likelihood ratio between distribution <span class="math inline">P</span> and distribution <span class="math inline">Q</span> evaluated on distribution <span class="math inline">P</span>, we can reuse the simulated residuals in matrix <span class="math inline">\boldsymbol{B}</span> to estimate the expectation by the sample mean. With the independence assumption, for non-normal <span class="math inline">P</span>, <span class="math inline">D_{KL}</span> can be approximated by</p>
<p><span id="eq-kl-3"><span class="math display">
\begin{aligned}
D_{KL} &amp;\approx \sum_{i = 1}^{n} \hat{D}_{KL}^{(i)}, \\
\hat{D}_{KL}^{(i)} &amp;= \frac{1}{m}\sum_{j = 1}^{m} \log\frac{\hat{p}_i(B_{ij})}{q(B_{ij})},
\end{aligned}
\tag{3.4}</span></span></p>
<p>where <span class="math inline">\hat{D}_{KL}^{(i)}</span> is the estimator of the Kullback-Leibler divergence for an individual residual <span class="math inline">e_i</span>, <span class="math inline">\boldsymbol{B}_{ij}</span> is the <span class="math inline">i</span>-th row and <span class="math inline">j</span>-th column entry of the matrix <span class="math inline">\boldsymbol{B}</span>, <span class="math inline">\hat{p}_i(.)</span> is the kernel density estimator of <span class="math inline">p_i(.)</span>, <span class="math inline">q(.)</span> is the normal density function with mean zero and an assumed variance estimated as <span class="math inline">\hat{\sigma}^2 = \sum_{b \in vec(\boldsymbol{B})}(b - \sum_{b \in vec(\boldsymbol{B})} b/nm)^2/(nm - 1)</span>, and <span class="math inline">vec(.)</span> is the vectorization operator which turns a <span class="math inline">n \times m</span> matrix into a <span class="math inline">nm \times 1</span> column vector by stacking the columns of the matrix on top of each other.</p>
</section></section><section id="sec-model-distance-estimation" class="level2" data-number="3.4"><h2 data-number="3.4" class="anchored" data-anchor-id="sec-model-distance-estimation">
<span class="header-section-number">3.4</span> Distance Estimation</h2>
<p>In the previous sections, we have defined a distance measure given in <a href="#eq-kl-0" class="quarto-xref">Equation&nbsp;<span>3.1</span></a> for quantifying the difference between the true residual distribution <span class="math inline">P</span> and an ideal reference distribution <span class="math inline">Q</span>. However, this distance measure can only be computed when the data generating process is known. In reality, we often have no knowledge about the data generating process, otherwise we do not need to do a residual diagnostic in the first place.</p>
<p>We use a computer vision model to estimate this distance measure for a residual plot. Let <span class="math inline">D</span> be the result of <a href="#eq-kl-0" class="quarto-xref">Equation&nbsp;<span>3.1</span></a>, and our estimator <span class="math inline">\hat{D}</span> is formulated as</p>
<p><span id="eq-d-approx"><span class="math display">
\hat{D} = f_{CV}(V_{h \times w}(\boldsymbol{e}, \hat{\boldsymbol{y}})),
\tag{3.5}</span></span></p>
<p>where <span class="math inline">V_{h \times w}(.)</span> is a plotting function that saves a residuals vs fitted values plot with fixed aesthetic as an image with <span class="math inline">h \times w</span> pixels in three channels (RGB), <span class="math inline">f_{CV}(.)</span> is a computer vision model which takes an <span class="math inline">h \times w</span> image as input and predicts the distance in the domain <span class="math inline">[0, +\infty)</span>.</p>
<p>With the estimated distance <span class="math inline">\hat{D}</span>, we can compare the underlying distribution of the residuals to a theoretically “good” residual distribution. <span class="math inline">\hat{D}</span> can also be used as an index of the model violations indicating the strength of the visual signal embedded in the residual plot.</p>
<p>It is not expected that <span class="math inline">\hat{D}</span> will be equal to original distance <span class="math inline">D</span>. This is largely because information contained in a single residual plot is limited and it may not be able to summarise all the important characteristics of the residual distribution. For a given residual distribution <span class="math inline">P</span>, many different residual plots can be simulated, where many will share similar visual patterns, but some of them could be visually very different from the rest, especially for regression models with small <span class="math inline">n</span>. This suggests the error of the estimation will vary depends on whether the input residual plot is representative or not.</p>
</section><section id="sec-model-statistical-testing" class="level2" data-number="3.5"><h2 data-number="3.5" class="anchored" data-anchor-id="sec-model-statistical-testing">
<span class="header-section-number">3.5</span> Statistical testing</h2>
<section id="sec-model-lineup-evaluation" class="level3" data-number="3.5.1"><h3 data-number="3.5.1" class="anchored" data-anchor-id="sec-model-lineup-evaluation">
<span class="header-section-number">3.5.1</span> Lineup Evaluation</h3>
<p>Theoretically, the distance <span class="math inline">D</span> for a correctly specified model is <span class="math inline">0</span>, because <span class="math inline">P</span> will be the same as <span class="math inline">Q</span>. However, the computer vision model may not necessary predict <span class="math inline">0</span> for a null plot. Using <a href="#fig-false-finding" class="quarto-xref">Figure&nbsp;<span>3.1</span></a> as an example, it contains a visual pattern which is an indication of heteroskedasticity. We would not expect the model to be able to magically tell if the suspicious pattern is caused by the skewed distribution of the fitted values or the existence of heteroskedasticity. Additionally, some null plots could have outliers or strong visual patterns due to randomness, and a reasonable model will try to summarise those information into the prediction, resulting in <span class="math inline">\hat{D} &gt; 0</span>.</p>
<p>This property is not an issue if <span class="math inline">\hat{D} \gg 0</span> for which the visual signal of the residual plot is very strong, and we usually do not need any further examination of the significance of the result. However, if the visual pattern is weak or moderate, having <span class="math inline">\hat{D}</span> will not be sufficient to determine if <span class="math inline">H_0</span> should be rejected.</p>
<p>To address this issue we can adhere to the paradigm of visual inference, by comparing the estimated distance <span class="math inline">\hat{D}</span> to the estimated distances for the null plots in a lineup. Specifically, if a lineup comprises 20 plots, the null hypothesis <span class="math inline">H_0</span> will be rejected if <span class="math inline">\hat{D}</span> exceeds the maximum estimated distance among the <span class="math inline">m - 1</span> null plots, denoted as <span class="math inline">\max\limits_{1 \leq i \leq m-1} {\hat{D}_{null}^{(i)}}</span>, where <span class="math inline">\hat{D}_{null}^{(i)}</span> represents the estimated distance for the <span class="math inline">i</span>-th null plot. This approach is equivalent to the typical lineup protocol requiring a 95% significance level, where <span class="math inline">H_0</span> is rejected if the data plot is identified as the most distinct plot by the sole observer. The estimated distance serves as a metric to quantify the difference between the data plot and the null plots, as intended.</p>
<!-- For lineups consisting of more than 20 plots, the 95% significance level can be maintained if the number of plots is a multiple of 20. Specifically, for lineups comprising $20t$ plots, where $t$ is a positive integer, we reject $H_0$ if $\hat{D}$ exceeds 95% ${\hat{D}_{null}^{(i)}}$ for $i = 1, \ldots, 20t-1$. The $p$-value in this case is given by $\frac{1}{20t} + \frac{1}{20t}\sum_{i=1}^{20t-1} I\left(\hat{D}_{null}^{(i)} > \hat{D}\right)$, where $I(\cdot)$ is the indicator function. -->
<p>Moreover, if the number of plots in a lineup, denoted by <span class="math inline">m</span>, is sufficiently large, the empirical distribution of <span class="math inline">{\hat{D}_{null}^{(i)}}</span> can be viewed as an approximation of the null distribution of the estimated distance. Consequently, quantiles of the null distribution can be estimated using the sample quantiles, and these quantiles can be utilized for decision-making purposes. The details of the sample quantile computation can be found in <span class="citation" data-cites="hyndman1996sample">Hyndman and Fan (<a href="refs.html#ref-hyndman1996sample" role="doc-biblioref">1996</a>)</span>. For instance, if <span class="math inline">\hat{D}</span> is greater than or equal to the 95% sample quantile, denoted as <span class="math inline">Q_{null}(0.95)</span>, we can conclude that the estimated distance for the true residual plot is significantly different from the estimated distance for null plots with a 95% significance level. Based on our experience, to obtain a stable estimate of the 95% quantile, the number of null plots, <span class="math inline">n_{null}</span>, typically needs to be at least 100. However, if the null distribution exhibits a long tail, a larger number of null plots may be required. Alternatively, a <span class="math inline">p</span>-value is the probability of observing a distance equally or greater than <span class="math inline">\hat{D}</span> under the null hypothesis <span class="math inline">H_0</span>, and it can be estimated by <span class="math inline">\frac{1}{m} + \frac{1}{m}\sum_{i=1}^{m-1}I\left(\hat{D}_{null}^{(i)} \geq \hat{D}\right)</span>.</p>
<p>To alleviate computation burden, a lattice of quantiles for <span class="math inline">\hat{D}</span> under <span class="math inline">H_0</span> with specified sample sizes can be precomputed. We can then map the <span class="math inline">\hat{D}</span> and sample size to the closet quantile and sample size in lattice to calculate the corresponding <span class="math inline">p</span>-value. This approach lose precision in <span class="math inline">p</span>-value calculation, however, significantly improves computational efficiency.</p>
</section><section id="bootstrapping" class="level3" data-number="3.5.2"><h3 data-number="3.5.2" class="anchored" data-anchor-id="bootstrapping">
<span class="header-section-number">3.5.2</span> Bootstrapping</h3>
<p>Bootstrap is often employed in linear regression when conducting inference for estimated parameters <span class="citation" data-cites="davison1997bootstrap">Efron and Tibshirani (<a href="refs.html#ref-efron1994introduction" role="doc-biblioref">1994</a>)</span>. It is typically done by sampling individual cases with replacement and refitting the regression model. If the observed data accurately reflects the true distribution of the population, the bootstrapped estimates can be used to measure the variability of the parameter estimate without making strong distributional assumptions about the data generating process.</p>
<p>Similarly, bootstrap can be applied on the estimated distance <span class="math inline">\hat{D}</span>. For each refitted model <span class="math inline">M_{boot}^{(i)}</span>, there will be an associated residual plot <span class="math inline">V_{boot}^{(i)}</span> which can be fed into the computer vision model to obtain <span class="math inline">\hat{D}_{boot}^{(i)}</span>, where <span class="math inline">i = 1,...,n_{boot}</span>, and <span class="math inline">n_{boot}</span> is the number of bootstrapped samples. If we are interested in the variation of <span class="math inline">\hat{D}</span>, we can use <span class="math inline">\hat{D}_{boot}^{(i)}</span> to estimate a confidence interval.</p>
<p>Alternatively, since each <span class="math inline">M_{boot}^{(i)}</span> has a set of estimated coefficients <span class="math inline">\hat{\boldsymbol{\beta}}_{boot}^{(i)}</span> and an estimated variance <span class="math inline">\hat{\sigma^2}_{boot}^{(i)}</span>, a new approximated null distribution can be construed and the corresponding 95% sample quantile <span class="math inline">Q_{boot}^{(i)}(0.95)</span> can be computed. Then, if <span class="math inline">\hat{D}_{boot}^{(i)} \geq Q_{boot}^{(i)}(0.95)</span>, <span class="math inline">H_0</span> will be rejected for <span class="math inline">M_{boot}^{(i)}</span>. The ratio of rejected <span class="math inline">M_{boot}^{(i)}</span> among all the refitted models provides an indication of how often the assumed regression model are considered to be incorrect if the data can be obtained repetitively from the same data generating process. But this approach is computationally very expensive because it requires <span class="math inline">n_{boot} \times n_{null}</span> times of residual plot assessment. In practice, <span class="math inline">Q_{null}(0.95)</span> can be used to replace <span class="math inline">Q_{boot}^{(i)}(0.95)</span> in the computation.</p>
</section></section><section id="sec-model-violations-index" class="level2" data-number="3.6"><h2 data-number="3.6" class="anchored" data-anchor-id="sec-model-violations-index">
<span class="header-section-number">3.6</span> Model Violations Index</h2>
<p>While statistical testing is a powerful tool for detecting model violations, it can become cumbersome and time-consuming when quick decisions are needed, particularly due to the need to evaluate numerous null plots. In practice, a more convenient and immediate method for assessing model performance is often required. This is where an index, such as the Model Violations Index (MVI), becomes valuable. It offers a straightforward way to quantify deviations from model assumptions, enabling rapid assessment and easier comparison across models.</p>
<p>The estimator <span class="math inline">\hat{D}</span> measures the difference between the true residual distribution and the reference residual distribution, a difference primarily arises from deviations in model assumptions. The magnitude of <span class="math inline">D</span> directly reflects the degree of these deviations, thus making <span class="math inline">\hat{D}</span> instrumental in forming a model violations index (MVI).</p>
<p>Note that if more observations are used for estimating the linear regression, the result of <a href="#eq-kl-1" class="quarto-xref">Equation&nbsp;<span>3.2</span></a> will increase, as the integration will be performed with larger <span class="math inline">n</span>. For a given data generating process, <span class="math inline">D</span> typically increases logarithmically with the number of observations. This behaviour comes from the relationship <span class="math inline">D = \text{log}(1 + D_{KL})</span>, where <span class="math inline">D_{KL} = \sum_{i=1}^{n}D_{KL}^{(i)}</span> under the assumption of independence.</p>
<p>Since <span class="math inline">\hat{D}</span> is an estimate of <span class="math inline">D</span>, it is expected that a larger number of observations will also lead to a higher <span class="math inline">\hat{D}</span>. However, this does not imply that <span class="math inline">\hat{D}</span> fails to accurately represent the extent of model violations. In fact, when examining residual plots with more observations, we often observe a stronger visual signal strength, as the underlying patterns are more likely to be revealed, except in cases of significant overlapping.</p>
<p>Therefore, the Model Violations Index (MVI) can be proposed as</p>
<p><span id="eq-mvi"><span class="math display">
\text{MVI} = C + \hat{D} - \log(n),
\tag{3.6}</span></span></p>
<p>where <span class="math inline">C</span> is a large enough constant keeping the result positive and the term <span class="math inline">-\log(n)</span> is used to offset the increase in <span class="math inline">D</span> due to sample size.</p>
<p><a href="#fig-poly-heter-index" class="quarto-xref">Figure&nbsp;<span>3.2</span></a> displays the residual plots for fitted models exhibiting varying degrees of non-linearity and heteroskedasticity. Each residual plot’s MVI is computed using <a href="#eq-mvi" class="quarto-xref">Equation&nbsp;<span>3.6</span></a> with <span class="math inline">C = 10</span>. When <span class="math inline">\text{MVI} &gt; 8</span>, the visual patterns are notably strong and easily discernible by humans. In the range <span class="math inline">6 &lt; \text{MVI} &lt; 8</span>, the visibility of the visual pattern diminishes as MVI decreases. Conversely, when <span class="math inline">\text{MVI} &lt; 6</span>, the visual pattern tends to become relatively faint and challenging to observe. <a href="#tbl-mvi" class="quarto-xref">Table&nbsp;<span>3.1</span></a> provides a summary of the MVI usage and it is applicable to other linear regression models.</p>
<div class="cell">
<div id="tbl-mvi" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-mvi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.1: Degree of model violations or the strength of the visual signals according to the Model Violations Index (MVI). The constant <span class="math inline">C</span> is set to be 10.
</figcaption><div aria-describedby="tbl-mvi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead><tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">Degree of Model Violations</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Range (<span class="math inline">C</span> = 10)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Strong</td>
<td style="text-align: center;"><span class="math inline">\text{MVI} &gt; 8</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Moderate</td>
<td style="text-align: center;"><span class="math inline">6 &lt; \text{MVI} &lt; 8</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Weak</td>
<td style="text-align: center;"><span class="math inline">\text{MVI} &lt; 6</span></td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-poly-heter-index" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-poly-heter-index-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-poly-heter-index-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-poly-heter-index-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.2: Residual plots generated from fitted models exhibiting varying degrees of (A) non-linearity and (B) heteroskedasticity violations. The model violations index (MVI) is displayed atop each residual plot. The non-linearity patterns are relatively strong for <span class="math inline">MVI &gt; 8</span>, and relatively weak for <span class="math inline">MVI &lt; 6</span>, while the heteroskedasticity patterns are relatively strong for <span class="math inline">MVI &gt; 8</span>, and relatively weak for <span class="math inline">MVI &lt; 6</span>.
</figcaption></figure>
</div>
</div>
</div>
</section><section id="sec-model-data-generation" class="level2" data-number="3.7"><h2 data-number="3.7" class="anchored" data-anchor-id="sec-model-data-generation">
<span class="header-section-number">3.7</span> Data Generation</h2>
<section id="simulation-scheme" class="level3" data-number="3.7.1"><h3 data-number="3.7.1" class="anchored" data-anchor-id="simulation-scheme">
<span class="header-section-number">3.7.1</span> Simulation Scheme</h3>
<p>While observational data is frequently employed in training models for real-world applications, the data generating process of observational data often remains unknown, making computation for our target variable <span class="math inline">D</span> unattainable. Consequently, the computer vision models developed in this study were trained using synthetic data, including 80,000 training images and 8,000 test images. This approach provided us with precise label annotations. Additionally, it ensured a large and diverse training dataset, as we had control over the data generating process, and the simulation of the training data was relatively cost-effective.</p>
<p>We have incorporated three types of residual departures of linear regression model in the training data, including non-linearity, heteroskedasticity and non-normality. All three departures can be summarised by the data generating process formulated as</p>
<p><span id="eq-data-sim"><span class="math display">
\begin{aligned}
\boldsymbol{y} &amp;= \boldsymbol{1}_n + \boldsymbol{x}_1 + \beta_1\boldsymbol{x}_2 + \beta_2(\boldsymbol{z} + \beta_1\boldsymbol{w}) + \boldsymbol{k} \odot \boldsymbol{\varepsilon}, \\
\boldsymbol{z} &amp;= \text{He}_j(g(\boldsymbol{x}_1, 2)), \\
\boldsymbol{w} &amp;= \text{He}_j(g(\boldsymbol{x}_2, 2)), \\
\boldsymbol{k} &amp;= \left[\boldsymbol{1}_n + b(2 - |a|)(\boldsymbol{x}_1 + \beta_1\boldsymbol{x}_2 - a\boldsymbol{1}_n)^{\circ2}\right]^{\circ1/2},
\end{aligned}
\tag{3.7}</span></span></p>
<p>where <span class="math inline">\boldsymbol{y}</span>, <span class="math inline">\boldsymbol{x}_1</span>, <span class="math inline">\boldsymbol{x}_2</span>, <span class="math inline">\boldsymbol{z}</span>, <span class="math inline">\boldsymbol{w}</span>, <span class="math inline">\boldsymbol{k}</span> and <span class="math inline">\boldsymbol{\varepsilon}</span> are vectors of size <span class="math inline">n</span>, <span class="math inline">\boldsymbol{1}_n</span> is a vector of ones of size <span class="math inline">n</span>, <span class="math inline">\boldsymbol{x}_1</span> and <span class="math inline">\boldsymbol{x}_2</span> are two independent predictors, <span class="math inline">\text{He}_j(.)</span> is the <span class="math inline">j</span>th-order probabilist’s Hermite polynomials <span class="citation" data-cites="hermite1864nouveau">(<a href="refs.html#ref-hermite1864nouveau" role="doc-biblioref">Hermite 1864</a>)</span>, <span class="math inline">(.)^{\circ2}</span> and <span class="math inline">(.)^{\circ1/2}</span> are Hadamard square and square root, <span class="math inline">\odot</span> is the Hadamard product, and <span class="math inline">g(\boldsymbol{x}, k)</span> is a scaling function to enforce the support of the random vector to be <span class="math inline">[-k, k]^n</span> defined as</p>
<p><span class="math display">g(\boldsymbol{x}, k) = 2k \cdot \frac{\boldsymbol{x} - x_{\min}\boldsymbol{1}_n}{x_{\max} - x_{\min}} - k\boldsymbol{1}_n,~for~k &gt; 0,</span> where <span class="math inline">x_{\min} = \underset{i \in \{ 1,...,n\}}{\min} x_i</span>, <span class="math inline">x_{\max} = \underset{i \in \{ 1,...,n\}}{\max} x_i</span> and <span class="math inline">x_i</span> is the <span class="math inline">i</span>-th entry of <span class="math inline">\boldsymbol{x}</span>.</p>
<div class="cell">
<div id="tbl-factor" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-factor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.2: Factors used in the data generating process for synthetic data simulation. Factor <span class="math inline">j</span> and <span class="math inline">a</span> controls the non-linearity shape and the heteroskedasticity shape respectively. Factor <span class="math inline">b</span>, <span class="math inline">\sigma_\varepsilon</span> and <span class="math inline">n</span> control the signal strength. Factor <span class="math inline">\text{dist}_\varepsilon</span>, <span class="math inline">\text{dist}_{x1}</span> and <span class="math inline">\text{dist}_{x2}</span> specifies the distribution of <span class="math inline">\varepsilon</span>, <span class="math inline">X_1</span> and <span class="math inline">X_2</span> respectively.
</figcaption><div aria-describedby="tbl-factor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead><tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">Factor</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Domain</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">j</td>
<td style="text-align: left;">{2, 3, ..., 18}</td>
</tr>
<tr class="even">
<td style="text-align: left;">a</td>
<td style="text-align: left;">[-1, 1]</td>
</tr>
<tr class="odd">
<td style="text-align: left;">b</td>
<td style="text-align: left;">[0, 100]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\beta_1</span></td>
<td style="text-align: left;">{0, 1}</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\beta_2</span></td>
<td style="text-align: left;">{0, 1}</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\text{dist}_{\varepsilon}</span></td>
<td style="text-align: left;">{discrete, uniform, normal, lognormal}</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\text{dist}_{x1}</span></td>
<td style="text-align: left;">{discrete, uniform, normal, lognormal}</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\text{dist}_{x2}</span></td>
<td style="text-align: left;">{discrete, uniform, normal, lognormal}</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\sigma_{\varepsilon}</span></td>
<td style="text-align: left;">[0.0625, 9]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\sigma_{X1}</span></td>
<td style="text-align: left;">[0.3, 0.6]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\sigma_{X2}</span></td>
<td style="text-align: left;">[0.3, 0.6]</td>
</tr>
<tr class="even">
<td style="text-align: left;">n</td>
<td style="text-align: left;">[50, 500]</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>The residuals and fitted values of the fitted model were obtained by regressing <span class="math inline">\boldsymbol{y}</span> on <span class="math inline">\boldsymbol{x}_1</span>. If <span class="math inline">\beta_1 \neq 0</span>, <span class="math inline">\boldsymbol{x}_2</span> was also included in the design matrix. This data generation process was adapted from <span class="citation" data-cites="li2024plot">Li et al. (<a href="refs.html#ref-li2024plot" role="doc-biblioref">2024</a>)</span>, where it was utilized to simulate residual plots exhibiting non-linearity and heteroskedasticity visual patterns for human subject experiments. A summary of the factors utilized in <a href="#eq-data-sim" class="quarto-xref">Equation&nbsp;<span>3.7</span></a> is provided in <a href="#tbl-factor" class="quarto-xref">Table&nbsp;<span>3.2</span></a>.</p>
<p>In <a href="#eq-data-sim" class="quarto-xref">Equation&nbsp;<span>3.7</span></a>, <span class="math inline">\boldsymbol{z}</span> and <span class="math inline">\boldsymbol{w}</span> represent higher-order terms of <span class="math inline">\boldsymbol{x}_1</span> and <span class="math inline">\boldsymbol{x}_2</span>, respectively. If <span class="math inline">\beta_2 \neq 0</span>, the regression model will encounter non-linearity issues. Parameter <span class="math inline">j</span> serves as a shape parameter that controls the number of tuning points in the non-linear pattern. Typically, higher values of <span class="math inline">j</span> lead to an increase in the number of tuning points, as illustrated in <a href="#fig-different-j" class="quarto-xref">Figure&nbsp;<span>3.3</span></a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-different-j" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-different-j-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-different-j-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-different-j-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.3: Non-linearity forms generated for the synthetic data simulation. The 17 shapes are generated by varying the order of polynomial given by <span class="math inline">j</span> in <span class="math inline">He_j(.)</span>.
</figcaption></figure>
</div>
</div>
</div>
<p>Additionally, scaling factor <span class="math inline">\boldsymbol{k}</span> directly affects the error distribution and it is correlated with <span class="math inline">\boldsymbol{x}_1</span> and <span class="math inline">\boldsymbol{x}_2</span>. If <span class="math inline">b \neq 0</span> and <span class="math inline">\boldsymbol{\varepsilon} \sim N(\boldsymbol{0}_n, \sigma^2\boldsymbol{I}_n)</span>, the constant variance assumption will be violated. Parameter <span class="math inline">a</span> is a shape parameter controlling the location of the smallest variance in a residual plot as shown in <a href="#fig-different-a" class="quarto-xref">Figure&nbsp;<span>3.4</span></a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-different-a" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-different-a-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-different-a-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="921">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-different-a-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.4: Heteroskedasticity forms generated for the synthetic data simulation. Different shapes are controlled by the continuous factor <span class="math inline">a</span> between -1 and 1. For <span class="math inline">a = -1</span>, the residual plot exhibits a “left-triangle” shape. And for <span class="math inline">a = 1</span>, the residual plot exhibits a “right-triangle” shape.
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-different-e" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-different-e-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-different-e-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-different-e-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.5: Non-normality forms generated for the synthetic data simulation. Four different error distributions including discrete, lognormal, normal and uniform are considered.
</figcaption></figure>
</div>
</div>
</div>
<p>Non-normality violations arise from specifying a non-normal distribution for <span class="math inline">\boldsymbol{\varepsilon}</span>. In the synthetic data simulation, four distinct error distributions are considered, including discrete, uniform, normal, and lognormal distributions, as presented in <a href="#fig-different-e" class="quarto-xref">Figure&nbsp;<span>3.5</span></a>. Each distribution imparts unique characteristics in the residual plot. The discrete error distribution introduces discrete clusters in residuals, while the lognormal distribution typically yields outliers. Uniform error distribution may result in residuals filling the entire space of the residual plot. All of these distributions exhibit visual distinctions from the normal error distribution.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-different-j-x2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-different-j-x2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-different-j-x2-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-different-j-x2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.6: Residual plots of multiple linear regression models with non-linearity issues. The 17 shapes are generated by varying the order of polynomial given by <span class="math inline">j</span> in <span class="math inline">He_j(.)</span>. A second predictor <span class="math inline">\boldsymbol{x}_2</span> is introduced to the regression model to create complex shapes.
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-different-j-heter" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-different-j-heter-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-different-j-heter-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-different-j-heter-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.7: Residual plots of models violating both the non-linearity and the heteroskedasticity assumptions. The 17 shapes are generated by varying the order of polynomial given by <span class="math inline">j</span> in <span class="math inline">He_j(.)</span>, and the “left-triangle” shape is introduced by setting <span class="math inline">a = -1</span>.
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-different-e-heter" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-different-e-heter-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-different-e-heter-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-different-e-heter-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.8: Residual plots of models violating both the non-normality and the heteroskedasticity assumptions. The four shapes are generated by using four different error distributions including discrete, lognormal, normal and uniform, and the “left-triangle” shape is introduced by setting <span class="math inline">a = -1</span>.
</figcaption></figure>
</div>
</div>
</div>
<p><a href="#eq-data-sim" class="quarto-xref">Equation&nbsp;<span>3.7</span></a> accommodates the incorporation of the second predictor <span class="math inline">\boldsymbol{x}_2</span>. Introducing it into the data generation process by setting <span class="math inline">\beta_1 = 1</span> significantly enhances the complexity of the shapes, as illustrated in <a href="#fig-different-j-x2" class="quarto-xref">Figure&nbsp;<span>3.6</span></a>. In comparison to <a href="#fig-different-j" class="quarto-xref">Figure&nbsp;<span>3.3</span></a>, <a href="#fig-different-j-x2" class="quarto-xref">Figure&nbsp;<span>3.6</span></a> demonstrates that the non-linear shape resembles a surface rather than a single curve. This augmentation can facilitate the computer vision model in learning visual patterns from residual plots of the multiple linear regression model.</p>
<p>In real-world analysis, it is not uncommon to encounter instances where multiple model violations coexist. In such cases, the residual plots often exhibit a mixed pattern of visual anomalies corresponding to different types of model violations. <a href="#fig-different-j-heter" class="quarto-xref">Figure&nbsp;<span>3.7</span></a> and <a href="#fig-different-e-heter" class="quarto-xref">Figure&nbsp;<span>3.8</span></a> show the visual patterns of models with multiple model violations.</p>
</section><section id="balanced-dataset" class="level3" data-number="3.7.2"><h3 data-number="3.7.2" class="anchored" data-anchor-id="balanced-dataset">
<span class="header-section-number">3.7.2</span> Balanced Dataset</h3>
<p>To train a robust computer vision model, we deliberately controlled the distribution of the target variable <span class="math inline">D</span> in the training data. We ensured that it followed a uniform distribution between <span class="math inline">0</span> and <span class="math inline">7</span>. This was achieved by organizing <span class="math inline">50</span> buckets, each exclusively accepting training samples with <span class="math inline">D</span> falling within the range <span class="math inline">[7(i - 1)/49, 7i/49)</span> for <span class="math inline">i &lt; 50</span>, where <span class="math inline">i</span> represents the index of the <span class="math inline">i</span>-th bucket. For the <span class="math inline">50</span>-th bucket, any training samples with <span class="math inline">D \geq 7</span> were accepted.</p>
<p>With 80,000 training images prepared, each bucket accommodated a maximum of <span class="math inline">80000/ 50 = 1600</span> training samples. The simulator iteratively sampled parameter values from the parameter space, generated residuals and fitted values using the data generation process, computed the distance, and checked if the sample fitted within the corresponding bucket. This process continued until all buckets were filled.</p>
<p>Similarly, we adopted the same methodology to prepare 8,000 test images for performance evaluation and model diagnostics.</p>
</section></section><section id="sec-model-architecture" class="level2" data-number="3.8"><h2 data-number="3.8" class="anchored" data-anchor-id="sec-model-architecture">
<span class="header-section-number">3.8</span> Model Architecture</h2>
<div class="cell">
<div class="cell-output-display">
<div id="fig-cnn-diag" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-cnn-diag-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-cnn-diag-1.png" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cnn-diag-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.9: Diagram of the architecture of the optimized computer vision model. Numbers at the bottom of each box show the shape of the output of each layer. The band of each box drawn in a darker colour indicates the use of the rectified linear unit activation function. Yellow boxes are 2D convolutional layers, orange boxes are pooling layers, the grey box is the concatenation layer, and the purple boxes are dense layers.
</figcaption></figure>
</div>
</div>
</div>
<p>The architecture of the computer vision model is adapted from a well-established architecture known as VGG16, which has demonstrated high performance in image classification <span class="citation" data-cites="simonyan2014very">(<a href="refs.html#ref-simonyan2014very" role="doc-biblioref">Simonyan and Zisserman 2014</a>)</span>. <a href="#fig-cnn-diag" class="quarto-xref">Figure&nbsp;<span>3.9</span></a> provides a diagram of the architecture. More details about the neural network layers used in this study are provided in <a href="B-appB.html" class="quarto-xref"><span>Appendix B</span></a>.</p>
<p>The model begins with an input layer of shape <span class="math inline">n \times h \times w \times 3</span>, capable of handling <span class="math inline">n</span> RGB images. This is followed by a grayscale conversion layer utilizing the luma formula under the Rec. 601 standard, which converts the colour image to grayscale. Grayscale suffices for our task since data points are plotted in black. We experiment with three combinations of <span class="math inline">h</span> and <span class="math inline">w</span>: <span class="math inline">32 \times 32</span>, <span class="math inline">64 \times 64</span>, and <span class="math inline">128 \times 128</span>, aiming to achieve sufficiently high image resolution for the problem at hand.</p>
<p>The processed image is used as the input for the first convolutional block. The model comprises at most five consecutive convolutional blocks, mirroring the original VGG16 architecture. Within each block, there are two 2D convolutional layers followed by two activation layers, respectively. Subsequently, a 2D max-pooling layer follows the second activation layer. The 2D convolutional layer convolves the input with a fixed number of <span class="math inline">3 \times 3</span> convolution filters, while the 2D max-pooling layer downsamples the input along its spatial dimensions by taking the maximum value over a <span class="math inline">2 \times 2</span> window for each channel of the input. The activation layer employs the rectified linear unit (ReLU) activation function, a standard practice in deep learning, which introduces a non-linear transformation of the output of the 2D convolutional layer. Additionally, to regularize training, a batch normalization layer is added after each 2D convolutional layer and before the activation layer. Finally, a dropout layer is appended at the end of each convolutional block to randomly set some inputs to zero during training, further aiding in regularization.</p>
<p>The output of the last convolutional block is summarized by either a global max pooling layer or a global average pooling layer, resulting in a two-dimensional tensor. To leverage the information contained in scagnostics, this tensor is concatenated with an additional <span class="math inline">n \times 5</span> tensor, which contains the “Monotonic”, “Sparse”, “Splines”, and “Striped” measures, along with the number of observations for <span class="math inline">n</span> residual plots.</p>
<p>The concatenated tensor is then fed into the final prediction block. This block consists of two fully-connected layers. The first layer contains at least <span class="math inline">128</span> units, followed by a dropout layer. Occasionally, a batch normalization layer is inserted between the fully-connected layer and the dropout layer for regularization purposes. The second fully-connected layer consists of only one unit, serving as the output of the model.</p>
<p>The model weights <span class="math inline">\boldsymbol{\theta}</span> were randomly initialized and they were optimized by the Adam optimizer <span class="citation" data-cites="kingma2014adam">(<a href="refs.html#ref-kingma2014adam" role="doc-biblioref">Kingma and Ba 2014</a>)</span> with the mean square error loss function</p>
<p><span class="math display">\hat{\boldsymbol{\theta}} = \underset{\boldsymbol{\theta}}{\text{arg min}}\frac{1}{n_{\text{train}}}\sum_{i=1}^{n_{\text{train}}}(D_i - f_{\boldsymbol{\theta}}(V_i, S_i))^2,</span></p>
<p>where <span class="math inline">n_{\text{train}}</span> is the number of training samples, <span class="math inline">V_i</span> is the <span class="math inline">i</span>-th residual plot and <span class="math inline">S_i</span> is the additional information about the <span class="math inline">i</span>-th residual plot including four scagnostics and the number of observations.</p>
</section><section id="sec-model-training" class="level2" data-number="3.9"><h2 data-number="3.9" class="anchored" data-anchor-id="sec-model-training">
<span class="header-section-number">3.9</span> Model Training</h2>
<p>To achieve a near-optimal deep learning model, hyperparameters like the learning rate often need to be fine-tuned using a tuner. In our study, we utilized the Bayesian optimization tuner from the <code>KerasTuner</code> Python library <span class="citation" data-cites="omalley2019kerastuner">(<a href="refs.html#ref-omalley2019kerastuner" role="doc-biblioref">O’Malley et al. 2019</a>)</span> for this purpose. A comprehensive list of hyperparameters is provided in <a href="#tbl-hyperparameter" class="quarto-xref">Table&nbsp;<span>3.3</span></a>.</p>
<p>The number of base filters determines the number of filters for the first 2D convolutional layer. In the VGG16 architecture, the number of filters for the 2D convolutional layer in a block is typically twice the number in the previous block, except for the last block, which maintains the same number of convolution filters as the previous one. This hyperparameter aids in controlling the complexity of the computer vision model. A higher number of base filters results in more trainable parameters. Likewise, the number of units for the fully-connected layer determines the complexity of the final prediction block. Increasing the number of units enhances model complexity, resulting in more trainable parameters.</p>
<p>The dropout rate and batch normalization are flexible hyperparameters that work in conjunction with other parameters to facilitate smooth training. A higher dropout rate is necessary when the model tends to overfit the training dataset by learning too much noise <span class="citation" data-cites="srivastava2014dropout">(<a href="refs.html#ref-srivastava2014dropout" role="doc-biblioref">Srivastava et al. 2014</a>)</span>. Conversely, a lower dropout rate is preferred when the model is complex and challenging to converge. Batch normalization, on the other hand, addresses the internal covariate shift problem arising from the randomness in weight initialization and input data <span class="citation" data-cites="goodfellow2016deep">(<a href="refs.html#ref-goodfellow2016deep" role="doc-biblioref">Goodfellow et al. 2016</a>)</span>. It helps stabilize and accelerate the training process by normalizing the activations of each layer.</p>
<p>Additionally, incorporating additional inputs such as scagnostics and the number of observations can potentially enhance prediction accuracy. Therefore, we allow the tuner to determine whether these inputs were necessary for optimal model performance.</p>
<p>The learning rate is a crucial hyperparameter, as it dictates the step size of the optimization algorithm. A high learning rate can help the model avoid local minima but risks overshooting and missing the global minimum. Conversely, a low learning rate smoothens the training process but makes the convergence time longer and increases the likelihood of getting trapped in local minima.</p>
<p>Our model was trained on the MASSIVE M3 high-performance computing platform <span class="citation" data-cites="goscinski2014multi">(<a href="refs.html#ref-goscinski2014multi" role="doc-biblioref">Goscinski et al. 2014</a>)</span>, using TensorFlow <span class="citation" data-cites="abadi2016tensorflow">(<a href="refs.html#ref-abadi2016tensorflow" role="doc-biblioref">Abadi et al. 2016</a>)</span> and Keras <span class="citation" data-cites="chollet2015keras">(<a href="refs.html#ref-chollet2015keras" role="doc-biblioref">Chollet et al. 2015</a>)</span>. During training, 80% of the training data was utilized for actual training, while the remaining 20% was used as validation data. The Bayesian optimization tuner conducted 100 trials to identify the best hyperparameter values based on validation root mean square error. The tuner then restored the best epoch of the best model from the trials. Additionally, we applied early stopping, terminating the training process if the validation root mean square error fails to improve for 50 epochs. The maximum allowed epochs was set at 2,000, although no models reached this threshold.</p>
<div class="cell">
<div id="tbl-hyperparameter" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-hyperparameter-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.3: Name of hyperparameters and their correspoding domain for the computer vision model.
</figcaption><div aria-describedby="tbl-hyperparameter-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead><tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">Hyperparameter</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Domain</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Number of base filters</td>
<td style="text-align: left;">{4, 8, 16, 32, 64}</td>
</tr>
<tr class="even">
<td style="text-align: left;">Dropout rate for convolutional blocks</td>
<td style="text-align: left;">[0.1, 0.6]</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Batch normalization for convolutional blocks</td>
<td style="text-align: left;">{false, true}</td>
</tr>
<tr class="even">
<td style="text-align: left;">Type of global pooling</td>
<td style="text-align: left;">{max, average}</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Ignore additional inputs</td>
<td style="text-align: left;">{false, true}</td>
</tr>
<tr class="even">
<td style="text-align: left;">Number of units for the fully-connected layer</td>
<td style="text-align: left;">{128, 256, 512, 1024, 2048}</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Batch normalization for the fully-connected layer</td>
<td style="text-align: left;">{false, true}</td>
</tr>
<tr class="even">
<td style="text-align: left;">Dropout rate for the fully-connected layer</td>
<td style="text-align: left;">[0.1, 0.6]</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Learning rate</td>
<td style="text-align: left;">[<span class="math inline">10^{-8}</span>, <span class="math inline">10^{-1}</span>]</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>Based on the tuning process described above, the optimized hyperparameter values are presented in <a href="#tbl-best-hyperparameter" class="quarto-xref">Table&nbsp;<span>3.4</span></a>. It was observable that a minimum of <span class="math inline">32</span> base filters was necessary, with the preferable choice being <span class="math inline">64</span> base filters for both the <span class="math inline">64 \times 64</span> and <span class="math inline">128 \times 128</span> models, mirroring the original VGG16 architecture. The optimized dropout rate for convolutional blocks hovered around <span class="math inline">0.4</span>, and incorporating batch normalization for convolutional blocks proved beneficial for performance.</p>
<p>All optimized models chose to retain the additional inputs, contributing to the reduction of validation error. The number of units required for the fully-connected layer was <span class="math inline">256</span>, a relatively modest number compared to the VGG16 classifier, suggesting that the problem at hand was less complex. The optimized learning rates were higher for models with higher resolution input, likely because models with more parameters are more prone to getting stuck in local minima, requiring a higher learning rate.</p>
<div class="cell">
<div id="tbl-best-hyperparameter" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-best-hyperparameter-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.4: Hyperparameters values for the optimized computer vision models with different input sizes.
</figcaption><div aria-describedby="tbl-best-hyperparameter-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="table do-not-create-environment cell caption-top table-sm table-striped small" data-quarto-postprocess="true">
<thead><tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">Hyperparameter</th>
<th style="text-align: center;" data-quarto-table-cell-role="th"><span class="math inline">32 \times 32</span></th>
<th style="text-align: center;" data-quarto-table-cell-role="th"><span class="math inline">64 \times 64</span></th>
<th style="text-align: center;" data-quarto-table-cell-role="th"><span class="math inline">128 \times 128</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Number of base filters</td>
<td style="text-align: left;">32</td>
<td style="text-align: left;">64</td>
<td style="text-align: left;">64</td>
</tr>
<tr class="even">
<td style="text-align: left;">Dropout rate for convolutional blocks</td>
<td style="text-align: left;">0.4</td>
<td style="text-align: left;">0.3</td>
<td style="text-align: left;">0.4</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Batch normalization for convolutional blocks</td>
<td style="text-align: left;">true</td>
<td style="text-align: left;">true</td>
<td style="text-align: left;">true</td>
</tr>
<tr class="even">
<td style="text-align: left;">Type of global pooling</td>
<td style="text-align: left;">max</td>
<td style="text-align: left;">average</td>
<td style="text-align: left;">average</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Ignore additional inputs</td>
<td style="text-align: left;">false</td>
<td style="text-align: left;">false</td>
<td style="text-align: left;">false</td>
</tr>
<tr class="even">
<td style="text-align: left;">Number of units for the fully-connected layer</td>
<td style="text-align: left;">256</td>
<td style="text-align: left;">256</td>
<td style="text-align: left;">256</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Batch normalization for the fully-connected layer</td>
<td style="text-align: left;">false</td>
<td style="text-align: left;">true</td>
<td style="text-align: left;">true</td>
</tr>
<tr class="even">
<td style="text-align: left;">Dropout rate for the fully-connected layer</td>
<td style="text-align: left;">0.2</td>
<td style="text-align: left;">0.4</td>
<td style="text-align: left;">0.1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Learning rate</td>
<td style="text-align: left;">0.0003</td>
<td style="text-align: left;">0.0006</td>
<td style="text-align: left;">0.0052</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
</section><section id="sec-model-results" class="level2" data-number="3.10"><h2 data-number="3.10" class="anchored" data-anchor-id="sec-model-results">
<span class="header-section-number">3.10</span> Results</h2>
<section id="model-performance" class="level3" data-number="3.10.1"><h3 data-number="3.10.1" class="anchored" data-anchor-id="model-performance">
<span class="header-section-number">3.10.1</span> Model Performance</h3>
<p>The test performance for the optimized models with three different input sizes are summarized in <a href="#tbl-performance" class="quarto-xref">Table&nbsp;<span>3.5</span></a>. Among these models, the <span class="math inline">32 \times 32</span> model consistently exhibited the best test performance. The mean absolute error of the <span class="math inline">32 \times 32</span> model indicated that the difference between <span class="math inline">\hat{D}</span> and <span class="math inline">D</span> was approximately <span class="math inline">0.43</span> on the test set, a negligible deviation considering the normal range of <span class="math inline">D</span> typically falls between <span class="math inline">0</span> and <span class="math inline">7</span>. The high <span class="math inline">R^2</span> values also suggested that the predictions were largely linearly correlated with the target.</p>
<p><a href="#fig-model-performance" class="quarto-xref">Figure&nbsp;<span>3.10</span></a> presents a hexagonal heatmap for <span class="math inline">D - \hat{D}</span> versus <span class="math inline">D</span>. The brown smoothing curves, fitted by generalized additive models <span class="citation" data-cites="hastie2017generalized">(<a href="refs.html#ref-hastie2017generalized" role="doc-biblioref">Hastie 2017</a>)</span>, demonstrate that all the optimized models perform admirably on the test sets when <span class="math inline">1.5 &lt; D &lt; 6</span>, where no structural issues are noticeable. However, over-predictions occurred when <span class="math inline">D &lt; 1.5</span>, while under-predictions occurred predominantly when <span class="math inline">\hat{D} &gt; 6</span>.</p>
<p>For input images representing null plots where <span class="math inline">D = 0</span>, it was expected that the models will over-predict the distance, as explained in <a href="#sec-model-lineup-evaluation" class="quarto-xref"><span>Section 3.5.1</span></a>. However, it can not explain the under-prediction issue. Therefore, we analysed the relationship between residuals and all the factors involved in the data generating process. We found that most issues actually arose from non-linearity problems and the presence of a second predictor in the regression model as illustrated in <a href="#fig-over-under" class="quarto-xref">Figure&nbsp;<span>3.11</span></a>. When the variance for the error distribution was small, the optimized model tended to under-predict the distance. Conversely, when the error distribution had a large variance, the model tended to over-predict the distance.</p>
<p>Since most of the deviation stemmed from the presence of non-linearity violations, to further investigate this, we split the test set based on violation types and re-evaluated the performance, as detailed in <a href="#tbl-performance-sub" class="quarto-xref">Table&nbsp;<span>3.6</span></a>. It was evident that metrics for null plots were notably worse compared to other categories. Furthermore, residual plots solely exhibiting non-normality issues were the easiest to predict, with very low test root mean square error (RMSE) at around <span class="math inline">0.3</span>. Residual plots with non-linearity issues were more challenging to assess than those with heteroskedasticity or non-normality issues. When multiple violations were introduced to a residual plot, the performance metrics typically lay between the metrics for each individual violation.</p>
<p>Based on the model performance metrics, we chose to use the best-performing model evaluated on the test set, namely the <span class="math inline">32 \times 32</span> model, for the subsequent analysis.</p>
<div class="cell">
<div id="tbl-performance" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.5: The test performance of three optimized models with different input sizes.
</figcaption><div aria-describedby="tbl-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead><tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th"></th>
<th style="text-align: center;" data-quarto-table-cell-role="th">RMSE</th>
<th style="text-align: center;" data-quarto-table-cell-role="th"><span class="math inline">R^2</span></th>
<th style="text-align: center;" data-quarto-table-cell-role="th">MAE</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Huber loss</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left; padding-left: 2em;" data-indentlevel="1"><span class="math inline">32 \times 32</span></td>
<td style="text-align: right;">0.660</td>
<td style="text-align: right;">0.901</td>
<td style="text-align: right;">0.434</td>
<td style="text-align: right;">0.181</td>
</tr>
<tr class="even">
<td style="text-align: left; padding-left: 2em;" data-indentlevel="1"><span class="math inline">64 \times 64</span></td>
<td style="text-align: right;">0.674</td>
<td style="text-align: right;">0.897</td>
<td style="text-align: right;">0.438</td>
<td style="text-align: right;">0.186</td>
</tr>
<tr class="odd">
<td style="text-align: left; padding-left: 2em;" data-indentlevel="1"><span class="math inline">128 \times 128</span></td>
<td style="text-align: right;">0.692</td>
<td style="text-align: right;">0.892</td>
<td style="text-align: right;">0.460</td>
<td style="text-align: right;">0.199</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-model-performance" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-model-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-model-performance-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="2400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-model-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.10: Hexagonal heatmap for difference in <span class="math inline">D</span> and <span class="math inline">\hat{D}</span> vs <span class="math inline">D</span> on test data for three optimized models with different input sizes. The brown lines are smoothing curves produced by fitting gnealized additive models. The area over the zero line in light yellow indicates under-prediction, and the area under the zero line in light green indicates over-prediction.
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-over-under" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-over-under-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-over-under-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="2400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-over-under-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.11: Scatter plots for difference in <span class="math inline">D</span> and <span class="math inline">\hat{D}</span> vs <span class="math inline">\sigma</span> on test data for the <span class="math inline">32 \times 32</span> optimized model. The data is grouped by whether the regression has only non-linearity violation, and whether it includes a second predictor in the regression formula. The brown lines are smoothing curves produced by fitting gnealized additive models. The area over the zero line in light yellow indicates under-prediction, and the area under the zero line in light green indicates over-prediction.
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div id="tbl-performance-sub" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-performance-sub-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.6: The test performance of the <span class="math inline">32 \times 32</span> model presented with different model violations.
</figcaption><div aria-describedby="tbl-performance-sub-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="table do-not-create-environment cell caption-top table-sm table-striped small" data-quarto-postprocess="true">
<thead><tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">Violations</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">#samples</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">RMSE</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">no violations</td>
<td style="text-align: right;">155</td>
<td style="text-align: right;">1.267</td>
</tr>
<tr class="even">
<td style="text-align: left;">non-linearity</td>
<td style="text-align: right;">2218</td>
<td style="text-align: right;">0.787</td>
</tr>
<tr class="odd">
<td style="text-align: left;">heteroskedasticity</td>
<td style="text-align: right;">1067</td>
<td style="text-align: right;">0.602</td>
</tr>
<tr class="even">
<td style="text-align: left;">non-linearity + heteroskedasticity</td>
<td style="text-align: right;">985</td>
<td style="text-align: right;">0.751</td>
</tr>
<tr class="odd">
<td style="text-align: left;">non-normality</td>
<td style="text-align: right;">1111</td>
<td style="text-align: right;">0.320</td>
</tr>
<tr class="even">
<td style="text-align: left;">non-linearity + non-normality</td>
<td style="text-align: right;">928</td>
<td style="text-align: right;">0.600</td>
</tr>
<tr class="odd">
<td style="text-align: left;">heteroskedasticity + non-normality</td>
<td style="text-align: right;">819</td>
<td style="text-align: right;">0.489</td>
</tr>
<tr class="even">
<td style="text-align: left;">non-linearity + heteroskedasticity + non-normality</td>
<td style="text-align: right;">717</td>
<td style="text-align: right;">0.620</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<!-- - check if j has an impact on residuals more carefully -->
<!-- - the RMSE has very little to do with j if x2 is not included. And its impact is not as large as sigma. -->
</section><section id="comparison-with-human-visual-inference-and-conventional-tests" class="level3" data-number="3.10.2"><h3 data-number="3.10.2" class="anchored" data-anchor-id="comparison-with-human-visual-inference-and-conventional-tests">
<span class="header-section-number">3.10.2</span> Comparison with Human Visual Inference and Conventional Tests</h3>
<section id="overview-of-the-human-subject-experiment" class="level4"><h4 class="anchored" data-anchor-id="overview-of-the-human-subject-experiment">Overview of the Human Subject experiment</h4>
<p>In order to check the validity of the proposed computer vision model, residual plots presented in the human subject experiment conducted by <span class="citation" data-cites="li2024plot">Li et al. (<a href="refs.html#ref-li2024plot" role="doc-biblioref">2024</a>)</span> will be assessed.</p>
<!-- The experiment revealed that conventional tests are more sensitive to weak departures from model assumptions than visual test, and they often reject the null hypothesis when departures are not visibly different from null residual plots. -->
<p>This study has collected 7,974 human responses to 1,152 lineups. Each lineup contains one randomly placed true residual plot and 19 null plots. Among the 1,152 lineups, 24 are attention check lineups in which the visual patterns are designed to be extremely obvious and very different from the corresponding to null plots, 36 are null lineups where all the lineups consist of only null plots, 279 are lineups with uniform predictor distribution evaluated by 11 participants, and the remaining 813 are lineups with discrete, skewed or normal predictor distribution evaluated by 5 participants. Attention check lineups and null lineups will not be assessed in the following analysis.</p>
<p>In <span class="citation" data-cites="li2024plot">Li et al. (<a href="refs.html#ref-li2024plot" role="doc-biblioref">2024</a>)</span>, the residual plots are simulated from a data generating process which is a special case of <a href="#eq-data-sim" class="quarto-xref">Equation&nbsp;<span>3.7</span></a>. The main characteristic is the model violations are introduced separately, meaning non-linearity and heteroskedasticity will not co-exist in one lineup but assigned uniformly to all lineups. Additionally, non-normality and multiple predictors are not considered in the experimental design.</p>
</section><section id="model-performance-on-the-human-evaluated-data" class="level4"><h4 class="anchored" data-anchor-id="model-performance-on-the-human-evaluated-data">Model Performance on the Human-evaluated Data</h4>
<div class="cell">
<div id="tbl-experiment-performance" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-experiment-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.7: The performance of the <span class="math inline">32 \times 32</span> model on the data used in the human subject experiment.
</figcaption><div aria-describedby="tbl-experiment-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead><tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">Violation</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">RMSE</th>
<th style="text-align: center;" data-quarto-table-cell-role="th"><span class="math inline">R^2</span></th>
<th style="text-align: center;" data-quarto-table-cell-role="th">MAE</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Huber loss</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">heteroskedasticity</td>
<td style="text-align: right;">0.721</td>
<td style="text-align: right;">0.852</td>
<td style="text-align: right;">0.553</td>
<td style="text-align: right;">0.235</td>
</tr>
<tr class="even">
<td style="text-align: left;">non-linearity</td>
<td style="text-align: right;">0.738</td>
<td style="text-align: right;">0.770</td>
<td style="text-align: right;">0.566</td>
<td style="text-align: right;">0.246</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>For each lineup used in <span class="citation" data-cites="li2024plot">Li et al. (<a href="refs.html#ref-li2024plot" role="doc-biblioref">2024</a>)</span>, there is one true residual plot and 19 null plots. While the distance <span class="math inline">D</span> for the true residual plot depends on the underlying data generating process, the distance <span class="math inline">D</span> for the null plots is zero. We have used our optimized computer vision model to estimate distance for both the true residual plots and the null plots. To have a fair comparison, <span class="math inline">H_0</span> will be rejected if the true residual plot has the greatest estimated distance among all plots in a lineup. Additionally, the appropriate conventional tests including the Ramsey Regression Equation Specification Error Test (RESET) <span class="citation" data-cites="ramsey1969tests">(<a href="refs.html#ref-ramsey1969tests" role="doc-biblioref">Ramsey 1969</a>)</span> for non-linearity and the Breusch-Pagan test <span class="citation" data-cites="breusch1979simple">(<a href="refs.html#ref-breusch1979simple" role="doc-biblioref">Breusch and Pagan 1979</a>)</span> for heteroskedasticity were applied on the same data for comparison.</p>
<p>The performance metrics of <span class="math inline">\hat{D}</span> for true residual plots are outlined in <a href="#tbl-experiment-performance" class="quarto-xref">Table&nbsp;<span>3.7</span></a>. It’s notable that all performance metrics are slightly worse than those evaluated on the test data. Nevertheless, the mean absolute error remains at a low level, and the linear correlation between the prediction and the true value remains very high. Consistent with results in <a href="#tbl-performance-sub" class="quarto-xref">Table&nbsp;<span>3.6</span></a>, lineups with non-linearity issues are more challenging to predict than those with heteroskedasticity issues.</p>
<p><a href="#tbl-human-conv-table" class="quarto-xref">Table&nbsp;<span>3.8</span></a> provides a summary of the agreement between decisions made by the computer vision model and conventional tests. The agreement rates between conventional tests and the computer vision model are 85.95% and 79.69% for residual plots containing heteroskedasticity and non-linearity patterns, respectively. These figures are higher than those calculated for visual tests conducted by human, indicating that the computer vision model exhibits behaviour more akin to the best available conventional tests. However, <a href="#fig-conv-mosaic" class="quarto-xref">Figure&nbsp;<span>3.12</span></a> shows that the computer vision model does not always reject when the conventional tests reject. And a small number of plots will be rejected by computer vision model but not by conventional tests. This suggests that conventional tests are more sensitive than the computer vision model.</p>
<p><a href="#fig-pcp" class="quarto-xref">Figure&nbsp;<span>3.14</span></a> further illustrates the decisions made by visual tests conducted by human, computer vision models, and conventional tests, using a parallel coordinate plots. It can be observed that all three tests will agree with each other for around 50% of the cases. When visual tests conducted by human do not reject, there are substantial amount of cases where computer vision model also do not reject but conventional tests reject. There are much fewer cases that do not reject by visual tests and conventional tests, but is rejected by computer vision models. This indicates computer vision model can behave like visual tests conducted by human better than conventional tests. Moreover, there are great proportion of cases where visual tests conducted by human is the only test who does not reject.</p>
<p>When plotting the decision against the distance, as illustrated in <a href="#fig-power" class="quarto-xref">Figure&nbsp;<span>3.13</span></a>, several notable observations emerge. Firstly, compared to conventional tests, the computer vision model tends to have fewer rejected cases when <span class="math inline">D &lt; 2</span> and fewer non-rejected cases when <span class="math inline">2&lt; D &lt; 4</span>. This suggests tests based on the computer vision model are less sensitive to small deviations from model assumptions than conventional tests but more sensitive to moderate deviations. Additionally, visual tests demonstrate the lowest sensitivity to residual plots with small distances where not many residual plots are rejected when <span class="math inline">D &lt; 2</span>. Similarly, for large distances where <span class="math inline">D &gt; 4</span>, almost all residual plots are rejected by the computer vision model and conventional tests, but for visual tests conducted by humans, the threshold is higher with <span class="math inline">D &gt; 5</span>.</p>
<p>In <a href="#fig-power" class="quarto-xref">Figure&nbsp;<span>3.13</span></a>, rejection decisions are fitted by logistic regression models with no intercept terms and an offset equals to <span class="math inline">\text{log}(0.05/0.95)</span>. The fitted curves for the computer vision model fall between those of conventional tests and visual tests for both non-linearity and heteroskedasticity, which means there is still potential to refine the computer vision model to better align its behaviour with visual tests conducted by humans.</p>
<p>In the experiment conducted in <span class="citation" data-cites="li2024plot">Li et al. (<a href="refs.html#ref-li2024plot" role="doc-biblioref">2024</a>)</span>, participants were allowed to make multiple selections for a lineup. The weighted detection rate was computed by assigning weights to each detection. If the participant selected zero plots, a weight of 0.05 was assigned; otherwise, if the true residual plot was detected, the weight was 1 divided by the number of selections. This weighted detection rate allow us to assess the quality of the distance measure purposed in this chapter, by using the <span class="math inline">\delta</span>-difference statistic. The <span class="math inline">\delta</span>-difference is originally defined by <span class="citation" data-cites="chowdhury2018measuring">Chowdhury et al. (<a href="refs.html#ref-chowdhury2018measuring" role="doc-biblioref">2018</a>)</span>, is given by</p>
<p><span class="math display">
\delta = \bar{d}_{\text{true}} - \underset{j}{\text{max}}\left(\bar{d}_{\text{null}}^{(j)}\right) \quad \text{for}~j = 1,...,m-1,
</span></p>
<p>where <span class="math inline">\bar{d}_{\text{null}}^{(j)}</span> is the mean distance between the <span class="math inline">j</span>-th null plot and the other null plots, <span class="math inline">\bar{d}_{\text{true}}</span> is the mean distance between the true residual plot and null plots, and <span class="math inline">m</span> is the number of plots in a lineup. These mean distances are used because, as noted by <span class="citation" data-cites="chowdhury2018measuring">Chowdhury et al. (<a href="refs.html#ref-chowdhury2018measuring" role="doc-biblioref">2018</a>)</span>, the distances can vary depending on which data plot is used for comparison. For instance, with three null plots, A, B and C, the distance between A and B may differ from the distance between A and C. To obtain a consistent distance for null plot A, averaging is necessary. However, this approach is not applicable to the distance proposed in this chapter, as we only compare the residual plot against a theoretically good residual plot. Consequently, the statistic must be adjusted to evaluate our distance measure effectively.</p>
<p>One important aspect that the <span class="math inline">\delta</span>-difference was designed to capture is the empirical distribution of distances for null plot. If we were to replace the mean distances <span class="math inline">\bar{d}_{\text{null}}^{(j)}</span> directly with <span class="math inline">D_{\text{null}}^{(j)}</span>, the distance of the <span class="math inline">j</span>-th null plot, the resulting distribution would be degenerate, since <span class="math inline">D_{null}</span> equals zero by definition. Additionally, <span class="math inline">D</span> can not be derived from an image, meaning it falls outside the scope of the distances considered by <span class="citation" data-cites="chowdhury2018measuring">Chowdhury et al. (<a href="refs.html#ref-chowdhury2018measuring" role="doc-biblioref">2018</a>)</span>. Instead, the focus should be on the empirical distribution of <span class="math inline">\hat{D}</span>, as it influences decision-making. Therefore, the adjusted <span class="math inline">\delta</span>-different is defined as</p>
<p><span class="math display">
\delta_{\text{adj}} = \hat{D} - \underset{j}{\text{max}}\left(\hat{D}_{\text{null}}^{(j)}\right) \quad \text{for}~j = 1,...,m-1,
</span></p>
<p>where <span class="math inline">\hat{D}_{\text{null}}^{(j)}</span> is the estimated distance for the <span class="math inline">j</span>-th null plot, and <span class="math inline">m</span> is the number of plots in a lineup.</p>
<p><a href="#fig-delta" class="quarto-xref">Figure&nbsp;<span>3.15</span></a> displays the scatter plot of the weighted detection rate vs the adjusted <span class="math inline">\delta</span>-difference. It indicates that the weighted detection rate increases as the adjusted <span class="math inline">\delta</span>-difference increases, particularly when the adjusted <span class="math inline">\delta</span>-difference is greater than zero. A negative adjusted <span class="math inline">\delta</span>-difference suggests that there is at least one null plot in the lineup with a stronger visual signal than the true residual plot. In some instances, the weighted detection rate is close to one, yet the adjusted <span class="math inline">\delta</span>-difference is negative. This discrepancy implies that the distance measure, or the estimated distance, may not perfectly reflect actual human behaviour.</p>
<div class="cell">
<div id="tbl-human-conv-table" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-human-conv-table-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.8: Summary of the comparison of decisions made by computer vision model with decisions made by conventional tests and visual tests conducted by human.
</figcaption><div aria-describedby="tbl-human-conv-table-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead><tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">Violations</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">#Samples</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">#Agreements</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Agreement rate</th>
</tr></thead>
<tbody>
<tr class="odd" data-grouplength="2">
<td colspan="4" style="border-bottom: 1px solid"><strong>Compared with conventional tests</strong></td>
</tr>
<tr class="even">
<td style="text-align: left; padding-left: 2em;" data-indentlevel="1">heteroskedasticity</td>
<td style="text-align: right;">540</td>
<td style="text-align: right;">464</td>
<td style="text-align: right;">0.8593</td>
</tr>
<tr class="odd">
<td style="text-align: left; padding-left: 2em;" data-indentlevel="1">non-linearity</td>
<td style="text-align: right;">576</td>
<td style="text-align: right;">459</td>
<td style="text-align: right;">0.7969</td>
</tr>
<tr class="even" data-grouplength="2">
<td colspan="4" style="border-bottom: 1px solid"><strong>Compared with visual tests conducted by human</strong></td>
</tr>
<tr class="odd">
<td style="text-align: left; padding-left: 2em;" data-indentlevel="1">heteroskedasticity</td>
<td style="text-align: right;">540</td>
<td style="text-align: right;">367</td>
<td style="text-align: right;">0.6796</td>
</tr>
<tr class="even">
<td style="text-align: left; padding-left: 2em;" data-indentlevel="1">non-linearity</td>
<td style="text-align: right;">576</td>
<td style="text-align: right;">385</td>
<td style="text-align: right;">0.6684</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-conv-mosaic" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-conv-mosaic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-conv-mosaic-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-conv-mosaic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.12: Rejection rate (<span class="math inline">p</span>-value <span class="math inline">\leq0.05</span>) of computer vision models conditional on conventional tests on non-linearity (left) and heteroskedasticity (right) lineups displayed using a mosaic plot. When the conventional test fails to reject, the computer vision mostly fails to reject the same plot as well as indicated by the height of the top right yellow rectangle, but there are non negliable amount of plots where the conventoinal test rejects but the computer vision model fails to reject as indicated by the width of the top left yellow rectangle.
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-power" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-power-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-power-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-power-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.13: Comparison of power of visual tests, conventional tests and the computer vision model. Marks along the x-axis at the bottom of the plot represent rejections made by each type of test. Marks at the top of the plot represent acceptances. Power curves are fitted by logistic regression models with no intercept but an offset equals to <span class="math inline">\text{log}(0.05/0.95)</span>.
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-pcp" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-pcp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-pcp-1.png" class="img-fluid figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pcp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.14: Parallel coordinate plots of decisions made by computer vision model, conventional tests and visual tests made by human.
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-delta" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-delta-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-delta-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-delta-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.15: A weighted detection rate vs adjusted <span class="math inline">\delta</span>-difference plot. The brown line is smoothing curve produced by fitting gnealized additive models.
</figcaption></figure>
</div>
</div>
</div>
</section></section></section><section id="sec-examples" class="level2" data-number="3.11"><h2 data-number="3.11" class="anchored" data-anchor-id="sec-examples">
<span class="header-section-number">3.11</span> Examples</h2>
<p>In this section, we present the performance of trained computer vision model on three example datasets. These include the dataset associated with the residual plot displaying a “left-triangle” shape, as displayed in <a href="#fig-false-finding" class="quarto-xref">Figure&nbsp;<span>3.1</span></a>, along with the Boston housing dataset <span class="citation" data-cites="harrison1978hedonic">(<a href="refs.html#ref-harrison1978hedonic" role="doc-biblioref">Harrison Jr and Rubinfeld 1978</a>)</span>, and the “dino” datasets from the <code>datasauRus</code> R package <span class="citation" data-cites="datasaurus">(<a href="refs.html#ref-datasaurus" role="doc-biblioref">Davies et al. 2022</a>)</span>.</p>
<p>The first example illustrates a scenario where both the computer vision model and human visual inspection successfully avoid rejecting <span class="math inline">H_0</span> when <span class="math inline">H_0</span> is true, contrary to conventional tests. This underscores the necessity of visually examining the residual plot.</p>
<p>In the second example, we encounter a more pronounced violation of the model, resulting in rejection of <span class="math inline">H_0</span> by all three tests. This highlights the practicality of the computer vision model, particularly for less intricate tasks.</p>
<p>The third example presents a situation where the model deviation is non-typical. Here, the computer vision model and human visual inspection reject <span class="math inline">H_0</span>, whereas some commonly used conventional tests do not. This emphasizes the benefits of visual inspection and the unique advantage of the computer vision model, which, like humans, makes decisions based on visual discoveries.</p>
<section id="left-triangle" class="level3" data-number="3.11.1"><h3 data-number="3.11.1" class="anchored" data-anchor-id="left-triangle">
<span class="header-section-number">3.11.1</span> Left-triangle</h3>
<p>In <a href="#sec-model-introduction" class="quarto-xref"><span>Section 3.1</span></a>, we presented an example residual plot showcased in <a href="#fig-false-finding" class="quarto-xref">Figure&nbsp;<span>3.1</span></a>, illustrating how humans might misinterpret the “left-triangle” shape as indicative of heteroskedasticity. Additionally, the Breusch-Pagan test yielded a rejection with a <span class="math inline">p</span>-value of 0.046, despite the residuals originating from a correctly specified model. <a href="#fig-false-lineup" class="quarto-xref">Figure&nbsp;<span>3.17</span></a> offers a lineup for this fitted model, showcasing various degrees of “left-triangle” shape across all residual plots. This phenomenon is evidently caused by the skewed distribution of the fitted values. Notably, if the residual plot were evaluated through a visual test, it would not be rejected since the true residual plot positioned at 10 can not be distinguished from the others.</p>
<p><a href="#fig-false-check" class="quarto-xref">Figure&nbsp;<span>3.16</span></a> presents the results of the assessment by the computer vision model. Notably, the observed visual signal strength is considerably lower than the 95% sample quantile of the null distribution. Moreover, the bootstrapped distribution suggests that it is highly improbable for the fitted model to be misspecified as the majority of bootstrapped fitted models will not be rejected. Thus, for this particular fitted model, both the visual test and the computer vision model will not reject <span class="math inline">H_0</span>. However, the Breusch-Pagan test will reject <span class="math inline">H_0</span> because it can not effectively utilize information from null plots.</p>
<p>The attention map at <a href="#fig-false-check" class="quarto-xref">Figure&nbsp;<span>3.16</span></a>B suggests that the estimation is highly influenced by the top-right and bottom-right part of the residual plot, as it forms two vertices of the triangular shape. A principal component analysis (PCA) is also performed on the output of the global pooling layer of the computer vision model. As mentioned in <span class="citation" data-cites="simonyan2014very">Simonyan and Zisserman (<a href="refs.html#ref-simonyan2014very" role="doc-biblioref">2014</a>)</span>, a computer vision model built upon the convolutional blocks can be viewed as a feature extractor. For the <span class="math inline">32 \times 32</span> model, there are 256 features outputted from the global pooling layer, which can be further used for different visual tasks not limited to distance prediction. To see if these features can be effectively used for distinguishing null plots and true residual plot, we linearly project them into the first and second principal components space as shown in <a href="#fig-false-check" class="quarto-xref">Figure&nbsp;<span>3.16</span></a>D. It can be observed that because the bootstrapped plots are mostly similar to the null plots, the points drawn in different colours are mixed together. The true residual plot is also covered by both the cluster of null plots and cluster of bootstrapped plots. This accurately reflects our understanding of <a href="#fig-false-lineup" class="quarto-xref">Figure&nbsp;<span>3.17</span></a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-false-check" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-false-check-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-false-check-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-false-check-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.16: A summary of the residual plot assessment evaluted on 200 null plots and 200 bootstrapped plots. (A) The true residual plot exhibiting a “left-triangle” shape. (B) The attention map produced by computing the gradient of the output with respect to the greyscale input. (C) The density plot of estimated distance for null plots and bootstrapped plots. The green area indicates the distribution of estimated distances for bootstrapped plots, while the yellow area represents the distribution of estimated distances for null plots. The fitted model will not be rejected since <span class="math inline">\hat{D} &lt; Q_{null}(0.95)</span>. (D) plot of first two principal components of features extracted from the global pooling layer of the computer vision model.
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-false-lineup" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-false-lineup-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-false-lineup-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-false-lineup-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.17: A lineup of residual plots displaying “left-triangle” visual patterns. The true residual plot occupies position 10, yet there are no discernible visual patterns that distinguish it from the other plots.
</figcaption></figure>
</div>
</div>
</div>
</section><section id="boston-housing" class="level3" data-number="3.11.2"><h3 data-number="3.11.2" class="anchored" data-anchor-id="boston-housing">
<span class="header-section-number">3.11.2</span> Boston Housing</h3>
<p>The Boston housing dataset, originally published by <span class="citation" data-cites="harrison1978hedonic">Harrison Jr and Rubinfeld (<a href="refs.html#ref-harrison1978hedonic" role="doc-biblioref">1978</a>)</span>, offers insights into housing in the Boston, Massachusetts area. For illustration purposes, we utilize a reduced version from Kaggle, comprising 489 rows and 4 columns: average number of rooms per dwelling (RM), percentage of lower status of the population (LSTAT), pupil-teacher ratio by town (PTRATIO), and median value of owner-occupied homes in $1000’s (MEDV). In our analysis, MEDV will serve as the response variable, while the other columns will function as predictors in a linear regression model. Our primary focus is to detect non-linearity, because the relationships between RM and MEDV or LSTAT and MEDV are non-linear.</p>
<p><a href="#fig-boston-check" class="quarto-xref">Figure&nbsp;<span>3.18</span></a> displays the residual plot and the assessment conducted by the computer vision model. A clear non-linearity pattern resembling a “U” shape is shown in the plot A. Furthermore, the RESET test yields a very small <span class="math inline">p</span>-value. The estimated distance <span class="math inline">\hat{D}</span> significantly exceeds <span class="math inline">Q_{null}(0.95)</span>, leading to rejection of <span class="math inline">H_0</span>. The bootstrapped distribution also suggests that almost all the bootstrapped fitted models will be rejected, indicating that the fitted model is unlikely to be correctly specified. The attention map in plot B suggests the center of the image has higher leverage than other areas, and it is the turning point of the “U” shape. The CPA provided in plot D shows two distinct clusters of data points, further underling the visual differences between bootstrapped plots and null plots. This coincides the findings from <a href="#fig-boston-lineup" class="quarto-xref">Figure&nbsp;<span>3.19</span></a>, where the true plot exhibiting a “U” shape is visually distinctive from null plots. If a visual test is conducted by human, <span class="math inline">H_0</span> will also be rejected.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-boston-check" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-boston-check-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-boston-check-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-boston-check-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.18: A summary of the residual plot assessment for the Boston housing fitted model evaluted on 200 null plots and 200 bootstrapped plots. (A) The true residual plot exhibiting a “U” shape. (B) The attention map produced by computing the gradient of the output with respect to the greyscale input. (C) The density plot of estimated distance for null plots and bootstrapped plots. The blue area indicates the distribution of estimated distances for bootstrapped plots, while the yellow area represents the distribution of estimated distances for null plots. The fitted model will be rejected since <span class="math inline">\hat{D} \geq Q_{null}(0.95)</span>. (D) plot of first two principal components of features extracted from the global pooling layer of the computer vision model.
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-boston-lineup" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-boston-lineup-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-boston-lineup-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-boston-lineup-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.19: A lineup of residual plots for the Boston housing fitted model. The true residual plot is at position 7. It can be easily identified as the most different plot.
</figcaption></figure>
</div>
</div>
</div>
</section><section id="datasaurus" class="level3" data-number="3.11.3"><h3 data-number="3.11.3" class="anchored" data-anchor-id="datasaurus">
<span class="header-section-number">3.11.3</span> DatasauRus</h3>
<p>The computer vision model possesses the capability to detect not only typical issues like non-linearity, heteroskedasticity, and non-normality but also artifact visual patterns resembling real-world objects, as long as they do not appear in null plots. These visual patterns can be challenging to categorize in terms of model violations. Therefore, we will employ the RESET test, the Breusch-Pagan test, and the Shapiro-Wilk test <span class="citation" data-cites="shapiro1965analysis">(<a href="refs.html#ref-shapiro1965analysis" role="doc-biblioref">Shapiro and Wilk 1965</a>)</span> for comparison.</p>
<p>The “dino” dataset within the <code>datasauRus</code> R package exemplifies this scenario. With only two columns, x and y, fitting a regression model to this data yields a residual plot resembling a “dinosaur”, as displayed in <a href="#fig-dino-check" class="quarto-xref">Figure&nbsp;<span>3.20</span></a>A. Unsurprisingly, this distinct residual plot stands out in a lineup, as shown in <a href="#fig-dino-lineup" class="quarto-xref">Figure&nbsp;<span>3.21</span></a>. A visual test conducted by humans would undoubtedly reject <span class="math inline">H_0</span>.</p>
<p>According to the residual plot assessment by the computer vision model, <span class="math inline">\hat{D}</span> exceeds <span class="math inline">Q_{null}(0.95)</span>, warranting a rejection of <span class="math inline">H_0</span>. Additionally, most of the bootstrapped fitted models will be rejected, indicating an misspecified model. However, both the RESET test and the Breusch-Pagan test yield <span class="math inline">p</span>-values greater than 0.3, leading to a non-rejection of <span class="math inline">H_0</span>. Only the Shapiro-Wilk test rejects the normality assumption with a small <span class="math inline">p</span>-value.</p>
<p>More importantly, the attention map in <a href="#fig-dino-check" class="quarto-xref">Figure&nbsp;<span>3.20</span></a>B clearly exhibits a “dinosaur” shape, strongly suggesting the prediction of the distance is based on human perceptible visual patterns. The computer vision model is also capable of capturing the contour or the outline of the embedded shape, just like human being reading residual plots. The PCA in <a href="#fig-dino-check" class="quarto-xref">Figure&nbsp;<span>3.20</span></a>D also shows that the cluster of bootstrapped plots is at the corner of the cluster of null plots.</p>
<p>More importantly, the attention map in <a href="#fig-dino-check" class="quarto-xref">Figure&nbsp;<span>3.20</span></a>B clearly exhibits a “dinosaur” shape, strongly suggesting that the distance prediction is based on human-perceptible visual patterns. The computer vision model effectively captures the contour or outline of the embedded shape, similar to how humans interpret residual plots. Additionally, the PCA in <a href="#fig-dino-check" class="quarto-xref">Figure&nbsp;<span>3.20</span></a>D demonstrates that the cluster of bootstrapped plots is positioned at the corner of the cluster of null plots.</p>
<p>In practice, without accessing the residual plot, it would be challenging to identify the artificial pattern of the residuals. Moreover, conducting a normality test for a fitted regression model is not always standard practice among analysts. Even when performed, violating the normality assumption is sometimes deemed acceptable, especially considering the application of quasi-maximum likelihood estimation in linear regression. This example underscores the importance of evaluating residual plots and highlights how the proposed computer vision model can facilitate this process.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-dino-check" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-dino-check-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-dino-check-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dino-check-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.20: A summary of the residual plot assessment for the datasauRus fitted model evaluted on 200 null plots and 200 bootstrapped plots. (A) The residual plot exhibits a “dinosaur” shape. (B) The attention map produced by computing the gradient of the output with respect to the greyscale input. (C) The density plot of estimated distance for null plots and bootstrapped plots. The blue area indicates the distribution of estimated distances for bootstrapped plots, while the yellow area represents the distribution of estimated distances for null plots. The fitted model will be rejected since <span class="math inline">\hat{D} \geq Q_{null}(0.95)</span>. (D) plot of first two principal components of features extracted from the global pooling layer of the computer vision model.
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-dino-lineup" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="!h">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-dino-lineup-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="03-chap3_files/figure-html/fig-dino-lineup-1.png" class="img-fluid figure-img" data-fig-pos="!h" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dino-lineup-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.21: A lineup of residual plots for the fitted model on the “dinosaur” dataset. The true residual plot is at position 17. It can be easily identified as the most different plot as the visual pattern is extremly artificial.
</figcaption></figure>
</div>
</div>
</div>
</section></section><section id="limitations-and-future-work" class="level2" data-number="3.12"><h2 data-number="3.12" class="anchored" data-anchor-id="limitations-and-future-work">
<span class="header-section-number">3.12</span> Limitations and Future Work</h2>
<p>Despite the computer vision model performing well with general cases under the synthetic data generation scheme and the three examples used in this chapter, this study has several limitations that could guide future work.</p>
<p>The proposed distance measure assumes that the true model is a classical normal linear regression model, which can be restrictive. Although this chapter does not address the relaxation of this assumption, there are potential methods to evaluate other types of regression models. The most comprehensive approach would be to define a distance measure for each different class of regression model and then train the computer vision model following the methodology described in this chapter. To accelerate training, one could use the convolutional blocks of our trained model as a feature extractor and perform transfer learning on top of it, as these blocks effectively capture shapes in residual plots. Another approach would be to transform the residuals so they are roughly normally distributed and have constant variance. If only raw residuals are used, the distance-based statistical testing compares the difference in distance to a classical normal linear regression model for the true plot and null plots. This comparison is meaningful only if the difference can be identified by the distance measure proposed in this chapter.</p>
<p>There are other types of residual plots commonly used in diagnostics, such as residuals vs.&nbsp;predictor and quantile-quantile plots. In this study, we focused on the most commonly used residual plot as a starting point for exploring the new field of automated visual inference. Similarly, we did not explore other, more sophisticated computer vision model architectures and specifications for the same reason. While the performance of the computer vision model is acceptable, there is still room for improvement to achieve behavior more closely resembling that of humans interpreting residual plots. This may require external survey data or human subject experiment data to understand the fundamental differences between our implementation and human evaluation.</p>
</section><section id="conclusion" class="level2" data-number="3.13"><h2 data-number="3.13" class="anchored" data-anchor-id="conclusion">
<span class="header-section-number">3.13</span> Conclusion</h2>
<p>In this chapter, we have introduced a distance measure based on Kullback-Leibler divergence to quantify the disparity between the residual distribution of a fitted classical normal linear regression model and the reference residual distribution assumed under correct model specification. This distance measure effectively captures the magnitude of model violations in misspecified models. We propose a computer vision model to estimate this distance, utilizing the residual plot of the fitted model as input. The resulting estimated distance serves as the foundation for constructing a single Model Violations Index (MVI), facilitating the quantification of various model violations.</p>
<p>Moreover, the estimated distance enables the development of a formal statistical testing procedure by evaluating a large number of null plots generated from the fitted model. Additionally, employing bootstrapping techniques and refitting the regression model allows us to ascertain how frequently the fitted model is considered misspecified if data were repeatedly obtained from the same data generating process.</p>
<p>The trained computer vision model demonstrates strong performance on both the training and test sets, although it exhibits slightly lower performance on residual plots with non-linearity visual patterns compared to other types of violations. The statistical tests relying on the estimated distance predicted by the computer vision model exhibit lower sensitivity compared to conventional tests but higher sensitivity compared to visual tests conducted by humans. While the estimated distance generally mirrors the strength of the visual signal perceived by humans, there remains scope for further improvement in its performance.</p>
<p>Several examples are provided to showcase the effectiveness of the proposed method across different scenarios, emphasizing the similarity between visual tests and distance-based tests. Overall, both visual tests and distance-based tests can be viewed as ensemble of tests, aiming to assess any violations of model assumptions collectively. In contrast, individual residual diagnostic tests such as the RESET test and the Breusch-Pagan test only evaluate specific violations of model assumptions. In practice, selecting an appropriate set of statistical tests for regression diagnostics can be challenging, particularly given the necessity of adjusting the significance level for each test.</p>
<p>Our method holds significant value as it helps alleviate a portion of analysts’ workload associated with assessing residual plots. While we recommend analysts to continue reading residual plots whenever feasible, as they offer invaluable insights, our approach serves as a valuable tool for automating the diagnostic process or for supplementary purposes when needed.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-abadi2016tensorflow" class="csl-entry" role="listitem">
Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., and others (2016), <span>“Tensorflow: Large-scale machine learning on heterogeneous distributed systems,”</span> <em>arXiv preprint arXiv:1603.04467</em>.
</div>
<div id="ref-belsley1980regression" class="csl-entry" role="listitem">
Belsley, D. A., Kuh, E., and Welsch, R. E. (1980), <em>Regression diagnostics: Identifying influential data and sources of collinearity</em>, John Wiley &amp; Sons.
</div>
<div id="ref-breusch1979simple" class="csl-entry" role="listitem">
Breusch, T. S., and Pagan, A. R. (1979), <span>“A simple test for heteroscedasticity and random coefficient variation,”</span> <em>Econometrica: Journal of the Econometric Society</em>, JSTOR, 1287–1294.
</div>
<div id="ref-brunetti2018computer" class="csl-entry" role="listitem">
Brunetti, A., Buongiorno, D., Trotta, G. F., and Bevilacqua, V. (2018), <span>“Computer vision and deep learning techniques for pedestrian detection and tracking: A survey,”</span> <em>Neurocomputing</em>, Elsevier, 300, 17–33.
</div>
<div id="ref-buja2009statistical" class="csl-entry" role="listitem">
Buja, A., Cook, D., Hofmann, H., Lawrence, M., Lee, E.-K., Swayne, D. F., and Wickham, H. (2009), <span>“Statistical inference for exploratory data analysis and model diagnostics,”</span> <em>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</em>, The Royal Society Publishing, 367, 4361–4383.
</div>
<div id="ref-chen2020convolutional" class="csl-entry" role="listitem">
Chen, Y., Su, S., and Yang, H. (2020), <span>“Convolutional neural network analysis of recurrence plots for anomaly detection,”</span> <em>International Journal of Bifurcation and Chaos</em>, World Scientific, 30, 2050002.
</div>
<div id="ref-chollet2015keras" class="csl-entry" role="listitem">
Chollet, F., and others (2015), <span>“Keras,”</span> <a href="https://keras.io" class="uri">https://keras.io</a>.
</div>
<div id="ref-chopra2005learning" class="csl-entry" role="listitem">
Chopra, S., Hadsell, R., and LeCun, Y. (2005), <span>“Learning a similarity metric discriminatively, with application to face verification,”</span> in <em>2005 IEEE computer society conference on computer vision and pattern recognition (CVPR’05)</em>, IEEE, pp. 539–546.
</div>
<div id="ref-chowdhury2018measuring" class="csl-entry" role="listitem">
Chowdhury, N. R., Cook, D., Hofmann, H., and Majumder, M. (2018), <span>“Measuring lineup difficulty by matching distance metrics with subject choices in crowd-sourced data,”</span> <em>Journal of Computational and Graphical Statistics</em>, Taylor &amp; Francis, 27, 132–145.
</div>
<div id="ref-chu2019automatic" class="csl-entry" role="listitem">
Chu, H., Liao, X., Dong, P., Chen, Z., Zhao, X., and Zou, J. (2019), <span>“An automatic classification method of well testing plot based on convolutional neural network (CNN),”</span> <em>Energies</em>, MDPI, 12, 2846.
</div>
<div id="ref-cook1982residuals" class="csl-entry" role="listitem">
Cook, R. D., and Weisberg, S. (1982), <em>Residuals and influence in regression</em>, New York: Chapman; Hall.
</div>
<div id="ref-datasaurus" class="csl-entry" role="listitem">
Davies, R., Locke, S., and D’Agostino McGowan, L. (2022), <em><a href="https://CRAN.R-project.org/package=datasauRus">datasauRus: Datasets from the datasaurus dozen</a></em>.
</div>
<div id="ref-davison1997bootstrap" class="csl-entry" role="listitem">
Davison, A. C., and Hinkley, D. V. (1997), <em>Bootstrap methods and their application</em>, Cambridge university press.
</div>
<div id="ref-efron1994introduction" class="csl-entry" role="listitem">
Efron, B., and Tibshirani, R. J. (1994), <em>An introduction to the bootstrap</em>, Chapman; Hall/CRC.
</div>
<div id="ref-emami2012facial" class="csl-entry" role="listitem">
Emami, S., and Suciu, V. P. (2012), <span>“Facial recognition using OpenCV,”</span> <em>Journal of Mobile, Embedded and Distributed Systems</em>, 4, 38–43.
</div>
<div id="ref-fieberg2024using" class="csl-entry" role="listitem">
Fieberg, J., Freeman, S., and Signer, J. (2024), <span>“Using lineups to evaluate goodness of fit of animal movement models,”</span> <em>Methods in Ecology and Evolution</em>, Wiley Online Library.
</div>
<div id="ref-frisch1933partial" class="csl-entry" role="listitem">
Frisch, R., and Waugh, F. V. (1933), <span>“Partial time regressions as compared with individual trends,”</span> <em>Econometrica: Journal of the Econometric Society</em>, JSTOR, 387–401.
</div>
<div id="ref-fukushima1982neocognitron" class="csl-entry" role="listitem">
Fukushima, K., and Miyake, S. (1982), <span>“Neocognitron: A new algorithm for pattern recognition tolerant of deformations and shifts in position,”</span> <em>Pattern recognition</em>, Elsevier, 15, 455–469.
</div>
<div id="ref-goodfellow2016deep" class="csl-entry" role="listitem">
Goodfellow, I., Bengio, Y., and Courville, A. (2016), <em>Deep learning</em>, MIT press.
</div>
<div id="ref-goscinski2014multi" class="csl-entry" role="listitem">
Goscinski, W. J., McIntosh, P., Felzmann, U., Maksimenko, A., Hall, C. J., Gureyev, T., Thompson, D., Janke, A., Galloway, G., Killeen, N. E., and others (2014), <span>“The multi-modal australian ScienceS imaging and visualization environment (MASSIVE) high performance computing infrastructure: Applications in neuroscience and neuroinformatics research,”</span> <em>Frontiers in Neuroinformatics</em>, Frontiers Media SA, 8, 30.
</div>
<div id="ref-hailesilassie2019financial" class="csl-entry" role="listitem">
Hailesilassie, T. (2019), <span>“Financial market prediction using recurrence plot and convolutional neural network,”</span> Preprints.
</div>
<div id="ref-harrison1978hedonic" class="csl-entry" role="listitem">
Harrison Jr, D., and Rubinfeld, D. L. (1978), <span>“Hedonic housing prices and the demand for clean air,”</span> <em>Journal of environmental economics and management</em>, Elsevier, 5, 81–102.
</div>
<div id="ref-hastie2017generalized" class="csl-entry" role="listitem">
Hastie, T. J. (2017), <span>“Generalized additive models,”</span> in <em>Statistical models in s</em>, Routledge, pp. 249–307.
</div>
<div id="ref-hatami2018classification" class="csl-entry" role="listitem">
Hatami, N., Gavet, Y., and Debayle, J. (2018), <span>“Classification of time-series images using deep convolutional neural networks,”</span> in <em>Tenth international conference on machine vision (ICMV 2017)</em>, SPIE, pp. 242–249.
</div>
<div id="ref-hermite1864nouveau" class="csl-entry" role="listitem">
Hermite, M. (1864), <em>Sur un nouveau d<span>é</span>veloppement en s<span>é</span>rie des fonctions</em>, Imprimerie de Gauthier-Villars.
</div>
<div id="ref-hyndman1996sample" class="csl-entry" role="listitem">
Hyndman, R. J., and Fan, Y. (1996), <span>“Sample quantiles in statistical packages,”</span> <em>The American Statistician</em>, Taylor &amp; Francis, 50, 361–365.
</div>
<div id="ref-kingma2014adam" class="csl-entry" role="listitem">
Kingma, D. P., and Ba, J. (2014), <span>“Adam: A method for stochastic optimization,”</span> <em>arXiv preprint arXiv:1412.6980</em>.
</div>
<div id="ref-krishnan2021hierarchical" class="csl-entry" role="listitem">
Krishnan, G., and Hofmann, H. (2021), <span>“Hierarchical decision ensembles-an inferential framework for uncertain human-AI collaboration in forensic examinations,”</span> <em>arXiv preprint arXiv:2111.01131</em>.
</div>
<div id="ref-kullback1951information" class="csl-entry" role="listitem">
Kullback, S., and Leibler, R. A. (1951), <span>“On information and sufficiency,”</span> <em>The Annals of Mathematical Statistics</em>, JSTOR, 22, 79–86.
</div>
<div id="ref-langsrud2005rotation" class="csl-entry" role="listitem">
Langsrud, Ø. (2005), <span>“Rotation tests,”</span> <em>Statistics and computing</em>, Springer, 15, 53–60.
</div>
<div id="ref-lee2015image" class="csl-entry" role="listitem">
Lee, H., and Chen, Y.-P. P. (2015), <span>“Image based computer aided diagnosis system for cancer detection,”</span> <em>Expert Systems with Applications</em>, Elsevier, 42, 5356–5365.
</div>
<div id="ref-li2024plot" class="csl-entry" role="listitem">
Li, W., Cook, D., Tanaka, E., and VanderPlas, S. (2024), <span>“A plot is worth a thousand tests: Assessing residual diagnostics with the lineup protocol,”</span> <em>Journal of Computational and Graphical Statistics</em>, Taylor &amp; Francis, 1–19.
</div>
<div id="ref-loy2013diagnostic" class="csl-entry" role="listitem">
Loy, A., and Hofmann, H. (2013), <span>“Diagnostic tools for hierarchical linear models,”</span> <em>Wiley Interdisciplinary Reviews: Computational Statistics</em>, Wiley Online Library, 5, 48–61.
</div>
<div id="ref-loy2014hlmdiag" class="csl-entry" role="listitem">
Loy, A., and Hofmann, H. (2014), <span>“HLMdiag: A suite of diagnostics for hierarchical linear models in r,”</span> <em>Journal of Statistical Software</em>, 56, 1–28.
</div>
<div id="ref-loy2015you" class="csl-entry" role="listitem">
Loy, A., and Hofmann, H. (2015), <span>“Are you normal? The problem of confounded residual structures in hierarchical linear models,”</span> <em>Journal of Computational and Graphical Statistics</em>, Taylor &amp; Francis, 24, 1191–1209.
</div>
<div id="ref-mason2022cassowaryr" class="csl-entry" role="listitem">
Mason, H., Lee, S., Laa, U., and Cook, D. (2022), <em><a href="https://CRAN.R-project.org/package=cassowary">Cassowaryr: Compute scagnostics on pairs of numeric variables in a data set</a></em>.
</div>
<div id="ref-omalley2019kerastuner" class="csl-entry" role="listitem">
O’Malley, T., Bursztein, E., Long, J., Chollet, F., Jin, H., Invernizzi, L., and others (2019), <span>“Keras <span>Tuner</span>,”</span> <a href="https://github.com/keras-team/keras-tuner" class="uri">https://github.com/keras-team/keras-tuner</a>.
</div>
<div id="ref-ojeda2020multivariate" class="csl-entry" role="listitem">
Ojeda, S. A. A., Solano, G. A., and Peramo, E. C. (2020), <span>“Multivariate time series imaging for short-term precipitation forecasting using convolutional neural networks,”</span> in <em>2020 international conference on artificial intelligence in information and communication (ICAIIC)</em>, IEEE, pp. 33–38.
</div>
<div id="ref-ramsey1969tests" class="csl-entry" role="listitem">
Ramsey, J. B. (1969), <span>“Tests for specification errors in classical linear least-squares regression analysis,”</span> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>, Wiley Online Library, 31, 350–371.
</div>
<div id="ref-rawat2017deep" class="csl-entry" role="listitem">
Rawat, W., and Wang, Z. (2017), <span>“Deep convolutional neural networks for image classification: A comprehensive review,”</span> <em>Neural computation</em>, MIT Press, 29, 2352–2449.
</div>
<div id="ref-shapiro1965analysis" class="csl-entry" role="listitem">
Shapiro, S. S., and Wilk, M. B. (1965), <span>“An analysis of variance test for normality (complete samples),”</span> <em>Biometrika</em>, JSTOR, 52, 591–611.
</div>
<div id="ref-silverman2018density" class="csl-entry" role="listitem">
Silverman, B. W. (2018), <em>Density estimation for statistics and data analysis</em>, Routledge.
</div>
<div id="ref-simonyan2014very" class="csl-entry" role="listitem">
Simonyan, K., and Zisserman, A. (2014), <span>“Very deep convolutional networks for large-scale image recognition,”</span> <em>arXiv preprint arXiv:1409.1556</em>.
</div>
<div id="ref-singh2017deep" class="csl-entry" role="listitem">
Singh, K., Gupta, G., Vig, L., Shroff, G., and Agarwal, P. (2017), <span>“Deep convolutional neural networks for pairwise causality,”</span> <em>arXiv preprint arXiv:1701.00597</em>.
</div>
<div id="ref-srivastava2014dropout" class="csl-entry" role="listitem">
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2014), <span>“Dropout: A simple way to prevent neural networks from overfitting,”</span> <em>The journal of machine learning research</em>, JMLR. org, 15, 1929–1958.
</div>
<div id="ref-tukey1985computer" class="csl-entry" role="listitem">
Tukey, J. W., and Tukey, P. A. (1985), <span>“Computer graphics and exploratory data analysis: An introduction,”</span> in <em>Proceedings of the sixth annual conference and exposition: Computer graphics</em>, pp. 773–785.
</div>
<div id="ref-vo2016localizing" class="csl-entry" role="listitem">
Vo, N. N., and Hays, J. (2016), <span>“Localizing and orienting street views using overhead imagery,”</span> in <em>Computer vision–ECCV 2016: 14th european conference, amsterdam, the netherlands, october 11–14, 2016, proceedings, part i 14</em>, Springer, pp. 494–509.
</div>
<div id="ref-wang2004image" class="csl-entry" role="listitem">
Wang, Z., Bovik, A. C., Sheikh, H. R., and Simoncelli, E. P. (2004), <span>“Image quality assessment: From error visibility to structural similarity,”</span> <em>IEEE transactions on image processing</em>, IEEE, 13, 600–612.
</div>
<div id="ref-widen2016graphical" class="csl-entry" role="listitem">
Widen, H. M., Elsner, J. B., Pau, S., and Uejio, C. K. (2016), <span>“Graphical inference in geographical research,”</span> <em>Geographical Analysis</em>, Wiley Online Library, 48, 115–131.
</div>
<div id="ref-wilkinson2005graph" class="csl-entry" role="listitem">
Wilkinson, L., Anand, A., and Grossman, R. (2005), <span>“Graph-theoretic scagnostics,”</span> in <em>Information visualization, IEEE symposium on</em>, IEEE Computer Society, pp. 21–21.
</div>
<div id="ref-zhang2020encoding" class="csl-entry" role="listitem">
Zhang, Y., Hou, Y., Zhou, S., and Ouyang, K. (2020), <span>“Encoding time series as multi-scale signed recurrence plots for classification using fully convolutional networks,”</span> <em>Sensors</em>, MDPI, 20, 3818.
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./02-chap2.html" class="pagination-link" aria-label="A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./04-chap4.html" class="pagination-link" aria-label="Software for Automated Residual Plot Assessment: autovi and autovi.web">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Software for Automated Residual Plot Assessment: autovi and autovi.web</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/TengMCing/PhD/edit/master/Thesis/03-chap3.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer></body></html>