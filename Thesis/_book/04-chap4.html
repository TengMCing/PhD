<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>4&nbsp; Tools for Automated Residual Plot Assessment: autovi and autovi.web – Advances in Artificial Intelligence for Data Visualization: Developing Computer Vision Models to Automate Reading of Data Plots, with Application to Regression Diagnostics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./refs.html" rel="next">
<link href="./03-chap3.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><link href="https://fonts.googleapis.com/css?family=Fira+Sans%7CMerriweather%7CSource%20Code%20Pro" rel="stylesheet">
<script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script><script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">
<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./04-chap4.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Tools for Automated Residual Plot Assessment: autovi and autovi.web</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Advances in Artificial Intelligence for Data Visualization: Developing Computer Vision Models to Automate Reading of Data Plots, with Application to Regression Diagnostics</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/TengMCing/PhD/tree/master/Thesis/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Advances-in-Artificial-Intelligence-for-Data-Visualization--Developing-Computer-Vision-Models-to-Automate-Reading-of-Data-Plots,-with-Application-to-Regression-Diagnostics.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Front matter</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-chap1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-chap2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-chap3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Automated Assessment of Residual Plots with Computer Vision Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-chap4.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Tools for Automated Residual Plot Assessment: autovi and autovi.web</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./refs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliography</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A-appA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Appendix to “A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol”</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B-appB.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Appendix to “Automated Assessment of Residual Plots with Computer vision Models”</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title"><b>Sections</b></h2>
   
  <ul class="collapse">
<li><a href="#sec-autovi-introduction" id="toc-sec-autovi-introduction" class="nav-link active" data-scroll-target="#sec-autovi-introduction"><span class="header-section-number">4.1</span> Introduction</a></li>
  <li><a href="#sec-autovi" id="toc-sec-autovi" class="nav-link" data-scroll-target="#sec-autovi"><span class="header-section-number">4.2</span> autovi</a></li>
  <li><a href="#sec-autovi-web" id="toc-sec-autovi-web" class="nav-link" data-scroll-target="#sec-autovi-web"><span class="header-section-number">4.3</span> autovi.web</a></li>
  <li><a href="#conclusions" id="toc-conclusions" class="nav-link" data-scroll-target="#conclusions"><span class="header-section-number">4.4</span> Conclusions</a></li>
  </ul><div class="toc-actions"><ul class="collapse"><li><a href="https://github.com/TengMCing/PhD/edit/master/Thesis/04-chap4.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title">
<span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Tools for Automated Residual Plot Assessment: autovi and autovi.web</span>
</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><section id="sec-autovi-introduction" class="level2" data-number="4.1"><h2 data-number="4.1" class="anchored" data-anchor-id="sec-autovi-introduction">
<span class="header-section-number">4.1</span> Introduction</h2>
<p>Regression analysis is a fundamental statistical technique widely used in various fields. In modern practice, this analysis is often performed using specialized statistical software, with R being a popular choice among researchers and data analysts. The Comprehensive R Archive Network (CRAN) <span class="citation" data-cites="hornik2012comprehensive">(<a href="refs.html#ref-hornik2012comprehensive" role="doc-biblioref">Hornik 2012</a>)</span> hosts a vast array of packages, many of which provide graphical tools for diagnosing residuals in linear regression models. These packages can be broadly categorized into three groups.</p>
<p>General-purpose regression analysis tools are the largest and most commonly used group. These packages aren’t specifically designed for graphical diagnostics of residuals in linear regression but offer this functionality as part of a broader set of statistical tools. A prime example is R’s built-in <code>stats</code> package <span class="citation" data-cites="stats">(<a href="refs.html#ref-stats" role="doc-biblioref">R Core Team 2022</a>)</span>, which provides a comprehensive collection of statistical modelling tools that includes common diagnostic plots like residuals vs fitted values, quantile-quantile (Q-Q) plots, and residuals vs leverage plots. Other packages such as <code>jtools</code> <span class="citation" data-cites="jtools">(<a href="refs.html#ref-jtools" role="doc-biblioref">Long 2022</a>)</span>, <code>olsrr</code> <span class="citation" data-cites="olsrr">(<a href="refs.html#ref-olsrr" role="doc-biblioref">Hebbali 2024</a>)</span>, <code>rockchalk</code> <span class="citation" data-cites="rockchalk">(<a href="refs.html#ref-rockchalk" role="doc-biblioref">Johnson 2022</a>)</span>, and <code>ggResidpanel</code> <span class="citation" data-cites="ggresidpanel">(<a href="refs.html#ref-ggresidpanel" role="doc-biblioref">Goode and Rey 2019</a>)</span> provide similar graphical tools with alternative aesthetic styles or interactive features. Although these packages may differ in presentation, they all fundamentally deliver diagnostic plots based on well-established principles in regression analysis, as outlined in classic works like <span class="citation" data-cites="cook1982residuals">Cook and Weisberg (<a href="refs.html#ref-cook1982residuals" role="doc-biblioref">1982</a>)</span>. However, consistently drawing accurate conclusions from these tools can be challenging due to individual differences in interpreting statistical graphics. As noted in <span class="citation" data-cites="li2024plot">Li et al. (<a href="refs.html#ref-li2024plot" role="doc-biblioref">2024</a>)</span>, relying solely on subjective assessments of data plots can lead to problems, such as over-interpreting random patterns as model violations.</p>
<p>Enhanced visual diagnostics is the second group, which offers advanced visual aids for interpreting diagnostic plots. A notable example is the <code>DHARMa</code> package <span class="citation" data-cites="dharma">(<a href="refs.html#ref-dharma" role="doc-biblioref">Hartig 2022</a>)</span>, which uses an innovative approach by fitting quantile regression on scaled residual plots. It compares the empirical 0.25, 0.5, and 0.75 quantiles in scaled residuals with their theoretical counterparts, making it particularly useful for highlighting deviations from model assumptions, detecting model violations such as heteroscedasticity and incorrect functional forms, and uncovering issues specific to generalized linear models and mixed-effect models, like over/underdispersion. By offering these enhanced visualizations, <code>DHARMa</code> enables users to more easily identify potential issues in their regression models that might not be immediately apparent with standard diagnostic plots. In summary, this group of packages enhances the interpretability of diagnostic plots by drawing attention to critical elements such as trends, clusters, and outliers. They sometimes automatically perform conventional tests on these elements, displaying the results as annotations, labels, or text within the plot, thereby further reducing the likelihood of misinterpretation.</p>
<p>Statistical testing for visual discoveries is the third group, which focuses on providing tools for conducting formal statistical tests for visual discoveries obtained from diagnostic plots <span class="citation" data-cites="buja2009statistical">(<a href="refs.html#ref-buja2009statistical" role="doc-biblioref">Buja et al. 2009</a>)</span>. Examples in this category include the <code>nullabor</code> <span class="citation" data-cites="nullabor">(<a href="refs.html#ref-nullabor" role="doc-biblioref">Wickham et al. 2020</a>)</span> and <code>regressinator</code> <span class="citation" data-cites="regressinator">(<a href="refs.html#ref-regressinator" role="doc-biblioref">Reinhart 2024</a>)</span> packages, which enables users to quantify the significance of patterns observed in residual diagnostic plots, perform hypothesis tests on specific aspects of model fit, and validate visual interpretations with statistical evidence. This approach addresses the issue of inconsistent interpretation of diagnostic plots by bridging the gap between visual inspection and formal statistical inference, thus offering a more robust framework for regression diagnostics.</p>
<p>Conducting a visual test for a residual plot, which is among the most common diagnostic plots in regression analysis, involves using a lineup protocol. In this protocol, the true residual plot is embedded within a lineup of several null plots and presented to one or more observers. The null plots are created by simulating residuals consistent with the null hypothesis <span class="math inline">H_0</span> that the regression model is correctly specified. Observers are then asked to identify the plot that appears most different from the others. If a significant percentage of observers correctly identify the true residual plot, it provides evidence against the <span class="math inline">H_0</span>, as according to <span class="citation" data-cites="buja2009statistical">Buja et al. (<a href="refs.html#ref-buja2009statistical" role="doc-biblioref">2009</a>)</span>, the true residual plot would have no distinguishable difference from the null plots if all residuals are generated by the same process.</p>
<p>However, as discussed in <a href="03-chap3.html" class="quarto-xref"><span>Chapter 3</span></a>, the lineup protocol has significant limitations in large-scale applications due to its high labor costs and time consumption. To address these issues, we developed a computer vision model and an associated statistical testing procedure to automate the assessment of residual plots. This model takes a residual plot and a vector of auxiliary variables (such as the number of observations) as inputs and outputs a visual signal strength. This strength estimates the distance between the residual distribution of the fitted regression model and the reference distribution assumed under correct model specification.</p>
<p>By estimating the visual signal strength for all plots in a lineup, we can compute a <span class="math inline">p</span>-value based on the ratio of plots with visual signal strength greater than or equal to that of the true residual plot. This <span class="math inline">p</span>-value has a lower bound of one divided by the number of plots in the lineup. Additionally, we can construct a null distribution of visual signal strength using the strengths of null plots.</p>
<p>We can also apply bootstrapping to obtain a distribution of visual signal strengths. This involves bootstrapping the data used to fit the linear regression model, refitting the model to obtain bootstrapped residuals, and then using the computer vision model to predict visual signal strength for these residuals. The resulting bootstrapped distribution can be compared against the null distribution. If these distributions are largely similar, it suggests that the bootstrapped residual plots are similar to the null plots. The proportion of bootstrapped visual signal strengths exceeding a critical value (such as the 95% sample quantile of the null distribution) indicates how often the assumed regression model would be considered incorrect if the data could be repeatedly obtained from the same data-generating process.</p>
<p>To make the statistical testing procedure and trained computer vision model widely accessible, we developed the R package <code>autovi</code>. In addition, we created a web-based tool that offers a user-friendly interface, enabling users to diagnose their residual plots without the need to install any dependencies required by the <code>autovi</code> package.</p>
<p>The remainder of this chapter is structured as follows: <a href="#sec-autovi" class="quarto-xref"><span>Section 4.2</span></a> provides a detailed documentation of the <code>autovi</code> package, including its usage and workflow. <a href="#sec-autovi-web" class="quarto-xref"><span>Section 4.3</span></a> focuses on the <code>autovi.web</code> interface, describing its design and usage, along with illustrative examples. Finally, <span class="quarto-unresolved-ref">?sec-autovi-conclusion</span> presents the main conclusions of this work.</p>
</section><section id="sec-autovi" class="level2" data-number="4.2"><h2 data-number="4.2" class="anchored" data-anchor-id="sec-autovi">
<span class="header-section-number">4.2</span> autovi</h2>
<p>The main purpose of <code>autovi</code> is to provide rejection decisions and <span class="math inline">p</span>-values for testing whether a regression model is correctly specified. The package introduces a novel approach to automating statistical analysis, particularly in the interpretation of residual plots. The name <code>autovi</code> stands for automated visual inference. While initially designed for linear regression residual diagnostics, it has the potential to be extended to broader visual inference applications, as we’ll discuss in section <a href="#sec-autovi-workflow" class="quarto-xref"><span>Section 4.2.4</span></a>.</p>
<section id="implementation" class="level3" data-number="4.2.1"><h3 data-number="4.2.1" class="anchored" data-anchor-id="implementation">
<span class="header-section-number">4.2.1</span> Implementation</h3>
<p><code>autovi</code> is built upon the <code>bandicoot</code> object-oriented programming (OOP) system <span class="citation" data-cites="bandicoot">(<a href="refs.html#ref-bandicoot" role="doc-biblioref">Li 2024</a>)</span>, which marks a departure from R’s conventional S3 generic system. The adoption of an OOP architecture enhances flexibility and modularity, enabling users to redefine key functions within the workflow through method overriding. While similar functionality could be replicated using R’s S3 system with generic functions, the OOP system offers a more structured and extensible foundation for the package.</p>
<p>The workflow of <code>autovi</code> demonstrates the effective integration of multiple programming languages and libraries to create a comprehensive analytical tool. It depends on five core libraries from Python and R, each contributing critically to the analysis pipeline. In Python, <code>pillow</code> <span class="citation" data-cites="clark2015pillow">(<a href="refs.html#ref-clark2015pillow" role="doc-biblioref">Clark et al. 2015</a>)</span> handles image processing tasks, including reading PNG files of residual plots, resizing them, and converting them into input tensors for further analysis. The <code>TensorFlow</code> <span class="citation" data-cites="abadi2016tensorflow">(<a href="refs.html#ref-abadi2016tensorflow" role="doc-biblioref">Abadi et al. 2016</a>)</span> library, a cornerstone of contemporary machine learning, is employed to predict the visual signal strength of these residual plots, utilizing a pre-trained convolutional neural network.</p>
<p>Within the R environment, <code>autovi</code> utilizes several powerful libraries. <code>ggplot2</code> <span class="citation" data-cites="ggplot2">(<a href="refs.html#ref-ggplot2" role="doc-biblioref">Wickham 2016</a>)</span> is employed to generate the initial residual plots, which are then saved as PNG files, using as the primary visual input for the analysis. The <code>cassowaryr</code> <span class="citation" data-cites="mason2022cassowaryr">(<a href="refs.html#ref-mason2022cassowaryr" role="doc-biblioref">Mason et al. 2022</a>)</span> library calculates scagnostics (scatter plot diagnostics) of the residual plots, providing numerical features that capture various statistical properties of the plots. These scagnostics complement the visual analysis by supplying quantitative metrics as secondary input to the computer vision model. The <code>reticulate</code> <span class="citation" data-cites="reticulate">(<a href="refs.html#ref-reticulate" role="doc-biblioref">Ushey et al. 2024</a>)</span> package is used to bridge R and Python, allowing for seamless communication between the two languages and supporting an integrated workflow.</p>
<p>The package includes internal functions to check the current Python environment used by the <code>reticulate</code> package. If the necessary Python packages are not installed in the Python interpreter, an error will be raised. If you want to select a specific Python environment, you can do so by calling the <code><a href="https://rstudio.github.io/reticulate/reference/use_python.html">reticulate::use_python()</a></code> function before using the <code>autovi</code> package.</p>
</section><section id="installation" class="level3" data-number="4.2.2"><h3 data-number="4.2.2" class="anchored" data-anchor-id="installation">
<span class="header-section-number">4.2.2</span> Installation</h3>
<p>The <code>autovi</code> package is available on CRAN. It is actively developed and maintained, with the latest updates accessible on GitHub at <a href="https://github.com/TengMCing/autovi">https://github.com/TengMCing/autovi</a>. The code discussed in this chapter is based on <code>autovi</code> version 0.4.1.</p>
</section><section id="sec-autovi-quick-start" class="level3" data-number="4.2.3"><h3 data-number="4.2.3" class="anchored" data-anchor-id="sec-autovi-quick-start">
<span class="header-section-number">4.2.3</span> Quick Start</h3>
<p>To get started quickly, users need only five lines of code to obtain a summary of the automated residual assessment:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tengmcing.github.io/autovi/">autovi</a></span><span class="op">)</span></span>
<span><span class="va">checker</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tengmcing.github.io/autovi/reference/AUTO_VI.html">auto_vi</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">dist</span> <span class="op">~</span> <span class="va">speed</span>, data <span class="op">=</span> <span class="va">cars</span><span class="op">)</span>, </span>
<span>                   keras_model <span class="op">=</span> <span class="fu"><a href="https://tengmcing.github.io/autovi/reference/get_keras_model.html">get_keras_model</a></span><span class="op">(</span><span class="st">"vss_phn_32"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">checker</span><span class="op">$</span><span class="fu">check</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">checker</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── &lt;AUTO_VI object&gt;
Status:
 - Fitted model: lm
 - Keras model: (None, 32, 32, 3) + (None, 5) -&gt; (None, 1)
    - Output node index: 1
 - Result:
    - Observed visual signal strength: 3.162 (p-value = 0.0396)
    - Null visual signal strength: [100 draws]
       - Mean: 1.274
       - Quantiles: 
          ╔═════════════════════════════════════════════════╗
          ║   25%    50%    75%    80%    90%    95%    99% ║
          ║0.8021 1.1109 1.5751 1.6656 1.9199 2.6564 3.3491 ║
          ╚═════════════════════════════════════════════════╝
    - Bootstrapped visual signal strength: [100 draws]
       - Mean: 2.786 (p-value = 0.05941)
       - Quantiles: 
          ╔══════════════════════════════════════════╗
          ║  25%   50%   75%   80%   90%   95%   99% ║
          ║2.452 2.925 3.173 3.285 3.463 3.505 3.652 ║
          ╚══════════════════════════════════════════╝
    - Likelihood ratio: 0.7275 (boot) / 0.06298 (null) = 11.55 </code></pre>
</div>
</div>
<ol type="1">
<li>Load the package using the <code><a href="https://rdrr.io/r/base/library.html">library()</a></code> function.</li>
<li>Construct a checker with two inputs: a linear regression model and a pre-trained Keras model <span class="citation" data-cites="chollet2015keras">(<a href="refs.html#ref-chollet2015keras" role="doc-biblioref">Chollet et al. 2015</a>)</span>.</li>
<li>Use <code><a href="https://tengmcing.github.io/autovi/reference/get_keras_model.html">get_keras_model()</a></code>, a function provided by <code>autovi</code>, to download a trained computer vision model (described in <a href="03-chap3.html" class="quarto-xref"><span>Chapter 3</span></a>) from GitHub. “vss_phn_32” specifies a model that predicts visual signal strength (vss) and is trained on residuals with polynomial, heteroskedasticity, and non-normality patterns (phn). More details about the hosted models will be provided in section <a href="#sec-trained-model-hosting" class="quarto-xref"><span>Section 4.2.7</span></a>.</li>
<li>Call the <code>check()</code> method of the checker with default arguments. This predicts the visual signal strength for the true residual plot, 100 null plots, and 100 bootstrapped plots, storing the predictions internally.</li>
<li>Use the <code><a href="https://rdrr.io/r/base/print.html">print()</a></code> function to generate a concise report of the check results.</li>
</ol>
<p>The report highlights key findings such as the visual signal strength of the true residual plot and the <span class="math inline">p</span>-value of the automated visual test. The <span class="math inline">p</span>-value is the ratio of null plots having visual signal strength greater than or equal to the true residual plot. We typically reject the null hypothesis when the <span class="math inline">p</span>-value is smaller than or equal to 5%. The report also provides sample quantiles of visual signal strength for null and bootstrapped plots, helping to explain the severity and likelihood of model violations.</p>
<p>Although the <span class="math inline">p</span>-value is sufficient for automated decision-making, users are strongly encouraged to visually inspect the original residual plot alongside a sample null plot. This visual comparison can clarify why <span class="math inline">H_0</span> is either rejected or not, and help identify potential remedies. The <code>plot_pair()</code> method facilitates this comparison.</p>
<div class="cell">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">plot_pair</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="04-chap4_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="384"></p>
</figure>
</div>
</div>
</div>
<p>This method displays the true residual plot on the left and a null plot on the right. Users should look for any distinct visual patterns in the true residual plot that are absent in the null plot. It’s recommended to run this function multiple times to confirm any visual findings, as each execution generates a new random null plot for comparison.</p>
<p>The package offers a straightforward visualization of the assessment result through the <code>summary_plot()</code> function.</p>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">summary_plot</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="04-chap4_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<p>In the visualization, the blue area represents the density of visual signal strength for null residual plots, while the red area shows the density for bootstrapped residual plots. The dashed line indicates the visual signal strength of the true residual plot, and the solid line marks the critical value at a 95% significance level. The <span class="math inline">p</span>-value and the likelihood ratio are displayed in the subtitle. The likelihood ratio represents the ratio of the likelihood of observing the visual signal strength of the true residual plot from the bootstrapped distribution compared to the null distribution.</p>
<p>Interpreting the plot involves several key aspects. If the dashed line falls to the right of the solid line, it suggests rejecting the null hypothesis. The degree of overlap between the red and blue areas indicates similarity between the true residual plot and null plots; greater overlap suggests more similarity. Lastly, the portion of the red area to the right of the solid line represents the percentage of bootstrapped models considered to have model violations.</p>
<p>This visual summary provides an intuitive way to assess the model’s fit and potential violations, allowing users to quickly grasp the results of the automated analysis.</p>
</section><section id="sec-autovi-workflow" class="level3" data-number="4.2.4"><h3 data-number="4.2.4" class="anchored" data-anchor-id="sec-autovi-workflow">
<span class="header-section-number">4.2.4</span> Modularized Workflow</h3>
<div class="cell">
<div class="cell-output-display">
<div id="fig-autovi-diag" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-autovi-diag-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="04-chap4_files/figure-html/fig-autovi-diag-1.png" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-autovi-diag-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.1: Diagram illustrating the workflow of the R package autovi. The modules in green are primary inputs provided by users. Modules in blue are overridable methods that can be modified to accommodate users’ specific needs. The module in yellow is a pre-defined non-overridable method. The modules in red are primary outputs of the package.
</figcaption></figure>
</div>
</div>
</div>
<p>The initial motivation for developing <code>autovi</code> was to create a convenient interface for sharing the models described and trained in <a href="03-chap3.html" class="quarto-xref"><span>Chapter 3</span></a>. However, recognizing that the classical normal linear regression model represents a restricted class of models, we sought to avoid limiting the potential for future extensions, whether by the original developers or other users. As a result, the package was designed to function seamlessly with linear regression models with minimal modification and few required arguments, while also accommodating other classes of models through partial workflow replacement. This modular and customizable design allows <code>autovi</code> to handle a wide range of residual diagnostics tasks.</p>
<p>The workflow of <code>autovi</code> consists of ten core modules: data extraction, bootstrapping and model refitting, fitted values and residuals extraction, auxiliary computation, null residual simulation, plotting, plot saving, image reading and resizing, visual signal strength prediction, and <span class="math inline">p</span>-value computation. Each module is designed with minimal dependency on the preceding modules, allowing users to customize parts of the workflow without affecting its overall integrity. An overview of this workflow is illustrated in Figure <a href="#fig-autovi-diag" class="quarto-xref">Figure&nbsp;<span>4.1</span></a>.</p>
<p>The modules for visual signal strength prediction and <span class="math inline">p</span>-value computation are predefined and cannot be overridden, although users can interact with them directly through function arguments. Similarly, the image reading and resizing module is fixed but will adapt to different Keras models by checking their input shapes. The remaining seven modules are designed to be overridable, enabling users to tailor the workflow to their specific needs. These modules will be discussed in detail in the following sections.</p>
<section id="initialization" class="level4"><h4 class="anchored" data-anchor-id="initialization">Initialization</h4>
<p>An <code>autovi</code> checker can be initialized by supplying two primary inputs, including a regression model object, such as an <code>lm</code> object representing the result of a linear regression model, and a trained computer vision model compatible with the <code>Keras</code> <span class="citation" data-cites="chollet2015keras">(<a href="refs.html#ref-chollet2015keras" role="doc-biblioref">Chollet et al. 2015</a>)</span> Application Programming Interface (API), to the <code>AUTO_VI</code> class constructor <code><a href="https://tengmcing.github.io/autovi/reference/AUTO_VI.html">auto_vi()</a></code>. The input will be stored in the checker and can be accessed by the user through the <code>$</code> operator.</p>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tengmcing.github.io/autovi/">autovi</a></span><span class="op">)</span></span>
<span><span class="va">checker</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tengmcing.github.io/autovi/reference/AUTO_VI.html">auto_vi</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">dist</span> <span class="op">~</span> <span class="va">speed</span>, data <span class="op">=</span> <span class="va">cars</span><span class="op">)</span>, </span>
<span>                   keras_model <span class="op">=</span> <span class="fu"><a href="https://tengmcing.github.io/autovi/reference/get_keras_model.html">get_keras_model</a></span><span class="op">(</span><span class="st">"vss_phn_32"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Optionally, the user may specify the node index of the output layer of the trained computer vision model to be monitored by the checker via the <code>node_index</code> argument if there are multiple output nodes. This is particularly useful for multiclass classifiers when the user wants to use one of the nodes as a visual signal strength indicator.</p>
<p>After initializing the object, you can print the checker to view its status.</p>
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── &lt;AUTO_VI object&gt;
Status:
 - Fitted model: lm
 - Keras model: (None, 32, 32, 3) + (None, 5) -&gt; (None, 1)
    - Output node index: 1
 - Result: UNKNOWN </code></pre>
</div>
</div>
<p>The status includes the list of regression model classes (as provided by the built-in <code><a href="https://rdrr.io/r/base/class.html">class()</a></code> function), the input and output shapes of the Keras model in the standard <code>Numpy</code> format <span class="citation" data-cites="harris2020array">(<a href="refs.html#ref-harris2020array" role="doc-biblioref">Harris et al. 2020</a>)</span>, the output node index being monitored, and the assessment result. If no check has been run yet, the assessment result will display as “UNKNOWN”.</p>
</section><section id="fitted-values-and-residuals-extraction" class="level4"><h4 class="anchored" data-anchor-id="fitted-values-and-residuals-extraction">Fitted Values and Residuals Extraction</h4>
<p>To be able to predict visual signal strength for a residual plot, both fitted values and residuals are needed to be extracted from the regression model object supplied by the user. In R, statistical models like <code>lm</code> (linear model) and <code>glm</code> (generalized linear model) typically support the use of generic functions such as <code><a href="https://rdrr.io/r/stats/fitted.values.html">fitted()</a></code> and <code><a href="https://rdrr.io/r/stats/residuals.html">resid()</a></code> to retrieve these values. The <code>get_fitted_and_resid()</code> method, called by the checker, relies on these generic functions by default. However, generic functions only work with classes that have appropriate method implementations. Some regression modelling packages may not fully adhere to the <code>stats</code> package guidelines for implementing these functions. In such cases, overriding the method becomes necessary.</p>
<p>By design, the <code>get_fitted_and_resid()</code> method accepts a regression model object as input and returns a <code>tibble</code> with two columns: <code>.fitted</code> and <code>.resid</code>, representing the fitted values and residuals, respectively. If no input is supplied, the method uses the regression model object stored in the checker. Although modules in the <code>autovi</code> workflow make minimal assumptions about other modules, they do require strictly defined input and output formats to ensure data validation and prevent fatal bugs. Therefore, any overridden method should follow to these conventions.</p>
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">get_fitted_and_resid</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 50 × 2
   .fitted .resid
     &lt;dbl&gt;  &lt;dbl&gt;
 1   -1.85   3.85
 2   -1.85  11.8 
 3    9.95  -5.95
 4    9.95  12.1 
 5   13.9    2.12
 6   17.8   -7.81
 7   21.7   -3.74
 8   21.7    4.26
 9   21.7   12.3 
10   25.7   -8.68
# ℹ 40 more rows</code></pre>
</div>
</div>
</section><section id="data-extraction" class="level4"><h4 class="anchored" data-anchor-id="data-extraction">Data Extraction</h4>
<p>For linear regression model in R, the model frame contains all the data required by a formula for evaluation. This is essential for bootstrapping and refitting the model when constructing a bootstrapped distribution of visual signal strength. Typically, the model frame can be extracted from the regression model object using the <code><a href="https://rdrr.io/r/stats/model.frame.html">model.frame()</a></code> generic function, which is the default method used by <code>get_data()</code>. However, some regression models don’t use a formula or are evaluated differently, potentially lacking a model frame. In such cases, users can either provide the data used to fit the regression model through the <code>data</code> argument when constructing the checker, or customize the method to better suit their needs. It’s worth noting that this module is only necessary if bootstrapping is required, as the model frame is not used in other steps of the workflow.</p>
<p>The <code>get_data()</code> method accepts a regression model object as input and returns a <code>data.frame</code> representing the model frame of the fitted regression model. If no input is supplied, the regression model stored in the checker will be used.</p>
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">get_data</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  dist speed
1    2     4
2   10     4
3    4     7
4   22     7
5   16     8
6   10     9</code></pre>
</div>
</div>
</section><section id="bootstrapping-and-model-refitting" class="level4"><h4 class="anchored" data-anchor-id="bootstrapping-and-model-refitting">Bootstrapping and Model Refitting</h4>
<p>Bootstrapping a regression model typically involves sampling the observations with replacement and refitting the model with the bootstrapped data. The <code>boot_method()</code> method follows this bootstrapping scheme by default. It accepts a fitted regression model and a <code>data.frame</code> as inputs, and returns a <code>tibble</code> of bootstrapped residuals. If no inputs are provided, the method uses the regression model stored in the checker and the result of the <code>get_data()</code> method.</p>
<p>Note that instead of calling <code>get_data()</code> implicitly within the method, it is used as part of the default argument definition. This approach allows users to bypass the <code>get_data()</code> method entirely and directly supply a <code>data.frame</code> to initiate the bootstrap process. Many other methods in <code>autovi</code> adopt this principle when possible, where dependencies are explicitly listed in the formal arguments. This design choice enhances the reusability and isolation of modules, offers better control for testing, and simplifies the overall process.</p>
<div class="cell">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">boot_method</span><span class="op">(</span>data <span class="op">=</span> <span class="va">checker</span><span class="op">$</span><span class="fu">get_data</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 50 × 2
   .fitted .resid
     &lt;dbl&gt;  &lt;dbl&gt;
 1    30.0  -2.04
 2    37.6  -1.58
 3    30.0 -16.0 
 4    52.7 -10.7 
 5    15.0   1.03
 6    30.0 -10.0 
 7    56.4  11.6 
 8    22.5   3.50
 9    37.6  42.4 
10    26.3  -9.27
# ℹ 40 more rows</code></pre>
</div>
</div>
</section><section id="auxiliary-computation" class="level4"><h4 class="anchored" data-anchor-id="auxiliary-computation">Auxiliary Computation</h4>
<p>According to <a href="03-chap3.html" class="quarto-xref"><span>Chapter 3</span></a>, in some cases, a residual plot alone may not provide enough information to accurately determine visual signal strength. For instance, when the residual plot has significant overlap, the trend and shape of the residual pattern can be difficult to discern. Including auxiliary variables, such as the number of observations, as additional inputs to the computer vision model can be beneficial. To address this, <code>autovi</code> includes internal functions within the checker that automatically detect the number of inputs required by the provided Keras model. If multiple inputs are necessary, the checker invokes the <code>auxiliary()</code> method to compute these additional inputs.</p>
<p>The <code>auxiliary()</code> method takes a <code>data.frame</code> containing fitted values and residuals as input and returns a <code>data.frame</code> with five numeric columns. These columns represent four scagnostics — “Monotonic”, “Sparse”, “Striped”, and “Splines” — calculated using the <code>cassowaryr</code> package, as well as the number of observations. This approach is consistent with the training process of the computer vision models described in <a href="03-chap3.html" class="quarto-xref"><span>Chapter 3</span></a>. If no <code>data.frame</code> is provided, the method will default to retrieving fitted values and residuals by calling <code>get_fitted_and_resid()</code>.</p>
<p>Technically, any Keras-implemented computer vision model can be adapted to accept an image as the primary input and additional variables as secondary inputs by adding a data pre-processing layer before the actual input layer. If users wish to override <code>auxiliary()</code>, the output should be a <code>data.frame</code> with a single row and the number of columns matching the supplied Keras model.</p>
<div class="cell">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">auxiliary</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 5
  measure_monotonic measure_sparse measure_splines measure_striped     n
              &lt;dbl&gt;          &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt; &lt;int&gt;
1            0.0621          0.470          0.0901            0.62    50</code></pre>
</div>
</div>
</section><section id="sec-autovi-null-method" class="level4"><h4 class="anchored" data-anchor-id="sec-autovi-null-method">Null Residual Simulation</h4>
<p>A fundamental element of the automated residual assessment described in <a href="03-chap3.html" class="quarto-xref"><span>Chapter 3</span></a> is comparing the visual signal strength of null plots with that of the true residual plot. However, due to the variety of regression models, there is no universal method for simulating null residuals that are consistent with model assumptions. Fortunately, for classical normal linear regression models, null residuals can be effectively simulated using the residual rotation method, as outlined in <span class="citation" data-cites="buja2009statistical">Buja et al. (<a href="refs.html#ref-buja2009statistical" role="doc-biblioref">2009</a>)</span>. This process involves generating random draws from a standard normal distribution, regressing these draws on the original predictors, and then rescaling the resulting residuals by the ratio of the residual sum of squares to the that of the original linear regression model. Other regression models, such as <code>glm</code> (generalized linear model) and <code>gam</code> (generalized additive model), generally cannot use this method to efficiently simulate null residuals. Therefore, it is recommended that users override the <code>null_method()</code> to suit their specific model. The <code>null_method()</code> takes a fitted regression model as input, defaulting to the regression model stored in the checker, and returns a <code>tibble</code>.</p>
<div class="cell">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">null_method</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 50 × 2
   .fitted .resid
     &lt;dbl&gt;  &lt;dbl&gt;
 1   -1.85 -19.0 
 2   -1.85 -17.0 
 3    9.95   3.77
 4    9.95  19.7 
 5   13.9    7.26
 6   17.8  -12.5 
 7   21.7   -2.14
 8   21.7   15.4 
 9   21.7  -19.9 
10   25.7    6.28
# ℹ 40 more rows</code></pre>
</div>
</div>
</section><section id="plotting" class="level4"><h4 class="anchored" data-anchor-id="plotting">Plotting</h4>
<p>Plotting is a crucial aspect of residual plot diagnostics because aesthetic elements like marker size, marker color, and auxiliary lines impact the presentation of information. There are computer vision models trained to handle images captured in various scenarios. For example, the VGG16 model <span class="citation" data-cites="simonyan2014very">(<a href="refs.html#ref-simonyan2014very" role="doc-biblioref">Simonyan and Zisserman 2014</a>)</span> can classify objects in images taken under different lighting conditions and is robust to image rotation. However, data plots are a special type of image as the plotting style can always be consistent if controlled properly. Therefore, we assume computer vision models built for reading residual plots will be trained with residual plots of a specific aesthetic style. In this case, it is best to predict plots using the same style for optimal performance. The plotting method <code>plot_resid()</code> handles this aspect.</p>
<p><code>plot_resid()</code> accepts a <code>data.frame</code> containing fitted values and residuals, along with several customization options: a <code>ggplot</code> theme, an <code>alpha</code> value to control the transparency of data points, a <code>size</code> value to set the size of data points, and a <code>stroke</code> value to define the thickness of data point edges. Additionally, it includes four Boolean arguments to toggle the display of axes, legends, grid lines, and a horizontal red line. By default, it replicates the style we used to generate the training samples for the computer vision models described in <a href="03-chap3.html" class="quarto-xref"><span>Chapter 3</span></a>. In brief, the residual plot omits axis text and ticks, titles, and background grid lines, featuring only a red line at <span class="math inline">y = 0</span>. It retains only the necessary components of a residual plot. If the computer vision model is trained with a different but consistent aesthetic style, <code>plot_resid()</code> should be overridden.</p>
<p>The method returns a <code>ggplot</code> object, which can be saved as a PNG file in the following module. If no data is provided, the method will use <code>get_fitted_and_resid()</code> to retrieve the fitted values and residuals from the regression model stored in the checker.</p>
<div class="cell">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">plot_resid</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="04-chap4_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid figure-img" width="384"></p>
</figure>
</div>
</div>
</div>
<p>To manually generate true residual plots, null plots, or bootstrapped residual plots, you can pass the corresponding <code>data.frame</code> produced by the <code>get_fitted_and_resid()</code>, <code>null_method()</code>, and <code>boot_method()</code> methods to the <code>plot_resid()</code> method, respectively.</p>
<div class="cell">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">null_method</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="va">checker</span><span class="op">$</span><span class="fu">plot_resid</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="04-chap4_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="384"></p>
</figure>
</div>
</div>
</div>
</section><section id="plot-saving" class="level4"><h4 class="anchored" data-anchor-id="plot-saving">Plot Saving</h4>
<p>Another key aspect of a standardized residual plot is its resolution. In <a href="03-chap3.html" class="quarto-xref"><span>Chapter 3</span></a>, we used an image format of 420 pixels in height and 525 pixels in width. This resolution was chosen because the original set, consisting of 20 residual plots arranged in a four by five grid, was represented by an image of 2100 by 2100 pixels. The <code><a href="https://tengmcing.github.io/autovi/reference/save_plot.html">save_plot()</a></code> method takes a <code>ggplot</code> object as input, saves it as a temporary PNG file, and returns the file path as a string. Note that the <code><a href="https://tengmcing.github.io/autovi/reference/save_plot.html">save_plot()</a></code> method does not have default arguments, as it is not intended to be called without a plot. While an alternative design could be to save the true residual plot by default, this might be confusing for users, given that the method’s name does not fully convey this functionality.</p>
<div class="cell">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">plot_resid</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="va">checker</span><span class="op">$</span><span class="fu">save_plot</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "/var/folders/61/bv7_1qzs20x6fjb2rsv7513r0000gn/T//RtmpYGBEn2/filed5772e1b2f1.png"</code></pre>
</div>
</div>
</section><section id="image-reading-and-resizing" class="level4"><h4 class="anchored" data-anchor-id="image-reading-and-resizing">Image Reading and Resizing</h4>
<p>When training computer vision models, it is common to test various input sizes for the same architecture to identify the optimal setup. This involves preparing the original training image at a higher resolution than required and then resizing it to match the input size during training. The <code>autovi</code> package includes a class, <code>KERAS_WRAPPER</code>, to simplify this process. This Keras wrapper class features a method called <code>image_to_array()</code>, which reads an image as a <code>PIL</code> image using the <code>pillow</code> Python package, resizes it to the target input size required by the Keras model, and converts it to a <code>Numpy</code> array.</p>
<p>To construct a <code>KERAS_WRAPPER</code> object, you need to provide the Keras model as the main argument. However, users generally do not need to interact with this class directly, as the <code>autovi</code> checker automatically invokes its methods when performing visual signal strength predictions. The <code>image_to_array()</code> method takes the path to the image file, the target height, and the target width as inputs and returns a <code>Numpy</code> array. If not specified, the target height and target width will be retrieved from the input layer of the Keras model by the <code>get_input_height()</code> and <code>get_input_width()</code> method of <code>KERAS_WRAPPER</code>.</p>
<p>The following code example demonstrate the way to manually generate the true residual plot, save it as PNG file, and load it back as <code>Numpy</code> array.</p>
<div class="cell">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">wrapper</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tengmcing.github.io/autovi/reference/KERAS_WRAPPER.html">keras_wrapper</a></span><span class="op">(</span>keras_model <span class="op">=</span> <span class="va">checker</span><span class="op">$</span><span class="va">keras_model</span><span class="op">)</span>  </span>
<span><span class="va">input_array</span> <span class="op">&lt;-</span> <span class="va">checker</span><span class="op">$</span><span class="fu">plot_resid</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="va">checker</span><span class="op">$</span><span class="fu">save_plot</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="va">wrapper</span><span class="op">$</span><span class="fu">image_to_array</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">input_array</span><span class="op">$</span><span class="va">shape</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(1, 32, 32, 3)</code></pre>
</div>
</div>
</section><section id="visual-signal-strength-prediction" class="level4"><h4 class="anchored" data-anchor-id="visual-signal-strength-prediction">Visual Signal Strength Prediction</h4>
<p>Visual signal strength, as discussed in <a href="03-chap3.html" class="quarto-xref"><span>Chapter 3</span></a>, estimates the distance between the input residual plot and a theoretically good residual plot. It can be defined in various ways, much like different methods for measuring the distance between two points. This will not impact the <code>autovi</code> workflow as long as the provided Keras model can predict the intended measure.</p>
<p>There are several ways to obtain visual signal strength from the checker, with the most direct being the <code>vss()</code> method. By default, this method predicts the visual signal strength for the true residual plot. If a <code>ggplot</code> or a <code>data.frame</code>, such as null residuals generated by the <code>null_method()</code>, is explicitly provided, the method will use that input to predict visual signal strength accordingly. Note that if a <code>ggplot</code> is provided, auxiliary inputs must be supplied manually via the <code>auxiliary</code> argument, as we assume that auxiliary variables can not be computed directly from a <code>ggplot</code>.</p>
<p>Another way to obtain visual signal strength is by calling the <code>check()</code> method. This comprehensive method perform extensive diagnostics on the true residual plot and store the visual signal strength in the <code>check_result</code> field of the checker. Additionally, for obtaining visual signal strength for null residual plots and bootstrapped residual plots, there are two specialized methods, <code>null_vss()</code> and <code>boot_vss()</code>, designed for this purpose respectively.</p>
<p>Calling the <code>vss()</code> method without arguments will predict the visual signal strength for the true residual plot and return the result as a single-element <code>tibble</code>.</p>
<div class="cell">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">vss</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 1
    vss
  &lt;dbl&gt;
1  3.16</code></pre>
</div>
</div>
<p>Providing a <code>data.frame</code> of null residuals or a null residual plot yields the same visual signal strength.</p>
<div class="cell">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">null_resid</span> <span class="op">&lt;-</span> <span class="va">checker</span><span class="op">$</span><span class="fu">null_method</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">checker</span><span class="op">$</span><span class="fu">vss</span><span class="op">(</span><span class="va">null_resid</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 1
    vss
  &lt;dbl&gt;
1  1.02</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">null_resid</span> <span class="op">|&gt;</span></span>
<span>  <span class="va">checker</span><span class="op">$</span><span class="fu">plot_resid</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="va">checker</span><span class="op">$</span><span class="fu">vss</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 1
    vss
  &lt;dbl&gt;
1  1.02</code></pre>
</div>
</div>
<p>The <code>null_vss()</code> helper method primarily takes the number of null plots as input. If the user wants to use a ad hoc null simulation scheme, it can be provided via the <code>null_method</code> argument. Intermediate results, including null residuals and null plots, can be returned by enabling <code>keep_null_data</code> and <code>keep_null_plot</code>. The visual signal strength, along with null residuals and null plots, will be stored in a <code>tibble</code> with three columns. The following code example demonstrates how to predict the visual signal strength for five null residual plots while keeping the intermediate results.</p>
<div class="cell">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">null_vss</span><span class="op">(</span><span class="fl">5L</span>, </span>
<span>                 keep_null_data <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>                 keep_null_plot <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 3
    vss data              plot  
  &lt;dbl&gt; &lt;list&gt;            &lt;list&gt;
1 1.35  &lt;tibble [50 × 2]&gt; &lt;gg&gt;  
2 0.629 &lt;tibble [50 × 2]&gt; &lt;gg&gt;  
3 1.77  &lt;tibble [50 × 2]&gt; &lt;gg&gt;  
4 1.91  &lt;tibble [50 × 2]&gt; &lt;gg&gt;  
5 1.71  &lt;tibble [50 × 2]&gt; &lt;gg&gt;  </code></pre>
</div>
</div>
<p>The <code>boot_vss()</code> helper method is similar to <code>null_vss()</code>, with some differences in argument names. The following code example demonstrates how to predict the visual signal strength for five bootstrapped residual plots while keeping the intermediate results.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 3
    vss data              plot  
  &lt;dbl&gt; &lt;list&gt;            &lt;list&gt;
1  1.26 &lt;tibble [50 × 2]&gt; &lt;gg&gt;  
2  3.35 &lt;tibble [50 × 2]&gt; &lt;gg&gt;  
3  3.16 &lt;tibble [50 × 2]&gt; &lt;gg&gt;  
4  2.87 &lt;tibble [50 × 2]&gt; &lt;gg&gt;  
5  2.54 &lt;tibble [50 × 2]&gt; &lt;gg&gt;  </code></pre>
</div>
</div>
</section><section id="p-value-computation" class="level4"><h4 class="anchored" data-anchor-id="p-value-computation">
<span class="math inline">P</span>-value Computation</h4>
<p>Once we have obtained the visual signal strength from both the true residual plot and the null plots, we can compute the <span class="math inline">p</span>-value. This <span class="math inline">p</span>-value represents the ratio of plots with visual signal strength greater than or equal to that of the true residual plot. We can perform this calculation using the <code>check()</code> method. The main inputs for this method are the number of null plots and the number of bootstrapped plots to generate. If you need to access intermediate residuals and plots, you can enable the <code>keep_data</code> and <code>keep_plot</code> options. The method stores the final result in the <code>check_result</code> field of the object. To obtain the p-value using the <code>check()</code> method, you can use the following code.</p>
<div class="cell">
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">check</span><span class="op">(</span>boot_draws <span class="op">=</span> <span class="fl">100L</span>, null_draws <span class="op">=</span> <span class="fl">100L</span><span class="op">)</span></span>
<span><span class="va">checker</span><span class="op">$</span><span class="va">check_result</span><span class="op">$</span><span class="va">p_value</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.01980198</code></pre>
</div>
</div>
<p>You can also check the <span class="math inline">p</span>-value by printing the checker, which includes it in the summary report.</p>
<div class="cell">
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── &lt;AUTO_VI object&gt;
Status:
 - Fitted model: lm
 - Keras model: (None, 32, 32, 3) + (None, 5) -&gt; (None, 1)
    - Output node index: 1
 - Result:
    - Observed visual signal strength: 3.162 (p-value = 0.0198)
    - Null visual signal strength: [100 draws]
       - Mean: 1.42
       - Quantiles: 
          ╔═════════════════════════════════════════════════╗
          ║   25%    50%    75%    80%    90%    95%    99% ║
          ║0.9296 1.3095 1.7277 1.7810 2.2497 2.5835 3.1570 ║
          ╚═════════════════════════════════════════════════╝
    - Bootstrapped visual signal strength: [100 draws]
       - Mean: 2.623 (p-value = 0.05941)
       - Quantiles: 
          ╔══════════════════════════════════════════╗
          ║  25%   50%   75%   80%   90%   95%   99% ║
          ║2.144 2.770 3.160 3.256 3.444 3.589 3.705 ║
          ╚══════════════════════════════════════════╝
    - Likelihood ratio: 0.5334 (boot) / 0.02943 (null) = 18.12 </code></pre>
</div>
</div>
</section></section><section id="summary-plots" class="level3" data-number="4.2.5"><h3 data-number="4.2.5" class="anchored" data-anchor-id="summary-plots">
<span class="header-section-number">4.2.5</span> Summary Plots</h3>
<p>After executing the <code>check()</code> method, <code>autovi</code> offers two visualization options for the assessment result through the <code>summary_plot()</code> method, including the density plot and the rank plot. We have already discussed and interpreted the density plot in an earlier section. Here, we would like to highlight the flexibility in choosing which elements to display in the density plot. For instance, you can omit the bootstrapped distribution by setting <code>boot_dist</code> to <code>NULL</code>. Similarly, you can hide the null distribution (<code>null_dist</code>), the <span class="math inline">p</span>-value (<code>p_value</code>), or the likelihood ratio (<code>likelihood_ratio</code>) as needed. The following example demonstrates how to create a summary plot without the results from bootstrapped plots.</p>
<div class="cell">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">summary_plot</span><span class="op">(</span>boot_dist <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>                     likelihood_ratio <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="04-chap4_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<p>This customization allows you to focus on specific aspects of the assessment, tailoring the visualization to your analytical needs.</p>
<p>The rank plot, creating by setting <code>type</code> to “rank”, is a bar plot where the x-axis represents the rank and the y-axis shows the visual signal strength. The bar for the true residual plot is colored in red. By examining the rank plot, you can intuitively understand how the observed visual signal strength compares to the null visual signal strengths and identify any outliers in the null distribution.</p>
<div class="cell">
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">summary_plot</span><span class="op">(</span>type <span class="op">=</span> <span class="st">"rank"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="04-chap4_files/figure-html/unnamed-chunk-26-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
</section><section id="feature-extraction" class="level3" data-number="4.2.6"><h3 data-number="4.2.6" class="anchored" data-anchor-id="feature-extraction">
<span class="header-section-number">4.2.6</span> Feature Extraction</h3>
<p>In addition to predicting visual signal strength and computing <span class="math inline">p</span>-values, <code>autovi</code> offers methods to extract features from any layer of the Keras model. To see which layers are available in the current Keras model, you can use the <code>list_layer_name()</code> method from the <code>KERAS_WRAPPER</code> class.</p>
<p>The following code example lists the layer names of the currently used Keras model:</p>
<div class="cell">
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">wrapper</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tengmcing.github.io/autovi/reference/KERAS_WRAPPER.html">keras_wrapper</a></span><span class="op">(</span><span class="va">checker</span><span class="op">$</span><span class="va">keras_model</span><span class="op">)</span></span>
<span><span class="va">wrapper</span><span class="op">$</span><span class="fu">list_layer_name</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] "input_1"                  "tf.__operators__.getitem"
 [3] "tf.nn.bias_add"           "grey_scale"              
 [5] "block1_conv1"             "batch_normalization"     
 [7] "activation"               "block1_conv2"            
 [9] "batch_normalization_1"    "activation_1"            
[11] "block1_pool"              "dropout"                 
[13] "block2_conv1"             "batch_normalization_2"   
[15] "activation_2"             "block2_conv2"            
[17] "batch_normalization_3"    "activation_3"            
[19] "block2_pool"              "dropout_1"               
[21] "block3_conv1"             "batch_normalization_4"   
[23] "activation_4"             "block3_conv2"            
[25] "batch_normalization_5"    "activation_5"            
[27] "block3_conv3"             "batch_normalization_6"   
[29] "activation_6"             "block3_pool"             
[31] "dropout_2"                "block4_conv1"            
[33] "batch_normalization_7"    "activation_7"            
[35] "block4_conv2"             "batch_normalization_8"   
[37] "activation_8"             "block4_conv3"            
[39] "batch_normalization_9"    "activation_9"            
[41] "block4_pool"              "dropout_3"               
[43] "block5_conv1"             "batch_normalization_10"  
[45] "activation_10"            "block5_conv2"            
[47] "batch_normalization_11"   "activation_11"           
[49] "block5_conv3"             "batch_normalization_12"  
[51] "activation_12"            "block5_pool"             
[53] "dropout_4"                "global_max_pooling2d"    
[55] "additional_input"         "concatenate"             
[57] "dense"                    "dropout_5"               
[59] "activation_13"            "dense_1"                 </code></pre>
</div>
</div>
<p>Among these layers, the “global_max_pooling2d” layer is a 2D global max pooling layer that outputs the results from the last convolutional blocks. As <span class="citation" data-cites="simonyan2014very">Simonyan and Zisserman (<a href="refs.html#ref-simonyan2014very" role="doc-biblioref">2014</a>)</span> noted, all preceding convolutional blocks can be viewed as a large feature extractor. Consequently, the output from this layer provides features that can be utilized for various purposes, such as performing transfer learning.</p>
<p>To obtain the features, provide the layer name using the <code>extract_feature_from_layer</code> argument in the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> method. This will return a <code>tibble</code> with the visual signal strength and all features extracted from that layer. Each row corresponds to one plot. The features will be flattened into 2D and named with the prefix “f_” followed by a number from one to the total number of features.</p>
<div class="cell">
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">plot_resid</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="va">checker</span><span class="op">$</span><span class="fu">save_plot</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="va">wrapper</span><span class="op">$</span><span class="fu">image_to_array</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="va">wrapper</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span>auxiliary <span class="op">=</span> <span class="va">checker</span><span class="op">$</span><span class="fu">auxiliary</span><span class="op">(</span><span class="op">)</span>,</span>
<span>                  extract_feature_from_layer <span class="op">=</span> <span class="st">"global_max_pooling2d"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 257
    vss   f_1   f_2   f_3   f_4   f_5    f_6   f_7    f_8   f_9   f_10  f_11
  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
1  3.16 0.151     0     0     0     0 0.0203 0.109 0.0203     0 0.0834     0
# ℹ 245 more variables: f_12 &lt;dbl&gt;, f_13 &lt;dbl&gt;, f_14 &lt;dbl&gt;, f_15 &lt;dbl&gt;,
#   f_16 &lt;dbl&gt;, f_17 &lt;dbl&gt;, f_18 &lt;dbl&gt;, f_19 &lt;dbl&gt;, f_20 &lt;dbl&gt;, f_21 &lt;dbl&gt;,
#   f_22 &lt;dbl&gt;, f_23 &lt;dbl&gt;, f_24 &lt;dbl&gt;, f_25 &lt;dbl&gt;, f_26 &lt;dbl&gt;, f_27 &lt;dbl&gt;,
#   f_28 &lt;dbl&gt;, f_29 &lt;dbl&gt;, f_30 &lt;dbl&gt;, f_31 &lt;dbl&gt;, f_32 &lt;dbl&gt;, f_33 &lt;dbl&gt;,
#   f_34 &lt;dbl&gt;, f_35 &lt;dbl&gt;, f_36 &lt;dbl&gt;, f_37 &lt;dbl&gt;, f_38 &lt;dbl&gt;, f_39 &lt;dbl&gt;,
#   f_40 &lt;dbl&gt;, f_41 &lt;dbl&gt;, f_42 &lt;dbl&gt;, f_43 &lt;dbl&gt;, f_44 &lt;dbl&gt;, f_45 &lt;dbl&gt;,
#   f_46 &lt;dbl&gt;, f_47 &lt;dbl&gt;, f_48 &lt;dbl&gt;, f_49 &lt;dbl&gt;, f_50 &lt;dbl&gt;, f_51 &lt;dbl&gt;, …</code></pre>
</div>
</div>
<p>Alternatively, the <code>AUTO_VI</code> class provides a way to extract features using the <code>vss()</code> method. This method is essentially a high-level wrapper around the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> method of <code>KERAS_WRAPPER</code>, but it offers a more straightforward interface and better default arguments.</p>
<p>The results from the previous code example can be replicated with a single line of code as shown below.</p>
<div class="cell">
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">vss</span><span class="op">(</span>extract_feature_from_layer <span class="op">=</span> <span class="st">"global_max_pooling2d"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 257
    vss   f_1   f_2   f_3   f_4   f_5    f_6   f_7    f_8   f_9   f_10  f_11
  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
1  3.16 0.151     0     0     0     0 0.0203 0.109 0.0203     0 0.0834     0
# ℹ 245 more variables: f_12 &lt;dbl&gt;, f_13 &lt;dbl&gt;, f_14 &lt;dbl&gt;, f_15 &lt;dbl&gt;,
#   f_16 &lt;dbl&gt;, f_17 &lt;dbl&gt;, f_18 &lt;dbl&gt;, f_19 &lt;dbl&gt;, f_20 &lt;dbl&gt;, f_21 &lt;dbl&gt;,
#   f_22 &lt;dbl&gt;, f_23 &lt;dbl&gt;, f_24 &lt;dbl&gt;, f_25 &lt;dbl&gt;, f_26 &lt;dbl&gt;, f_27 &lt;dbl&gt;,
#   f_28 &lt;dbl&gt;, f_29 &lt;dbl&gt;, f_30 &lt;dbl&gt;, f_31 &lt;dbl&gt;, f_32 &lt;dbl&gt;, f_33 &lt;dbl&gt;,
#   f_34 &lt;dbl&gt;, f_35 &lt;dbl&gt;, f_36 &lt;dbl&gt;, f_37 &lt;dbl&gt;, f_38 &lt;dbl&gt;, f_39 &lt;dbl&gt;,
#   f_40 &lt;dbl&gt;, f_41 &lt;dbl&gt;, f_42 &lt;dbl&gt;, f_43 &lt;dbl&gt;, f_44 &lt;dbl&gt;, f_45 &lt;dbl&gt;,
#   f_46 &lt;dbl&gt;, f_47 &lt;dbl&gt;, f_48 &lt;dbl&gt;, f_49 &lt;dbl&gt;, f_50 &lt;dbl&gt;, f_51 &lt;dbl&gt;, …</code></pre>
</div>
</div>
<p>The argument <code>extract_feature_from_layer</code> is also available in other functions that build on the <code>vss()</code> method, including <code>null_vss()</code>, <code>boot_vss()</code>, and <code>check()</code>.</p>
<p>The package provides tools for analyzing these extracted features through the <code>feature_pca()</code> method and its associated visualization method, <code>feature_pca_plot()</code>. The <code>feature_pca()</code> method performs principal component analysis (PCA) on the features to reduce their dimensionality. However, it requires that a <code>check()</code> is performed first, as it relies on results stored in <code>check_result</code>. Alternatively, you can manually provide features using the <code>feature</code>, <code>null_feature</code>, and <code>boot_feature</code> arguments for the true residual plot, null plots, and bootstrapped plots, respectively. The <code>feature_pca()</code> method returns a tibble containing both the original features and the principal components. The rotation matrix and standard deviations of each principal component are stored as attributes.</p>
<div class="cell">
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">check</span><span class="op">(</span>null_draws <span class="op">=</span> <span class="fl">100L</span>,</span>
<span>              boot_draws <span class="op">=</span> <span class="fl">100L</span>,</span>
<span>              extract_feature_from_layer <span class="op">=</span> <span class="st">"global_max_pooling2d"</span><span class="op">)</span></span>
<span><span class="va">checker</span><span class="op">$</span><span class="fu">feature_pca</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 201 × 458
     f_1   f_2   f_3   f_4   f_5    f_6     f_7    f_8   f_9   f_10   f_11
   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
 1 0.151 0     0     0     0     0.0203 0.109   0.0203 0     0.0834 0     
 2 1.17  1.87  2.10  1.99  0.646 0.806  1.16    1.12   1.11  0.230  1.77  
 3 0.898 1.95  1.89  1.98  0.683 0.783  1.09    1.03   1.08  0.401  1.62  
 4 0.699 2.64  2.41  3.27  1.41  1.29   1.94    1.50   1.26  1.16   2.50  
 5 0.494 1.22  0.836 0.867 0     0.212  0.231   0.172  0.835 0      0.589 
 6 0.356 0.912 0.203 0.589 0     0      0.0225  0.142  0.485 0.0311 0.162 
 7 0.514 1.25  0.817 0.900 0     0.165  0.176   0.172  0.833 0      0.589 
 8 1.13  2.15  2.30  2.26  0.785 0.932  1.31    1.21   1.25  0.363  1.95  
 9 0.270 0.795 0.123 0.438 0     0      0       0.0272 0.501 0      0.0608
10 0.245 0.807 0     0.357 0     0      0.00358 0.0494 0.426 0      0     
# ℹ 191 more rows
# ℹ 447 more variables: f_12 &lt;dbl&gt;, f_13 &lt;dbl&gt;, f_14 &lt;dbl&gt;, f_15 &lt;dbl&gt;,
#   f_16 &lt;dbl&gt;, f_17 &lt;dbl&gt;, f_18 &lt;dbl&gt;, f_19 &lt;dbl&gt;, f_20 &lt;dbl&gt;, f_21 &lt;dbl&gt;,
#   f_22 &lt;dbl&gt;, f_23 &lt;dbl&gt;, f_24 &lt;dbl&gt;, f_25 &lt;dbl&gt;, f_26 &lt;dbl&gt;, f_27 &lt;dbl&gt;,
#   f_28 &lt;dbl&gt;, f_29 &lt;dbl&gt;, f_30 &lt;dbl&gt;, f_31 &lt;dbl&gt;, f_32 &lt;dbl&gt;, f_33 &lt;dbl&gt;,
#   f_34 &lt;dbl&gt;, f_35 &lt;dbl&gt;, f_36 &lt;dbl&gt;, f_37 &lt;dbl&gt;, f_38 &lt;dbl&gt;, f_39 &lt;dbl&gt;,
#   f_40 &lt;dbl&gt;, f_41 &lt;dbl&gt;, f_42 &lt;dbl&gt;, f_43 &lt;dbl&gt;, f_44 &lt;dbl&gt;, f_45 &lt;dbl&gt;, …</code></pre>
</div>
</div>
<p>The <code>feature_pca_plot()</code> method visualizes the results of the PCA. By default, it plots the first principal component on the x-axis and the second principal component on the y-axis, with points colored according to their origi, true residual plots, null residual plots, or bootstrapped residual plots. Users can customize the x and y axes by specifying symbols for the <code>x</code> and <code>y</code> arguments. Additionally, the <code>col_by_set</code> option can be disabled if you prefer not to use coloring.</p>
<div class="cell">
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">checker</span><span class="op">$</span><span class="fu">feature_pca_plot</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="04-chap4_files/figure-html/unnamed-chunk-31-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<p>When interpreting the principal component scatter plot, look for any outliers within the null or bootstrapped groups. Assess whether the null group and the bootstrapped group form a single cluster or distinct clusters. Additionally, evaluate whether the observed point is distinct from the null group.</p>
</section><section id="sec-trained-model-hosting" class="level3" data-number="4.2.7"><h3 data-number="4.2.7" class="anchored" data-anchor-id="sec-trained-model-hosting">
<span class="header-section-number">4.2.7</span> Trained Model Hosting</h3>
<p>The trained computer vision models described in <a href="03-chap3.html" class="quarto-xref"><span>Chapter 3</span></a> are hosted on a GitHub repository at <a href="https://github.com/TengMCing/autovi_data">https://github.com/TengMCing/autovi_data</a>. Currently, there are six models available. You can view them by calling <code><a href="https://tengmcing.github.io/autovi/reference/list_keras_model.html">list_keras_model()</a></code>, which will return a <code>tibble</code> showing the input shape and a description of each model.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 7
  model_name  path  input_height input_width input_channels auxiliary_input_size
  &lt;chr&gt;       &lt;chr&gt;        &lt;int&gt;       &lt;int&gt;          &lt;int&gt;                &lt;int&gt;
1 vss_32      kera…           32          32              3                    0
2 vss_64      kera…           64          64              3                    0
3 vss_128     kera…          128         128              3                    0
4 vss_phn_32  kera…           32          32              3                    5
5 vss_phn_64  kera…           64          64              3                    5
6 vss_phn_128 kera…          128         128              3                    5
# ℹ 1 more variable: description &lt;chr&gt;</code></pre>
</div>
</div>
<p>The <code><a href="https://tengmcing.github.io/autovi/reference/get_keras_model.html">get_keras_model()</a></code> function can be used to download a model to a temporary directory and load it into memory using <code>TensorFlow</code>. It requires only the model name, which is the value in the first column of the <code>tibble</code> returned by <code><a href="https://tengmcing.github.io/autovi/reference/list_keras_model.html">list_keras_model()</a></code>.</p>
</section><section id="extending-the-auto_vi-class" class="level3" data-number="4.2.8"><h3 data-number="4.2.8" class="anchored" data-anchor-id="extending-the-auto_vi-class">
<span class="header-section-number">4.2.8</span> Extending the <code>AUTO_VI</code> class</h3>
<p><code>bandicoot</code> is a lightweight object-oriented system with Python-like syntax that supports multiple inheritance and incorporates a Python-like method resolution order. The system is inspired by the OOP frameworks implemented in R6 [r6] and Python. In this section, we will provide essential details for extending the <code><a href="https://tengmcing.github.io/autovi/reference/AUTO_VI.html">autovi::AUTO_VI</a></code> class using <code>bandicoot</code>.</p>
<p>In <code>bandicoot</code>, a class is declared using the <code><a href="https://tengmcing.github.io/bandicoot/reference/new_class.html">bandicoot::new_class()</a></code> function, where parent classes are provided as positional arguments, and the class name is specified through the <code>class_name</code> argument. The output of <code><a href="https://tengmcing.github.io/bandicoot/reference/new_class.html">bandicoot::new_class()</a></code> is an environment with the S3 class <code>bandicoot_oop</code>. Printing a <code>bandicoot</code> object provides a summary of the object, which can be customized via the <code>..str..</code> magic method.</p>
<p>An extended class inherits attributes and methods from its parent class(es), so it will behave similarly to them. This can be verified using the built-in <code><a href="https://rdrr.io/r/base/names.html">names()</a></code> function.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code> [1] "vss"                  "rotate_resid"         "..init.."            
 [4] "get_data"             "has_attr"             "lineup_check"        
 [7] "null_vss"             "check_result"         "summary_plot"        
[10] "..str.."              "..new.."              "del_attr"            
[13] "plot_resid"           "null_method"          "..class.."           
[16] "..method_env.."       "auxiliary"            "summary"             
[19] "set_attr"             "get_attr"             "summary_density_plot"
[22] "get_fitted_and_resid" "..methods.."          "..class_tree.."      
[25] "..repr.."             "feature_pca"          "plot_pair"           
[28] "check"                "boot_vss"             "feature_pca_plot"    
[31] "boot_method"          "save_plot"            "summary_rank_plot"   
[34] "instantiate"          "p_value"              "..instantiated.."    
[37] "..type.."             "..dir.."              "..len.."             
[40] "..bases.."            "..mro.."              "likelihood_ratio"    </code></pre>
</div>
</div>
<p>To register a method for an extended class, you need to pass the class as the first argument and the method as a named argument to the <code><a href="https://tengmcing.github.io/bandicoot/reference/register_method.html">bandicoot::register_method()</a></code> function. Within a method, <code>self</code> can be used as a reference to the class or object environment. The following code example overrides the <code>null_method()</code> with a function that simulates null residuals from the corresponding normal distribution. This approach differs from the default null residual simulation scheme described in <a href="#sec-autovi-null-method" class="quarto-xref"><span>Section 4.2.4.6</span></a>. Although less efficient than the default method for linear regression models, it provides an alternative way to simulate null residuals. This method is particularly useful when the fitted model is unavailable, and only the fitted values and residuals are accessible, as discussed in <a href="#sec-autovi-web" class="quarto-xref"><span>Section 4.3</span></a>.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 50 × 2
   .fitted .resid
     &lt;dbl&gt;  &lt;dbl&gt;
 1   -1.85 -16.8 
 2   -1.85   7.40
 3    9.95 -25.5 
 4    9.95  15.9 
 5   13.9    1.82
 6   17.8   -6.60
 7   21.7   -8.77
 8   21.7   19.6 
 9   21.7  -10.8 
10   25.7   16.2 
# ℹ 40 more rows</code></pre>
</div>
</div>
<p>To create an object in <code>bandicoot</code>, you need to call the <code>instantiate()</code> method of a class. Alternatively, you can build a convenient class constructor for your class. It is recommended to provide the full list of arguments in the class constructor instead of using <code>...</code>, as this makes it easier for integrated development environments (IDEs) like RStudio to offer argument completion hints to the user.</p>
</section></section><section id="sec-autovi-web" class="level2" data-number="4.3"><h2 data-number="4.3" class="anchored" data-anchor-id="sec-autovi-web">
<span class="header-section-number">4.3</span> autovi.web</h2>
<p>The R package <code>autovi</code> is designed to provide rejection decisions and <span class="math inline">p</span>-values for testing the null hypothesis that a regression model is correctly specified. To construct a checker with <code>autovi</code>, one needs to supply a regression model object—typically an <code>lm</code> object representing the result of a linear regression model and a trained computer vision model compatible with the <code>Keras</code> API.</p>
<p>The regression model object is used to extract the fitted values and residuals for creating a residual plot. Additionally, a residual rotation technique is applied to the model object to generate null residuals, which are residuals consistent with the null hypothesis. For a linear regression model, this is conventionally achieved by simulating new random standard normal draws and using them as responses to refit the linear regression model.</p>
<p>Having null plots, which are residual plots consisting of null residuals and the original fitted values, is crucial for constituting a visual test. If the visual test were conducted by humans, a lineup consisting of <span class="math inline">m-1</span> null plots and one true residual plot would be presented to several observers. Observers would then be asked to select the plot they find most different out of the <span class="math inline">m</span> residual plots. If many observers correctly identify the true residual plot as the most different, it provides evidence for rejecting the null hypothesis that the model is correctly specified. This is because, under the null hypothesis, the true residual plot should be indistinguishable from the null plots.</p>
<p>Instead of human observers, the visual test in <code>autovi</code> is performed by a computer vision model. This model is trained to report the visual signal strength of each individual plot in a lineup. The visual signal strength estimates the divergence of the empirical residual distribution from the ideal residual distribution, effectively measuring the degree of model violations. The higher the visual signal strength, the more evidence there is against the null hypothesis.</p>
<p>The computer vision model’s training involves estimating this divergence or distance, which quantifies how much the residuals deviate from what is expected under a correctly specified model. More details about the mathematical derivation and the training process of the computer vision model can be found in the paper by Li et.al. (2024).</p>
<p>Furthermore, the computer vision model used in <code>autovi</code> requires a fixed-size 4D tensor as input. The dimensions of this tensor are as follows: the first dimension represents the batch size, the second dimension represents the width of the image, the third dimension represents the height of the image, and the fourth dimension represents the number of channels. The model outputs a numeric vector that represents the visual signal strength for each image in the batch. The computer vision model is also trained with a set of fixed-aesthetic residual plots, which means that the input images must be produced using the same data pipeline that was used for the training data preparation. This consistency is crucial for ensuring that the model can accurately interpret and analyze new data.</p>
<p>A significant portion of our web interface is dedicated to managing this data pipeline. This involves processing the user-provided data to generate input images that conform to the required format for the computer vision model. The pipeline ensures that the residual plots created from the user data match the aesthetics and format of the training data, enabling the model to provide accurate visual signal strength assessments.</p>
<!-- Our web interface simplifies this process for the user by automating the necessary steps to transform their data into the appropriate input format. Users can upload their CSV files, and the interface handles the extraction of residuals, the creation of residual plots, and the formatting of these plots into 4D tensors. This seamless integration allows users to focus on interpreting the results rather than on the technical details of data preparation. -->
<section id="data-pipeline" class="level3" data-number="4.3.1"><h3 data-number="4.3.1" class="anchored" data-anchor-id="data-pipeline">
<span class="header-section-number">4.3.1</span> Data Pipeline</h3>
<p>In this section, we will describe the entire data pipeline, including handling uploaded data, creating and saving fixed-aesthetic residual plots, loading and transforming images to the desired input format, and predicting visual signal strength.</p>
<section id="input-file-format" class="level4"><h4 class="anchored" data-anchor-id="input-file-format">Input File Format</h4>
<p>As described in Section , the <code>autovi</code> package requires a regression model object to initialize the diagnostics. However, it is impractical to ask users to upload an R regression model object for inspection. There are several reasons for this:</p>
<ol type="1">
<li>
<strong>User Complexity</strong>: Saving an R object to the filesystem involves extra steps and requires users to have specific knowledge.</li>
<li>
<strong>Data Sensitivity</strong>: The regression model object may contain sensitive, non-shareable data.</li>
<li>
<strong>File Size</strong>: The R object is often unnecessarily large because it contains extra information not needed for diagnostics.</li>
</ol>
<p>To simplify the process, the web interface instead requests a CSV file. This CSV file should contain at least two columns: <code>.fitted</code>, representing the fitted values, and <code>.resid</code>, representing the residuals. Additionally, it can contain an optional column <code>.sample</code> to indicate the ID of the residual plot. This is particularly useful if the user wants to evaluate a lineup of residual plots.</p>
<p>Compared to an R model object, a CSV file can be easily generated by various software programs, not just R. CSV files are widely accepted and can be easily viewed and modified using common desktop applications like Excel. CSV files are generally less sensitive than raw data because most information about the predictors is excluded.</p>
</section><section id="plot-drawing-and-image-loading" class="level4"><h4 class="anchored" data-anchor-id="plot-drawing-and-image-loading">Plot Drawing and Image Loading</h4>
<p>The training data for the computer vision models consist of <span class="math inline">32 \times 32</span> RGB residual plots. These plots display fitted values on the x-axis and residuals on the y-axis. All labels, including axis texts, are excluded, and no background grid lines are included in the plots. Residual points are drawn in black with a size of 0.5 points, where there are 72.27 points per inch. Additionally, a horizontal red line is drawn at <span class="math inline">y = 0</span> to help the computer vision model determine if the residual points are uniformly distributed on both sides of the line. The plot is then saved as a PNG file with a resolution of <span class="math inline">420 \times 525</span> pixels. This resolution mimics a typical lineup residual plot, which has a resolution of <span class="math inline">2100 \times 2100</span> pixels and is arranged in four rows and five columns.</p>
<p>The uploaded CSV file will be partitioned based on the values in the optional column <code>k</code>. If no optional column <code>k</code> is present, the entire data set will be used as one partition. Each partition will utilize the plot specifications to generate one residual plot and produce one PNG file.</p>
<p>The saved PNG plot is loaded as an array, where each entry contains a pixel value of the image. This array is then resized to match the input layer shape of the computer vision model, which is <span class="math inline">1 \times 32 \times 32 \times 3</span>. If multiple images are needed for visual signal strength estimation, the arrays can be stacked together to form a larger array with the shape <span class="math inline">n \times 32 \times 32 \times 3</span>, where <span class="math inline">n</span> is the number of images.</p>
</section><section id="visual-signal-strength-estimation" class="level4"><h4 class="anchored" data-anchor-id="visual-signal-strength-estimation">Visual Signal Strength Estimation</h4>
<p>Finally, the processed image array will be fed into the computer vision model, and returned a vector of visual signal strength which are numerical values always greater than zero.</p>
</section></section><section id="software-stack" class="level3" data-number="4.3.2"><h3 data-number="4.3.2" class="anchored" data-anchor-id="software-stack">
<span class="header-section-number">4.3.2</span> Software Stack</h3>
<section id="backend" class="level4"><h4 class="anchored" data-anchor-id="backend">Backend</h4>
<p>To utilize the <code>autovi</code> R package, the server hosting our web interface must have a functional R interpreter. A static HTML page cannot accomplish this task, as it only serves static resources to the client and lacks the capability to execute R code. The alternative option would be WebR, a version of R designed to run within a web browser. However, integrating WebR introduces complexities into the design of the web interface, which we will explore further in Section XXX. Additionally, The resizing of the image is originally done by the Python <code>Pillow</code> library. To maintain the same data pipeline, we also need a working Python interpreter. Given the required conditions, we have three options: (1) Use a traditional backend like the <code>Spring</code> framework written in Java for handling all the income and outcome traffic of the web interface. Meanwhile, install R and Python in the server and call them when needed. (2) Use a Python backend framework like <code>Flask</code> so that the <code>Pillow</code> library can be used natively. Still, R needs to be installed and correctly configured in the server and called when needed. (3) Use a R backend framework like <code>Shiny</code>. This is similar to the second option, but requires to install and configure Python separately.</p>
<p>Option one requires a good understanding</p>
<!-- Thus, we chose to implement the web interface with a shiny server. Shiny server is a backend framework written in R, so it allows us to receive user's input and interactively update the output rendered on the client side using R code.  -->
<!-- We deploy the shiny server using the services provided by Posit, called `shinyapps.io`. It is responsible for reading in the uploaded CSV file with the `readr` R package, splitting the dataset with the `dplyr` R package and drawing the residual plots with the `ggplot2` R package. The resulting PNG files are stored in the temporary directory of the remote machine. -->
<!-- The saved PNG file  -->
</section><section id="frontend" class="level4"><h4 class="anchored" data-anchor-id="frontend">Frontend</h4>
</section><section id="communications-between-software" class="level4"><h4 class="anchored" data-anchor-id="communications-between-software">Communications between Software</h4>
</section></section><section id="distribute-keras-model-files" class="level3" data-number="4.3.3"><h3 data-number="4.3.3" class="anchored" data-anchor-id="distribute-keras-model-files">
<span class="header-section-number">4.3.3</span> Distribute Keras Model Files</h3>
</section><section id="performance-optimization" class="level3" data-number="4.3.4"><h3 data-number="4.3.4" class="anchored" data-anchor-id="performance-optimization">
<span class="header-section-number">4.3.4</span> Performance Optimization</h3>
</section></section><section id="conclusions" class="level2" data-number="4.4"><h2 data-number="4.4" class="anchored" data-anchor-id="conclusions">
<span class="header-section-number">4.4</span> Conclusions</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-abadi2016tensorflow" class="csl-entry" role="listitem">
Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., and others (2016), <span>“Tensorflow: Large-scale machine learning on heterogeneous distributed systems,”</span> <em>arXiv preprint arXiv:1603.04467</em>.
</div>
<div id="ref-buja2009statistical" class="csl-entry" role="listitem">
Buja, A., Cook, D., Hofmann, H., Lawrence, M., Lee, E.-K., Swayne, D. F., and Wickham, H. (2009), <span>“Statistical inference for exploratory data analysis and model diagnostics,”</span> <em>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</em>, The Royal Society Publishing, 367, 4361–4383.
</div>
<div id="ref-chollet2015keras" class="csl-entry" role="listitem">
Chollet, F., and others (2015), <span>“Keras,”</span> <a href="https://keras.io" class="uri">https://keras.io</a>.
</div>
<div id="ref-clark2015pillow" class="csl-entry" role="listitem">
Clark, A., and others (2015), <span>“Pillow (pil fork) documentation,”</span> <em>readthedocs</em>.
</div>
<div id="ref-cook1982residuals" class="csl-entry" role="listitem">
Cook, R. D., and Weisberg, S. (1982), <em>Residuals and influence in regression</em>, New York: Chapman; Hall.
</div>
<div id="ref-ggresidpanel" class="csl-entry" role="listitem">
Goode, K., and Rey, K. (2019), <em><a href="https://CRAN.R-project.org/package=ggResidpanel">ggResidpanel: Panels and interactive versions of diagnostic plots using ’ggplot2’</a></em>.
</div>
<div id="ref-harris2020array" class="csl-entry" role="listitem">
Harris, C. R., Millman, K. J., Van Der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., and others (2020), <span>“Array programming with NumPy,”</span> <em>Nature</em>, Nature Publishing Group UK London, 585, 357–362.
</div>
<div id="ref-dharma" class="csl-entry" role="listitem">
Hartig, F. (2022), <em><a href="https://CRAN.R-project.org/package=DHARMa">DHARMa: Residual diagnostics for hierarchical (multi-level / mixed) regression models</a></em>.
</div>
<div id="ref-olsrr" class="csl-entry" role="listitem">
Hebbali, A. (2024), <em><a href="https://CRAN.R-project.org/package=olsrr">Olsrr: Tools for building OLS regression models</a></em>.
</div>
<div id="ref-hornik2012comprehensive" class="csl-entry" role="listitem">
Hornik, K. (2012), <span>“The comprehensive r archive network,”</span> <em>Wiley interdisciplinary reviews: Computational statistics</em>, Wiley Online Library, 4, 394–398.
</div>
<div id="ref-rockchalk" class="csl-entry" role="listitem">
Johnson, P. E. (2022), <em><a href="https://CRAN.R-project.org/package=rockchalk">Rockchalk: Regression estimation and presentation</a></em>.
</div>
<div id="ref-bandicoot" class="csl-entry" role="listitem">
Li, W. (2024), <span>“<a href="https://CRAN.R-project.org/package=bandicoot">Bandicoot: Light-weight python-like object-oriented system</a>.”</span>
</div>
<div id="ref-li2024plot" class="csl-entry" role="listitem">
Li, W., Cook, D., Tanaka, E., and VanderPlas, S. (2024), <span>“A plot is worth a thousand tests: Assessing residual diagnostics with the lineup protocol,”</span> <em>Journal of Computational and Graphical Statistics</em>, Taylor &amp; Francis, 1–19.
</div>
<div id="ref-jtools" class="csl-entry" role="listitem">
Long, J. A. (2022), <em><a href="https://cran.r-project.org/package=jtools">Jtools: Analysis and presentation of social scientific data</a></em>.
</div>
<div id="ref-mason2022cassowaryr" class="csl-entry" role="listitem">
Mason, H., Lee, S., Laa, U., and Cook, D. (2022), <em><a href="https://CRAN.R-project.org/package=cassowary">Cassowaryr: Compute scagnostics on pairs of numeric variables in a data set</a></em>.
</div>
<div id="ref-stats" class="csl-entry" role="listitem">
R Core Team (2022), <em><a href="https://www.R-project.org/">R: A language and environment for statistical computing</a></em>, Vienna, Austria: R Foundation for Statistical Computing.
</div>
<div id="ref-regressinator" class="csl-entry" role="listitem">
Reinhart, A. (2024), <em><a href="https://CRAN.R-project.org/package=regressinator">Regressinator: Simulate and diagnose (generalized) linear models</a></em>.
</div>
<div id="ref-simonyan2014very" class="csl-entry" role="listitem">
Simonyan, K., and Zisserman, A. (2014), <span>“Very deep convolutional networks for large-scale image recognition,”</span> <em>arXiv preprint arXiv:1409.1556</em>.
</div>
<div id="ref-reticulate" class="csl-entry" role="listitem">
Ushey, K., Allaire, J., and Tang, Y. (2024), <em><a href="https://CRAN.R-project.org/package=reticulate">Reticulate: Interface to ’python’</a></em>.
</div>
<div id="ref-ggplot2" class="csl-entry" role="listitem">
Wickham, H. (2016), <em><a href="https://ggplot2.tidyverse.org">ggplot2: Elegant graphics for data analysis</a></em>, Springer-Verlag New York.
</div>
<div id="ref-nullabor" class="csl-entry" role="listitem">
Wickham, H., Chowdhury, N. R., Cook, D., and Hofmann, H. (2020), <em><a href="https://CRAN.R-project.org/package=nullabor">Nullabor: Tools for graphical inference</a></em>.
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./03-chap3.html" class="pagination-link" aria-label="Automated Assessment of Residual Plots with Computer Vision Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Automated Assessment of Residual Plots with Computer Vision Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./refs.html" class="pagination-link" aria-label="Bibliography">
        <span class="nav-page-text">Bibliography</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/TengMCing/PhD/edit/master/Thesis/04-chap4.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer></body></html>