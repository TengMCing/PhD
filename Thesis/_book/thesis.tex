% This is a LaTeX thesis template for Monash University.
% to be used with Rmarkdown
% This template was produced by Rob Hyndman
% Version: 6 September 2016

\documentclass{monashthesis}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Add any LaTeX packages and other preamble here if required
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author{Weihao Li}
\title{Advances in Artificial Intelligence for Data Visualization: Developing Computer Vision Models to Automate Reading of Data Plots, with Application to Predictive Model Diagnostics}
\degrees{B.Comm. (Hons), Monash University}
\def\degreetitle{Doctor of Philosophy}
% Add subject and keywords below
\hypersetup{
     %pdfsubject={The Subject},
     %pdfkeywords={Some Keywords},
     pdfauthor={Weihao Li},
     pdftitle={Advances in Artificial Intelligence for Data Visualization: Developing Computer Vision Models to Automate Reading of Data Plots, with Application to Predictive Model Diagnostics},
     pdfproducer={Bookdown with LaTeX}
}


\bibliography{thesisrefs}

\begin{document}

\pagenumbering{roman}

\titlepage

{\setstretch{1.2}\sf\tighttoc\doublespacing}

\hypertarget{copyright-notice}{%
\chapter*{Copyright notice}\label{copyright-notice}}
\addcontentsline{toc}{chapter}{Copyright notice}

\emph{(Choose one of the following notices.)}

\emph{(Notice 1)}

\textcopyright { } \authorname~(\number\the\year).

\emph{The second notice certifies the appropriate use of any third-party material in the thesis. Students choosing to deposit their thesis into the restricted access section of the repository are not required to complete Notice 2.}

\emph{(Notice 2)}

\textcopyright { } \authorname~(\number\the\year).

I certify that I have made all reasonable efforts to secure copyright permissions for third-party content included in this thesis and have not knowingly added copyright content to my work without the owner's permission.

\newpage

\hypertarget{abstract}{%
\chapter*{Abstract}\label{abstract}}
\addcontentsline{toc}{chapter}{Abstract}

The abstract should outline the main approach and findings of the thesis and must not be more than 500 words.

\newpage

\hypertarget{declaration}{%
\chapter*{Declaration}\label{declaration}}
\addcontentsline{toc}{chapter}{Declaration}

\emph{(Standard thesis)}

This thesis is an original work of my research and contains no material which has been accepted for the award of any other degree or diploma at any university or equivalent institution and that, to the best of my knowledge and belief, this thesis contains no material previously published or written by another person, except where due reference is made in the text of the thesis.

\emph{(Thesis including published works declaration)}

I hereby declare that this thesis contains no material which has been accepted for the award of any other degree or diploma at any university or equivalent institution and that, to the best of my knowledge and belief, this thesis contains no material previously published or written by another person, except where due reference is made in the text of the thesis.

This thesis includes (insert number) original papers published in peer reviewed journals and (insert number) submitted publications. The core theme of the thesis is (insert theme). The ideas, development and writing up of all the papers in the thesis were the principal responsibility of myself, the student, working within the (insert name of academic unit) under the supervision of (insert name of supervisor).

(The inclusion of co-authors reflects the fact that the work came from active collaboration between researchers and acknowledges input into team-based research.) Remove this paragraph for theses with sole-authored work

In the case of (insert chapter numbers) my contribution to the work involved the following:

I have / have not renumbered sections of submitted or published papers in order to generate a consistent presentation within the thesis.

\begin{table}
\centering\footnotesize\tabcolsep=0.12cm
\begin{tabular}{|p{1.2cm}|p{2cm}|p{1.8cm}|p{3.4cm}|p{3.5cm}|p{1.5cm}|}
\hline
\RaggedRight\textbf{Thesis chapter}  & 
\RaggedRight\textbf{Publication title}  & 
\RaggedRight\textbf{Status (published, in press, accepted or returned for revision)}  &  
\RaggedRight\textbf{Nature and \% of student contribution} & 
\RaggedRight\textbf{Co-author name(s), nature and \% of co-authorâ€™s contribution} &  \RaggedRight\textbf{Co-author(s), Monash student Y/N} \\ 
\hline
2 & xx & xx  & xx & xx & \multicolumn{1}{c|}{N}   \\
\hline
3 & xx & xx  & xx & xx  & \multicolumn{1}{c|}{N}   \\
\hline
4 & xx & xx  & xx & xx & \multicolumn{1}{c|}{N}    \\
\hline
5 & xx & xx  & xx & xx & \multicolumn{1}{c|}{N}   \\
\hline
\end{tabular}
\end{table}

\textbf{Student name:} \authorname

\textbf{Student signature:}

\textbf{Date:}

\hypertarget{acknowledgements}{%
\chapter*{Acknowledgements}\label{acknowledgements}}
\addcontentsline{toc}{chapter}{Acknowledgements}

I would like to thank my pet goldfish for \dots

\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

The material in Chapter \ref{ch:intro} has been submitted to the journal \emph{Journal of Impossible Results} for possible publication.

The contribution in Chapter \ref{ch:litreview} of this thesis was presented in the International Symposium on Nonsense held in Dublin, Ireland, in July 2015.

\clearpage\pagenumbering{arabic}\setcounter{page}{0}

\hypertarget{ch:intro}{%
\chapter{Introduction}\label{ch:intro}}

\hypertarget{ai-four-approaches}{%
\section{AI: Four Approaches}\label{ai-four-approaches}}

\textbf{Artificial intelligence} (AI) is the field of research concerned with understanding and building machines who can demonstrate intelligence. As discussed in \textcite{russell_artificial_2002}, historically, there are disagreements among researchers about the definition of intelligence, which is caused by two critical questions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Should AI act and think humanly or rationally?
\item
  Without the thought process and reasoning, are behaviours sufficient to demonstrate intelligence?
\end{enumerate}

Based on the answer to the above questions, four major approaches to pursue AI have been established. These approaches can be summarized into a two by two table as shown in figure \ref{fig:twodimai}, where the row is ``Human'' vs.~``Rational'', and the column is ``Behaviour'' vs.~``Thought''. Positioning at the top right cell, the \textbf{rational agent approach} aims to build agent that perform mathematically perfect acts such that the best expected outcome can always be achieved. In contrast, the \textbf{``laws of thought'' approach} focus on understanding the logic behind the rationality. Closely related to \textbf{cognitive science}, the \textbf{cognitive modelling approach} attempts to express theories of human cognition as computer program to mimic the thought process of human. Lastly, the \textbf{Turing test approach} is built upon the famous \textbf{Turing test} proposed by \textcite{turing_computing_1950}. The test can be roughly described as, whether a human can distinguish another human from a computer with written communications only. To pass the test, several capabilities of computer are required. This includes \textbf{natural language processing} for communication with human, \textbf{knowledge representation} for encoding knowledge, \textbf{automated reasoning} for derivation of conclusions and \textbf{machine learning} for improving AI automatically through experience and data. Some researchers argued that written communication is insufficient to demonstrate intelligence, and some degree of physical simulation of a person is still necessary. One such example is the \textbf{total Turing test} proposed by \textcite{harnad_other_1991}. It adds \(3\) new requirements to the list, including \textbf{computer vision}, \textbf{speech recognition} and \textbf{robotics}, which are response for interactions with the physical world. Notably, all \(7\) required capabilities have become major subfields of AI today. And their development has made AI one of the fastest-growing fields in the 21st century \autocite{russell_artificial_2002}.

\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/twodimai-1.pdf}
\caption{\label{fig:twodimai}Four possible approaches to pursue AI based on the two dimensions in AI research - human vs.~rational and thought vs.~behavior \autocite{russell_artificial_2002}.}
\end{figure}

With the development of AI, mature AI technologies, such as facial recognition and web recommendation system, have profoundly affected the way modern society operates and citizen's daily life. This is largely as a consequence of the huge investment in AI industry by the financial market in recent years. Further, the increasingly cheap computing cost and the massive amount of accessible e-commerce data produced in the Internet age provide the possibility for applying data-intensive AI models, which enables AI performance to reach new heights in history \autocite{jordan_machine_2015}. Some AI systems have already been remarkably better than human in certain areas, e.g., game playing. AlphaGo and AlphaZero developed by the Google DeepMind team surpass all human Go players \autocite{silver_general_2018}.

\hypertarget{predictive-modelling-and-visual-diagnostics}{%
\section{Predictive Modelling and Visual Diagnostics}\label{predictive-modelling-and-visual-diagnostics}}

Behind the success of AI, a great propotion of AI systems rely on the predictive modelling framework. \textcite{donoho_50_2017} in its summary of data science stated that the concept of this modelling culture could be traced back to an article written by Breiman (2001). In contrast to the generative modelling culture, which aims to develop stochastic models to make inferences about the data generating process, predictive modelling emphasizes the ability of the model to make accurate predictions. Most AI tasks are complex prediction problems where the data mechanism is mysterious, or at least, partly unknowable. \textcite{breiman_statistical_2001} suggests that generative models are obviously not applicable in these scenarios, while the predictive modelling seeks only an accurate approximated function \(\boldsymbol{f}(\boldsymbol{x})\) to describe the relationship between the features \(\boldsymbol{x}\) and the responses \(\boldsymbol{y}\).

Predictive models are primarily evaluated by predictive accuracy with the use of validation and test data, but in predictive model diagnostics, especially model testing and tuning, data plots play an irreplaceable role. In these diagnostics, though numeric summaries are mostly available and some are even endorsed by finite or asymptotic properties, graphical representation of data is still preferred, or at least needed by researchers, due to its intuitiveness and the possibility to provide unexpected discoveries which may be abstract and unquantifiable.

However, unlike confirmatory data analysis built upon rigorous statistical procedures, e.g., hypothesis testing, visual diagnostics relies on graphical perception - human's ability to interpret and decode the information embedded in the graph \autocite{cleveland_graphical_1984}, which is to some extent subjective. Further, visual discovery suffers from its unsecured and unconfirmed nature where the degree of the presence of the visual features typically can not be measured quantitatively and objectively, which may lead to over or under-interpretations of the data. One such example is finding a separation between gene groups in a two-dimensional projection from a linear discriminant analysis where there is no difference in the expression levels between the gene groups \autocite{roy_chowdhury_using_2015}.

\hypertarget{visual-inference}{%
\section{Visual Inference}\label{visual-inference}}

Visual inference was first introduced by \textcite{buja_statistical_2009} as an inferential framework to extend confirmatory statistics to visual discoveries. This framework redefines the test statistics, tests, null distribution, significance levels and \(p\)-value for visual discovery modelled on the confirmatory statistical testing. Figure \ref{fig:parallelism} outlines the parallelism between conventional tests and visual discovery.

\begin{figure}
\centering
\includegraphics[width=4.6875in,height=3.55208in]{figures/rsta2009012001.jpg}
\caption{Parallelism between multiple quantitative testing and visual discovery \autocite{buja_statistical_2009}. Visible features in a plot are viewed as a collection of test statistics \(T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)\), and any visual discoveries are treated as evidence against the null hypothesis. \label{fig:parallelism}}
\end{figure}



In visual inference, a visual discovery is defined as a rejection of a null hypothesis, and the same null hypothesis can be rejected by many different visual discoveries \autocite{buja_statistical_2009}. For model diagnostics, the null hypothesis would be the assumed model, while the visual discoveries would be any findings that are inconsistent with the null hypothesis. The same assumed model, such as classical linear regression model, can be rejected by many reasons with residual plot, including nonlinearity and heteroskedasticity as shown in figure \ref{fig:nonlinearityheter}.

\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/nonlinearityheter-1.pdf}
\caption{\label{fig:nonlinearityheter}Residuals vs.~fitted values plot for a classical linear regression model. The residuals are produced by fitting a two-predictor multiple linear regression model with data generated from a cubic linear model. From the residual plot, ``butterfly shape'' can be observed which generally would be interpretd as evidence of heteroskedasticity. Further, from the outline of the shape, nonlinear patterns exist. Both visual discoveries are evidence against the null hypothesis, though heteroskedasticity actually does not exist in the data generating process.}
\end{figure}

\hypertarget{pre-specification-of-visual-discoverable-features}{%
\section{Pre-specification of Visual Discoverable Features}\label{pre-specification-of-visual-discoverable-features}}

As discussed in \textcite{buja_statistical_2009}, in the practice of model diagnostics, the range of possible visual discoveries is not pre-specified. In other words, people do not explicitly specify which one or more visual features they are looking for before the read of the diagnostic plot. This is concerning since conventional hypothesis testing always requires the pre-specification of the parameter space \(\Theta\) of the parameter of interest \(\theta \in \Theta\) to form a valid inferential procedure. To address this issue, a collection of test statistics \(T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)\) is defined, where \(\boldsymbol{\mathrm{y}}\) is the data and \(\boldsymbol{I}\) is a set of all possible visual features. \textcite{buja_statistical_2009} described each of the test statistics \(T^{(i)}(\boldsymbol{\mathrm{y}})\) as a measurement of the degree of presence of a visual feature. Alternatively, \textcite{majumder_validation_2013} avoids the use of visual features and defined the visual statistics \(T(.)\) as a mapping from a dataset to a data plot. Both definitions of visual test statistics are valid, but in the rest of the paper the first definition will be used as it covers some details needed by the following discussion.

The size of the collection \(T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)\) depends on the size of the set \(I\). Thus, if one can define \(I\) comprehensively, i.e, pre-specify all the visual discoverable features, the validity issue will be solved. Unfortunately, to our knowledge, there is no such a way to list all visual features. In linear regression diagnostics, possible visual features of a residual plot may be outliers, shapes and clusters. But this is an incomplete list which does not enumerate all the visual features.

Similarly, \textcite{wilkinson_graph-theoretic_2005} proposed the work called graph theoretic scagnostics, which adopted the idea of ``scagnostics'' - scatter plot diagnostics from (can't find the 1984 citation). It includes 9 computable scagnostics measures defined on planar proximity graphs: ``Outlying'', ``Convex'', ``Skinny'', ``Stringy'', ``Straight'', ``Monotonic'', ``Skewed'', ``Clumpy'' and ``Striated'' which attempts to describe outliers, shape, density, trend and coherence of the data. This approach is inspiring but it still does not give the complete list of visual discoverable features. In fact, it is possible that such a list will never be complete as suggested in \textcite{buja_statistical_2009}.

Thinking out of the box, \textcite{buja_statistical_2009} argued that there is actually no need for pre-specification of visual discoverable features. In model diagnostics, when the null hypothesis is rejected, the reasons for rejecting the hypothesis will also be known. This is because observers can not only point out the fact that visual discoveries have been found, but also describe the particular visual features they observed. Those features will correspond to the subset of the collection of visual test statistics \(T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)\) which resulted in rejection. This argument helps justifies the validity of visual inference.

\hypertarget{lineup-protocol}{%
\section{Lineup Protocol}\label{lineup-protocol}}

With the validity of visual inference being justified, another aspect of hypothesis testing that needs to be addressed is the control of false positive rate or Type I error. Any visual statistic \(T^{(i)}(\boldsymbol{\mathrm{y}})\) needs to pair with a critical value \(c^{(i)}\) to form a hypothesis test. When a visual feature \(i\) is discovered by the observer from a plot, the corresponding visual statistic \(T^{(i)}(\boldsymbol{\mathrm{y}})\) may not be known as there is no general agreement on the measurement of the degree of presence of a visual feature. It is only the event that \(T^{(i)}(\boldsymbol{\mathrm{y}}) > c^{(i)}\) is confirmed. Similarly, if any visual discovery is found by the observer, we say, there exists \(i \in I:~T^{(i)}(\boldsymbol{\mathrm{y}}) > c^{(i)}\) \autocite{buja_statistical_2009}.

Using the above definition, the family-wise Type I error can be controlled if one can provide the collection of critical values \(c^{(i)}~(i \in I)\) such that \(P(\mathrm{there~exists~} i \in I: T^{(i)}(\boldsymbol{\mathrm{y}}) > c^{(i)}|\boldsymbol{\mathrm{y}}) \leq \alpha\), where \(\alpha\) is the significance level. However, since the quantity of \(T^{(i)}(\boldsymbol{\mathrm{y}})\) may not be known, such collection of critical values can not be provided.

\textcite{buja_statistical_2009} proposed the lineup protocol as a visual test to calibrate the Type I error issue without the specification of \(c^{(i)}~(i \in I)\). It is inspired by the ``police lineup'' or ``identity parade'' which is the act of asking the eyewitness to identify criminal suspect from a group of irrelevant people. The protocol consists of \(m\) randomly placed data plots, where \(1\) plot is the actual data plot, and \(m-1\) null plots are produced by plotting data simulate from the null distribution which is consistent with the null hypothesis. Then, an observer who have not seen the actual data plot will be asked to point out the most different plot from the lineup.

Under the null hypothesis, it is expected that the actual data plot would have no distinguishable difference with the null plots, and the probability of the observer correctly picks the actual data plot is \(1/m\) due to randomness. If we reject the null hypothesis as the observer correctly picks the actual data plot, then the Type I error of this test is \(1/m\).

This provides us with an mechanism to control the Type I error, because \(m\) - the number of plots in a lineup can be chosen. A larger value of \(m\) will result in a smaller Type I error, but the limit to the value of \(m\) depends on the number of plots a human willing to view \autocite{buja_statistical_2009}. Typically, \(m\) will be set to \(20\) which is equivalent to set \(\alpha = 0.05\), a general choice of significance level for conventional testing among statisticians.

Further, if we involve \(K\) independent observers in a visual test, and let \(X\) be a random variable denoting the number of observers correctly picking the actual data plot. Then, under the null hypothesis \(X \sim \mathrm{Binom}_{K,1/m}\), and therefore, the \(p\)-value of a lineup of size \(m\) evaluated by \(K\) observer is given as

\[P(X \geq x) = \sum_{i=x}^{K}{{K}\choose{i}}\left(\frac{1}{m}\right)^i\left(\frac{m-1}{m}\right)^{k-i},\]
where \(x\) is the realization of number of observers correctly picking the actual data plot \autocite{majumder_validation_2013}.

The multiple individuals approach avoids the limit of \(m\), while provides visual tests with \(p\)-value much smaller than \(0.05\). In fact, the lower bound of \(p\)-value decreases exponentially as \(K\) increases. With just \(4\) individuals and \(20\) data plots in a lineup, the \(p\)-value could be as small as \(0.0001\).

Compared to the conventional test, whose power only depends on the parameter of interest \(\theta\), several studies \autocites[see][]{hofmann_graphical_2012,majumder_validation_2013,majumder_human_2014,roy_chowdhury_using_2015,loy_variations_2016} have shown the power of the visual test is subject-specific. Thus, to be able to account for individual's ability, an individual is required to evaluate multiple lineups \autocite{majumder_validation_2013}.

Assumes that individuals have the same ability and a lineup has been evaluated by multiple individuals, under the alternative hypothesis, the estimated power for a lineup can be expressed as \(\hat{p} = x/K\), the estimated probability of identifying the actual data plot from the lineup. If the individual skill needs to be taken into account, and \(L\) lienups have been evaluated by \(K\) individuals, \textcite{majumder_validation_2013} suggests that mixed effects logistic regression model can be fit as:

\[g(p_{li}) = W_{li}\delta + Z_{li}\tau_{li},\]
where \(g(.)\) is the logit link function \(g(p) = log(p) - log(1-p)\); \(0 \leq p \leq 1\). \(W_{li}\), \(1 \leq i \leq K\), \(1 \leq l \leq L\), is the covariate matrix including lineup-specific elements and demographic information of individuals, and \(\delta\) is a vector of parameters. \(Z\) is the random effects matrix, and \(\tau\) is a vector of variables follow \(N(\boldsymbol{0},\sigma_{\tau}\boldsymbol{I}_{KL\times KL})\).

Then, the estimated power for lineup \(l\) and individual \(i\) can be calculated as \(\hat{p}_{li} = g^{-1}(W_{li}\hat{\delta} + Z_{li}\hat{\tau}_{li})\) \autocite{majumder_validation_2013}.

\hypertarget{applications-of-lineup-protocol}{%
\section{Applications of Lineup Protocol}\label{applications-of-lineup-protocol}}

Lineup protocols are

List applications, fields, significance here.

\hypertarget{limitations-of-visual-tests}{%
\section{Limitations of visual tests}\label{limitations-of-visual-tests}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  infeasible in a large scale
\item
  unfriendly to vision-impaired people
\item
  high finical cost and human cost
\item
  time consuming
\end{enumerate}

similar to Handicraft in pre-industrial society

\hypertarget{automatic-visual-inference---computer-vision}{%
\section{Automatic visual inference -\textgreater{} Computer vision}\label{automatic-visual-inference---computer-vision}}

relieve people's workload by automating repeating tasks, and provide standard result in a control environment

the use of technology and machinery to enable mass evaluation of visual tests

\hypertarget{discussion-of-potential-methods}{%
\section{Discussion of potential methods}\label{discussion-of-potential-methods}}

\hypertarget{different-approaches-of-ai}{%
\subsection{different approaches of AI}\label{different-approaches-of-ai}}

\begin{itemize}
\tightlist
\item
  Not aim for understanding the thought process
\item
  Not aim for mimicking the human vision mechanism
\item
  May be able to define distance metrics to measure difference between data plots for making mathematically prefect decisions
\item
  May be able to use computer vision model to approximate how people evaluate lineups
\end{itemize}

computer vision model:

\begin{itemize}
\tightlist
\item
  Use human data to train model with human selection as target -\textgreater{} mimic the human behaviour
\item
  Use simulated lineup to train model with actual data plot as target -\textgreater{} assume the actual data plot is the most different one
\item
  Use simulated data plot to train model with null or not null as target -\textgreater{} limited to the alternatives given to the model, and Type I error can not be controlled
\item
  Use simulated data plot to train model, then let the model evaluate each plot of a lineup -\textgreater{} leads to multiple selections in a lineup, and the model does not compare different plots in a lineup

  \begin{itemize}
  \tightlist
  \item
    Use a very large \(m\) to ensure the null hypothesis can be rejected by a classifier slightly better than a random selector. The problem becomes how large the \(m\) should be
  \item
    Use multiple models as multiple individuals to evaluate lineup -\textgreater{} Which models should be used? How many models should be used?
  \end{itemize}
\item
  Let the model select multiple plots from a simulated lineup while comparing different plots in a lineup -\textgreater{} how to build such a system?

  \begin{itemize}
  \tightlist
  \item
    The input is \(m\) plots, what is the output? The probability of being the most different one?
  \item
    Then how many plots should be selected? Top 5? Or cumulative probability greater than a threshold?
  \item
    How to select the threshold?
  \end{itemize}
\end{itemize}

\hypertarget{human-subject-exeriments-toc}{%
\chapter{Human Subject Exeriments (toc)}\label{human-subject-exeriments-toc}}

What needs to be discussed?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  online recruitment platform (Prolific)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  pre-screen
\item
  approve and reject
\item
  redirect
\item
  payment
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  study web site
\end{enumerate}

\begin{itemize}
\tightlist
\item
  PythonAnywhere
\item
  Flask, Python
\item
  jsPsych
\item
  survey

  \begin{itemize}
  \tightlist
  \item
    age
  \item
    education
  \item
    preferred pronoun
  \item
    previous experience
  \end{itemize}
\item
  training
\item
  20 lineups

  \begin{itemize}
  \tightlist
  \item
    setup depends on the study
  \end{itemize}
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Cubic model
\end{enumerate}

\begin{itemize}
\tightlist
\item
  data generating process
\item
  null model
\item
  potential shapes
\item
  effect size
\item
  conventional test
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Heteroskedasticity model
\end{enumerate}

\begin{itemize}
\tightlist
\item
  data generating process
\item
  null model
\item
  potential shapes
\item
  effect size
\item
  conventional test
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Number of participants needed by the study
\item
  Study 1
\end{enumerate}

\begin{itemize}
\tightlist
\item
  logistic regression

  \begin{itemize}
  \tightlist
  \item
    easy
  \item
    medium
  \item
    hard
  \end{itemize}
\item
  number of participants
\item
  time
\item
  countries
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Study 2
\end{enumerate}

\begin{itemize}
\tightlist
\item
  logistic regression

  \begin{itemize}
  \tightlist
  \item
    easy
  \item
    medium
  \item
    hard
  \end{itemize}
\item
  number of participants
\item
  time
\item
  countries
\end{itemize}

\hypertarget{human-subject-exeriments}{%
\chapter{Human Subject Exeriments}\label{human-subject-exeriments}}

To collect data of human performance on reading residual plot of linear regression model with nonlinearity and heteroskedasticity defects, two human experiments were conducted. Participants of both experiments were recruited using an online platform called Prolific \autocite{prolific_prolific_2022}.

Prolific provides an international participant pool with the option to apply flexible pre-screening filters. In this study, we recruited participants who is fluent in English with at least \(10\) previous submissions and \(98\)\% approval rate in other Prolific studies for quality control. Further, balance sample across gender was imposed to prevent gender bias.

In Prolific, researchers can either approve or reject submissions based on the quality of the responses. If a submission is approved by the researcher, the participant will be paid a certain amount of money per hour of time spent on the experiment. To assess the quality of the responses, two attention checks were given to each participant during the experiment, where at least one of them was required to pass for the approval of submission.

Throughout the experiments, participants were requested to complete a short survey and evaluate 20 lineups on a website in an hour. Each lineup each consists of 19 null residual plots and 1 actual residual plot. Among the 20 lineups, there are 2 extremely east lineups used as attention checks which everyone should get correct. The short survey was intended to collect information about participant that might affect their ability in reading data plot including age, highest education, preferred pronoun and previous experience in similar study. For the evaluation of the lineup, participant first needed to select one or multiple most different data plot(s) from the lineup by clicking the corresponding image. Then, the reason for choosing the plots needed to be provided by selecting one of the given options - ``outlier(s)'', ``cluster(s)'', ``shape'' and ``other''. Explanations about these options were provided in the training page and the mouseover text. Table \ref{tab:lineupreason} gives the detailed explanations about these reasons. If the option ``other'' was selected, text input for the specified reason would be collected. Lastly, the degree of difference between their chosen data plot(s) and other data plots needed to be selected among \(5\) levels - ``not at all'', ``slightly'', ``moderately'', ``very'' and ``extremely''.

\begin{table}

\caption{\label{tab:lineupreason}Explanations about reasons for choosing data plots from a lineup}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{ll}
\toprule
Reasons & Explanations\\
\midrule
outlier(s) & In a data plot, an outlier is a point that differs significantly from other points.\\
cluster(s) & In a data plot, a cluster is a group of points positioned closely together. 
And usually, there will be gaps between different clusters.\\
shape & It could be any common shapes we would see in real life, like triangle shape, U-shape, butterfly shape, etc.\\
other & Patricipants needs to give their reasons in the text input.\\
\bottomrule
\end{tabular}}
\end{table}

The study website was powered by Flask \autocite{grinberg_flask_2018}, a web framework written in Python 3 \autocite{van_rossum_python_2009}, hosted on PythonAnywhere \autocite{pythonanywhere_pythonanywhere_2022}, a web hosting service provider. The website is built using a JavaScript \autocite{flanagan_javascript_2006} library jsPsych \autocite{de_leeuw_jspsych_2015} which is specialized in creating online behavioral experiments. One of the reasons we chose to use this library was it had a modularized but highly customizable template which could record participant's response time automatically. This is essential for us to confirm the quality of the data by checking exceptionally fast or slow responses. The first two pages of the website are the explanatory statement and the consent form. Participants needed to read the documentation and agree with the terms to advance to the short survey. With the completion of the survey, the next page is the training page, which contained instructions on how to evaluate the lineup, give the reason and choose the confidence level. Followed by the training page, there are 20 lineups each on a single page. At the end of the experiment, the participants would be redirected back to Prolific and waited for researchers' responses.

Next we will discuss the simulation setup for this study. The experiment data was simulated by the use of the programming language \texttt{R} \autocite{r_core_team_r_2021}. For the ease of reproducibility, functions to build models, simulate data from models, produce lineup with data, allocate stimulis for subjects and evaluate subject responses from this study are bundled in the package \texttt{visage} with a unique object-oriented programming system built upon the environment feature of \texttt{R}. In the description of the simulation, corresponding functionalities of the package will be introduced.

Two models were used in both experiments, which were linear models with some degree of violations of classical assumptions. Residuals vs.~fitted values plots were used to diagnose the issues.

\hypertarget{cubic-model}{%
\section{Cubic Model}\label{cubic-model}}

The first model was a cubic linear model with 2 regressors, which can be expressed by: \[\boldsymbol{Y}= 1 + (2-c)\boldsymbol{X} + c\boldsymbol{Z} + a[(2-c)\boldsymbol{X}]^2+a(c\boldsymbol{Z})^2+b[(2-c)\boldsymbol{X}]^3+b(c\boldsymbol{Z})^3+\boldsymbol{\varepsilon},\] where \(c \in (0,2)\), \(a \in (-3,3)\), \(b \in (-3,3)\), \(\boldsymbol{\varepsilon}\overset{iid}{\sim} N(\boldsymbol{0},\sigma^2\boldsymbol{I})\), \(\boldsymbol{X}\) and \(\boldsymbol{Z}\) are \(n\times1\) matrices.

This defines a cubic relationship between \(\boldsymbol{Y}\), \(\boldsymbol{X}\) and \(\boldsymbol{Z}\). Meanwhile, to create nonlinearity defect, the null model fitted by the OLS is: \[\boldsymbol{Y}=\boldsymbol{b}_0+\boldsymbol{b}_1\boldsymbol{X}+\boldsymbol{b}_2\boldsymbol{Z}+\boldsymbol{e}.\]

Clearly, there will be omitted-variable bias since the null model leaves out the quadric and cubic terms.

\hypertarget{distribution-of-the-residuals}{%
\subsection{Distribution of the Residuals}\label{distribution-of-the-residuals}}

Let \(\boldsymbol{X}_a=[\boldsymbol{1},\boldsymbol{X},\boldsymbol{Z}]\) denotes the set of regressors in matrix form. Using the Frisch--Waugh--Lovell theorem, the residual obtained by the null model is \(\boldsymbol{e}=\boldsymbol{R}_a\boldsymbol{Y}=\boldsymbol{R}_a(\boldsymbol{X}_a\boldsymbol{\beta}_a+\boldsymbol{X}_b\boldsymbol{\beta}_b+\boldsymbol{\varepsilon}),\) where \(\boldsymbol{R}_a=\boldsymbol{I}-\boldsymbol{X}_a(\boldsymbol{X}_a'\boldsymbol{X}_a)^{-1}\boldsymbol{X}_a'\), \(\boldsymbol{\beta}_a=(1,2-c,c)'\), \(\boldsymbol{X}_b=[\boldsymbol{X}^2,\boldsymbol{Z}^2,\boldsymbol{X}^3,\boldsymbol{Z}^3]\) and \(\boldsymbol{\beta}_b=(a(2-c)^2,ac^2,b(2-c)^3,bc^3)'\).

Because \(\boldsymbol{R}_a\boldsymbol{X}_a=\boldsymbol{0}\), we have \(\boldsymbol{e}=\boldsymbol{R}_a(\boldsymbol{X}_b\boldsymbol{\beta}_b+\boldsymbol{\varepsilon}).\) Since \(\boldsymbol{\varepsilon} \sim N(0,\sigma^2\boldsymbol{I})\), it follows that \(\boldsymbol{e} \sim N(\boldsymbol{R}_a\boldsymbol{X}_b\boldsymbol{\beta}_b, \sigma^2\boldsymbol{R}_a)\).

\hypertarget{shape-of-the-residuals}{%
\subsection{Shape of the Residuals}\label{shape-of-the-residuals}}

The previous result shows that the expectation of the residuals is clearly a function of \(\boldsymbol{X}\) and \(\boldsymbol{Z}\). Hence, we would expect to see some patterns in the residual plot. Given the expectation of the residuals, we could plot the expected values of residuals against the observed values. Figure \ref{fig:cubic1}, \ref{fig:cubic2} and \ref{fig:cubic3} illustrate the shape of residuals under different parameter settings.

The residuals used in these three figures are simulated from the cubic models built using the \texttt{cubic\_model()} function from the package \texttt{visage}. \texttt{cubic\_model()} is a cubic model class constructor, which takes arguments \texttt{a}, \texttt{b}, \texttt{c}, \texttt{sigma}, \texttt{x} and \texttt{z}, where the first four are numeric values defined above, and \texttt{x} and \texttt{z} are random variable instances created by the random variable abstract base class constructor \texttt{rand\_var()}.

Here, we set \(\boldsymbol{X}\) and \(\boldsymbol{Z}\) to be random uniform variables ranged from \(-1\) to \(1\). This can be done by using the random uniform variable class constructor \texttt{rand\_uniform()} inherited from the random variable abstract base class. It only takes two arguments which are the lower bound and the upper bound of the support.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(visage)}
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cubic\_model}\NormalTok{(}\AttributeTok{a =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\AttributeTok{b =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\AttributeTok{c =} \DecValTok{1}\NormalTok{, }\AttributeTok{sigma =} \FloatTok{0.5}\NormalTok{, }
                   \AttributeTok{x =} \FunctionTok{rand\_uniform}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{z =} \FunctionTok{rand\_uniform}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

An instance of cubic model class contains methods of simulating data and making residual plot. Method \texttt{mod\$gen()} returns a data frame containing realizations of \(x\), \(z\), \(y\) and \(\varepsilon\) simulated from the model. The number of realizations depends on the integer argument \texttt{n}. In addition, if argument \texttt{fit\_model\ =\ TRUE}, a null model will be fitted using the simulated data and residuals and fitted values will be included in the returned data frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod}\SpecialCharTok{$}\FunctionTok{gen}\NormalTok{(}\AttributeTok{n =} \DecValTok{5}\NormalTok{, }\AttributeTok{fit\_model =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             y          x          z          e      .resid     .fitted
## 1  0.72328137  0.8783282 0.17687898  0.1539500  0.37649863  0.34678274
## 2 -0.01317346  0.9593166 0.30200008 -0.3526064 -0.22899266  0.21581920
## 3  0.10405716  0.7677855 0.72090641 -0.4481692  0.36279717 -0.25874001
## 4 -0.53007353  0.9238035 0.55802451 -0.8849474 -0.46221585 -0.06785768
## 5  0.33947802 -0.7784446 0.02191688  0.2307539 -0.04808729  0.38756531
\end{verbatim}

Method \texttt{mod\$plot()} produce a ggplot \autocite{wickham_ggplot2_2011} object. It takes a data frame containing columns \texttt{.resid} and \texttt{.fitted} as input, along with a character argument \texttt{type} indicating the type of the data plot, and other aesthetic arguments such as \texttt{size} and \texttt{alpha} to control the appearance of the plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod}\SpecialCharTok{$}\FunctionTok{plot}\NormalTok{(mod}\SpecialCharTok{$}\FunctionTok{gen}\NormalTok{(}\AttributeTok{n =} \DecValTok{100}\NormalTok{, }\AttributeTok{fit\_model =} \ConstantTok{TRUE}\NormalTok{), }\AttributeTok{type =} \StringTok{"resid"}\NormalTok{, }\AttributeTok{size =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{thesis_files/figure-latex/test3-1.pdf}

The cubic model class also provides method to compute the expected values of residuals. Method \texttt{mod\$E()} takes a data frame with columns \texttt{x} and \texttt{z} as input, and returns a vector of expected values of residuals.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod}\SpecialCharTok{$}\FunctionTok{E}\NormalTok{(mod}\SpecialCharTok{$}\FunctionTok{gen}\NormalTok{(}\AttributeTok{n =} \DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  0.05836465 -0.03566983 -0.09457480 -0.01126447  0.08314445
\end{verbatim}

From the figure \ref{fig:cubic1}, it can be observed that with fixed \(\sigma\) and \(c\), \(a\) and \(b\) are controlling the 2D projection of a hypersurface, and seemingly performing some rotations along different axes. Figure \ref{fig:cubic2} shows that with fixed \(a\), \(b\) and \(\sigma\), \(c\) is controlling the contribution of \(\boldsymbol{X}\) and \(\boldsymbol{Z}\) to \(\boldsymbol{Y}\). If we move \(c\) toward \(0\) or \(2\), one variable will donminate another, which will mitigate some joint effects and resemble a typical cubic function. In figure \ref{fig:cubic3}, \(a\), \(b\) and \(c\) is held constant, and \(\sigma\) is controlling the noises around the expected values. As \(\sigma\) decreases, the underlying shape shows up.

\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/cubic1-1.pdf}
\caption{\label{fig:cubic1}cubic 1}
\end{figure}

\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/cubic2-1.pdf}
\caption{\label{fig:cubic2}cubic 2}
\end{figure}

\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/cubic3-1.pdf}
\caption{\label{fig:cubic3}cubic 3}
\end{figure}

\hypertarget{effect-size}{%
\subsection{Effect Size}\label{effect-size}}

Since we know that under the null hypothesis, the residual \(\boldsymbol{e}\sim N(\boldsymbol{0},\sigma^2\boldsymbol{R}_a)\). Thus, the difference between the expected values \(\boldsymbol{R}_a\boldsymbol{X}_b\boldsymbol{\beta}_b\) and \(\boldsymbol{0}\) represents the direct impact of the parameters \(a\) and \(b\) on the residuals. It is expected that the larger the magnitude of the expected value relative to the variance and covariance, the easier the human to spot the patterns in the residual plot.

To obtain a measure of the impact of \(a\) and \(b\) on the residuals, we need to address several properties of the residuals. First, because \(\boldsymbol{R}_a\) is not an identity matrix, the residuals will have different variance and will be correlated with each other. This can be fixed by standardizing the residuals by their variance-covariance matrix. Second, the difference between \(\boldsymbol{R}_a\boldsymbol{X}_b\boldsymbol{\beta}_b\) and \(\boldsymbol{0}\) could be negative, which is not ideal for comparison. Thus, the magnitude needs to be squared. Third, the measure needs to be a scalar. We could apply a weighted average operator \(\boldsymbol{W}\) on the transformed expected residuals to obtain a single numeric value. For simplicity, we set \(\boldsymbol{W}=n^{-1}\boldsymbol{1}\). This gives the effect size: \[ES=n^{-1}||\sigma^{-1}\boldsymbol{R}_a^{-\frac{1}{2}}\boldsymbol{R}_a\boldsymbol{X}_b\boldsymbol{\beta}_b||^2=n^{-1}\sigma^{-2}||\boldsymbol{R}_a^{\frac{1}{2}}\boldsymbol{X}_b\boldsymbol{\beta}_b||^2\approx n^{-1}\sigma^{-2}||diag(\boldsymbol{R}_a)^{\frac{1}{2}}\boldsymbol{X}_b\boldsymbol{\beta}_b||^2.\]

The interpretation of this effect size is the impact of parameter \(a\) and \(b\) on the squared deviation of the standardized expected residual per observation. It is not directly related to the shape, or the pattern observed from the residual plot, but it is a reasonable approximation of the degree of the deviation from the null residuals under our cubic model setting.

\includegraphics{thesis_files/figure-latex/unnamed-chunk-5-1.pdf}

\hypertarget{section}{%
\subsection{}\label{section}}

\hypertarget{heteroskedasticity-model}{%
\section{Heteroskedasticity Model}\label{heteroskedasticity-model}}

\clearpage

\hypertarget{ch:paper1}{%
\chapter{Automatic Visual Statistical Inference, with Application to Linear Regression Diagnostics}\label{ch:paper1}}

\hypertarget{abstract-1}{%
\section{Abstract}\label{abstract-1}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\hypertarget{model-diagnostics}{%
\subsection{Model Diagnostics}\label{model-diagnostics}}

{[}ET: suggestion: A model can be fitted to data with no guarantee of a meaningful interpretation. Model diagnostics play an important role in assessing the appropriateness of the model. The assessment can involve examining the goodness of fit, checking if there are potential violations of model assumptions and validating models with external information.{]}

Model diagnostics is the part of data analysis, preceded by the fit of a model, whose primary objectives are to examine the goodness of fit and reveal potential violations of model assumptions.

{[}ET: model fit is more than just goodness of fit and checking model assumptions. It's too reductive to say this because you could have a model with good fit (according to some metric) and no model violation but if the way that the data were collected was flawed then scientific interpretation of the model is rendered useless. Diagnostics involve also the domain knowledge checks as well.{]}

In these diagnostics, though numeric summaries are mostly available and some are even endorsed by finite or asymptotic properties, graphical representation of data is still preferred, or at least needed, due to its intuitiveness and the possibility to provide unexpected discoveries which may be abstract and
unquantifiable.

{[}ET: Generally, your sentences are too long. Break it up into smaller sentences. The generally idea is to make sentences that \emph{continue an idea from the preceding sentence} so it leads from one to the next naturally. E.g. Today is cloudy. Cloudy days are rare. Perhaps today will be different to other days!{]}

However, unlike confirmatory data analysis built upon rigorous statistical procedures, e.g., hypothesis testing, visual diagnostics relies on graphical perception - human's ability to interpret and decode the information embedded in the graph \autocite{cleveland_graphical_1984}, which is to some extent subjective. Further, visual discovery suffers from its unsecured and unconfirmed nature where the degree of the presence of the visual features typically can not be measured quantitatively and objectively, which may lead to over or under-interpretations of the data. One such example is finding a separation between gene groups in a two-dimensional projection from a linear discriminant analysis where there is no difference in the expression levels between the gene groups \autocite{roy_chowdhury_using_2015}.

{[}ET: Confirmatory data analysis is well characterised by a rigorous procedure to discern particular hypothesis. The most widespread form of confirmatory data analysis are the use of \(p\)-values in testing hypothesis in a frequentist framework. More specifically, hypothesis testing in a frequentist framework involve stating a well-defined hypotheses; summarising the evidence as a test statistic; and calculating the probability of observing a statistic as extreme as the observed test statistic under the null hypothesis. This rigour, however, is often not present when inferences are drawn from a plot.

Something about model diagnostics with a plot being the common thing to do..{]}

\hypertarget{visual-inference-1}{%
\subsection{Visual Inference}\label{visual-inference-1}}

Visual inference was first introduced by \textcite{buja_statistical_2009} as an inferential framework to extend confirmatory statistics to visual discoveries. This framework redefines the test statistics, tests, null distribution, significance levels and \(p\)-value for visual discovery modelled on the confirmatory statistical testing. Figure \ref{fig:fparallelism} outlines the parallelism between conventional tests and visual discovery.

{[}ET: note use Rmd syntax for figures references! So it's easy to use it for HTML later if you want to do something like \href{https://github.com/earowang/thesis}{Earo} and have PDF + HTML thesis. {]}

\begin{figure}
\centering
\includegraphics[width=4.6875in,height=3.55208in]{figures/rsta2009012001.jpg}
\caption{Parallelism between multiple quantitative testing and visual discovery \autocite{buja_statistical_2009}. Visible features in a plot are viewed as a collection of test statistics \(T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)\), and any visual discoveries are treated as evidence against the null hypothesis. \label{fig:parallelism}}
\end{figure}

Parallelism between multiple quantitative testing and visual discovery \autocite{buja_statistical_2009}. Visible features in a plot are viewed as a collection of test statistics \(T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)\), and any visual discoveries are treated as evidence against the null hypothesis. Parallelism between multiple quantitative testing and visual discovery \autocite{buja_statistical_2009}.

In visual inference, a visual discovery is defined as a rejection of a null hypothesis, and the same null hypothesis can be rejected by many different visual discoveries \autocite{buja_statistical_2009}. For model diagnostics, the null hypothesis would be the assumed model, while the visual discoveries would be any findings that are inconsistent with the hypothesis. The same assumed model, such as classical linear regression model, can be rejected by both nonlinearity and heteroskedasticity with the residual plot as shown in Figure \ref{fig:nonlinearityheter}.

\hypertarget{pre-specification-of-visual-discoverable-features-1}{%
\subsection{Pre-specification of Visual Discoverable Features}\label{pre-specification-of-visual-discoverable-features-1}}

As discussed in \textcite{buja_statistical_2009}, in the practice of model diagnostics, the range of possible visual discoveries is not pre-specified. In other words, people do not explicitly specify which one or more visual features they are looking for before the read of the diagnostic plot. This is concerning since conventional hypothesis testing always requires the pre-specification of the parameter space \(\Theta\) of the parameter of interest \(\theta \in \Theta\) to form a valid inferential procedure. To address this issue, a collection of test statistics \(T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)\) is defined, where \(\boldsymbol{\mathrm{y}}\) is the data and \(\boldsymbol{I}\) is a set of all possible visual features. \textcite{buja_statistical_2009} described each of the test statistics \(T^{(i)}(\boldsymbol{\mathrm{y}})\) as a measurement of the degree of presence of a visual feature. Alternatively, \textcite{majumder_validation_2013} avoids the use of visual features and defined the visual statistics \(T(.)\) as a mapping from a dataset to a data plot. Both definitions of visual test statistics are valid, but in the rest of the paper, the first definition will be used as it covered some details needed by this work.

The size of the collection \(T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)\) depends on the size of the set \(I\). Thus, if one can define \(I\) comprehensively, i.e, pre-specify all the visual discoverable features, the validity issue will be solved. Unfortunately, to our knowledge, there is no such a way to list all visual features. In linear regression diagnostics, possible visual features of a residual plot may be outliers, shapes and clusters. But this is an incomplete list which does not enumerate all the visual features.

Similarly, \textcite{wilkinson_graph-theoretic_2005} proposed the work called graph theoretic scagnostics, which adopted the idea of ``scagnostics'' - scatter plot diagnostics from (can't find the 1984 citation). It includes 9 computable scagnostics measures defined on planar proximity graphs: ``Outlying'', ``Convex'', ``Skinny'', ``Stringy'', ``Straight'', ``Monotonic'', ``Skewed'', ``Clumpy'' and ``Striated'' which attempts to describe outliers, shape, density, trend and coherence of the data. This approach is inspiring but it still does not give the complete list of visual discoverable features. In fact, it is possible that such a list will never be complete as suggested in \textcite{buja_statistical_2009}.

Thinking out of the box, \textcite{buja_statistical_2009} argued that there is actually no need for pre-specification of visual discoverable features. In model diagnostics, when the null hypothesis is rejected, the reasons for rejecting the hypothesis will also be known. This is because observers can not only point out the fact that visual discoveries have been found, but also describe the particular visual features they observed. Those features will correspond to the subset of the collection of visual test statistics \(T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)\) which resulted in rejection. This argument helps justifies the validity of visual inference.

\hypertarget{lineup-protocol-1}{%
\subsection{Lineup Protocol}\label{lineup-protocol-1}}

With the validity of visual inference being justified, another aspect of hypothesis testing that needs to be addressed is the control of false positive rate or Type I error. Any visual statistic \(T^{(i)}(\boldsymbol{\mathrm{y}})\) needs to pair with a critical value \(c^{(i)}\) to form a hypothesis test. When a visual feature \(i\) is discovered by the observer from a plot, the corresponding visual statistic \(T^{(i)}(\boldsymbol{\mathrm{y}})\) may not be known as there is no general agreement on the measurement of the degree of presence of a visual feature. It is only the event that \(T^{(i)}(\boldsymbol{\mathrm{y}}) > c^{(i)}\) is confirmed. Similarly, if any visual discovery is found by the observer, we say, there exists \(i \in I:~T^{(i)}(\boldsymbol{\mathrm{y}}) > c^{(i)}\) \autocite{buja_statistical_2009}.

Using the above definition, the family-wise Type I error can be controlled if one can provide the collection of critical values \(c^{(i)}~(i \in I)\) such that \(P(\mathrm{there~exists~} i \in I: T^{(i)}(\boldsymbol{\mathrm{y}}) > c^{(i)}|\boldsymbol{\mathrm{y}}) \leq \alpha\), where \(\alpha\) is the significance level. However, since the quantity of \(T^{(i)}(\boldsymbol{\mathrm{y}})\) may not be known, such collection of critical values can not be provided.

\textcite{buja_statistical_2009} proposed the lineup protocol as a visual test to calibrate the Type I error issue without the specification of \(c^{(i)}~(i \in I)\). It is inspired by the ``police lineup'' or ``identity parade'' which is the act of asking the eyewitness to identify criminal suspect from a group of irrelevant people. The protocol consists of \(m\) randomly placed data plots, where \(1\) plot is the actual data plot, and \(m-1\) null plots are produced by plotting data simulate from the null distribution which is consistent with the null hypothesis. Then, an observer who have not seen the actual data plot will be asked to point out the most different plot from the lineup.

Under the null hypothesis, it is expected that the actual data plot would have no distinguishable difference with the null plots, and the probability of the observer correctly picks the actual data plot is \(1/m\) due to randomness. If we reject the null hypothesis as the observer correctly picks the actual data plot, then the Type I error of this test is \(1/m\).

This provides us with an mechanism to control the Type I error, because \(m\) - the number of plots in a lineup can be chosen. Further, if we involve \(K\) independent observers in a visual test, and let \(X\) be a random variable denoting the number of observers correctly picking the actual data plot. Then, under the null hypothesis \(X \sim \mathrm{Binom}_{K,1/m}\), and therefore, the \(p\)-value of a lineup of size \(m\) evaluated by \(K\) observer is given as

\[P(X \geq x) = \sum_{i=x}^{K}{{K}\choose{i}}\left(\frac{1}{m}\right)^i\left(\frac{m-1}{m}\right)^{k-i},\]
where \(x\) is the realization of number of observers correctly picking the actual data plot \autocite{majumder_validation_2013}.

\hypertarget{visual-inference-applied-to-linear-regression}{%
\subsection{Visual Inference Applied to Linear Regression}\label{visual-inference-applied-to-linear-regression}}

How people used visual inference in linear regression?

\hypertarget{limitation-of-the-visual-inference}{%
\subsection{Limitation of the Visual Inference}\label{limitation-of-the-visual-inference}}

What are the limitations?

\hypertarget{computer-vision-model}{%
\subsection{Computer Vision Model}\label{computer-vision-model}}

What is computer vision model?

\hypertarget{contribution}{%
\subsection{Contribution}\label{contribution}}

What has been done by this paper?

\hypertarget{structure-of-this-paper}{%
\subsection{Structure of This Paper}\label{structure-of-this-paper}}

What is the structure of the paper?

Model diagnostics is the part of data analysis whose primary objectives are to examine the goodness of the model fit and reveal potential violations of the assumptions. Graphical approaches

For regression diagnostics, it may includes the needs of

Linear regression is an modelling approach to describe the relationship between an response variable and one or more explanatory variable. It has been widely used for both generative modeling and predictive modelling.

Regression diagnostics is needed

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  to check whether the assumptions has been violated
\item
  to check whether the line fit the data
\end{enumerate}

Model diagnostics for linear regression is well developed

\appendix

\hypertarget{additional-stuff}{%
\chapter{Additional stuff}\label{additional-stuff}}

You might put some computer output here, or maybe additional tables.

Note that line 5 must appear before your first appendix. But other appendices can just start like any other chapter.

\printbibliography[heading=bibintoc]



\end{document}
