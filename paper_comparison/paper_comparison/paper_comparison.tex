% interactcadsample.tex
% v1.03 - April 2017

\documentclass[]{interact}

\usepackage{epstopdf}% To incorporate .eps illustrations using PDFLaTeX, etc.
\usepackage{subfigure}% Support for small, `sub' figures and tables
%\usepackage[nolists,tablesfirst]{endfloat}% To `separate' figures and tables from text if required

\usepackage{natbib}% Citation support using natbib.sty
\bibpunct[, ]{(}{)}{;}{a}{}{,}% Citation support using natbib.sty
\renewcommand\bibfont{\fontsize{10}{12}\selectfont}% Bibliography support using natbib.sty

\theoremstyle{plain}% Theorem-like structures provided by amsthm.sty
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheorem{notation}{Notation}

% see https://stackoverflow.com/a/47122900

% Pandoc citation processing

\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\def\tightlist{}
\newcommand*{\Perm}[2]{{}^{#1}\!P_{#2}}%
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}

\begin{document}

\articletype{ARTICLE TEMPLATE}

\title{Why aren't significance tests commonly used for linear regression
diagnostics?}


\author{\name{Weihao Li$^{a}$, Dianne Cook$^{a}$, Emi Tanaka$^{a}$}
\affil{$^{a}$Department of Econometrics and Business Statistics, Monash
University, Clayton, VIC, Australia}
}

\thanks{CONTACT Weihao
Li. Email: \href{mailto:weihao.li@monash.edu}{\nolinkurl{weihao.li@monash.edu}}, Dianne
Cook. Email: \href{mailto:dicook@monash.edu}{\nolinkurl{dicook@monash.edu}}, Emi
Tanaka. Email: \href{mailto:emi.tanaka@monash.edu}{\nolinkurl{emi.tanaka@monash.edu}}}

\maketitle

\begin{abstract}
Abstract to fill.
\end{abstract}

\begin{keywords}
data visualization; visual inference; hypothesis testing; residual
plots;
\end{keywords}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\begin{quote}
\emph{``Since all models are wrong the scientist must be alert to what
is importantly wrong.''} \citep{box1976science}
\end{quote}

Diagnosing a model is the key to determining whether there is anything
importantly wrong. For linear regression analysis, it is typical to
interrogate the residuals. Residuals summarise what is not captured by
the model, and thus provide the capacity to identify what might be
wrong. There are many ways that residuals could be assessed.

Residuals might be plotted, as a histogram or quantile-quantile plot to
examine the distribution. Using the classical linear regression model as
an example, if the distribution is symmetric and unimodal, it is
well-behaved. But if the distribution is skewed, bimodal, multimodal, or
contains outliers, there is cause for concern. The distribution could
also be inspected by conducting a goodness of fit test, such as the
Shapiro-Wilk Normality test \citep{shapiro1965analysis}.

Plotting the residuals against predicted values and each of the
explanatory variables on a scatter plot is a recommend way to scrutinize
their relationships. If there is any visually discoverable patterns, the
model is potentially misspecified. However, it is a very difficult task
for a human judge, though to make a decision that there's nothing there.
It is especially common, particularly among new data analysts to report
patterns when an experienced data analyst might quickly conclude that
there are none. Generally, one looks for departures from nothingness
like non-linear dependency or heteroskedasticity. It is also possible to
conduct hypothesis tests for non-linear dependence
\citep{ramsey_tests_1969}, and use a Breusch-Pagan test
\citep{breusch_simple_1979} for heteroskedasticity.

There is an abundance of literature describing appropriate diagnostic
methods for linear regression: \citet{draper1998applied},
\citet{montgomery1982introduction}, \citet{belsley_regression_1980},
\citet{cook_applied_1999} and \citet{cook1982residuals}. The diligent
reader of these sage writings will also notice sentences that express
sentiments like \emph{based on their experience, statistical tests are
not widely used in regression diagnostics. The same or even larger
amount of information can be provided by diagnostic plots than the
corresponding tests in most empirical studies.} There is a common
guidance by experts that plots are the best for diagnosing model fits.

This is curious, and investigating why this might be common advice is
the subject of this paper. The paper is structured as follows. The next
background section describes the the types of departures that one
expects to detect, and describes a formal process for reading residual
plots, called visual inference, that can avoid the concerns about
subjectiveness of human readers. Section \ref{experimental-design}
describes the experimental setup to enable a comparison between decision
made by formal hypothesis testing, and how humans would read diagnostic
plots. The results are reported in Section \ref{results}. We finish with
a discussion on future work, in particular how the responsibility for
residual plot reading might be passed on to computer vision.

\hypertarget{background}{%
\section{Background}\label{background}}

\hypertarget{departures-from-good-residual-plots}{%
\subsection{Departures from good residual
plots}\label{departures-from-good-residual-plots}}

\includegraphics{paper_comparison_files/figure-latex/unnamed-chunk-6-1.pdf}

Graphical summaries in which residuals are plotted against fitted values
or other functions of the predictor variables that are approximately
orthogonal to residuals are referred to as standard residual plots in
\citet{cook1982residuals}. As shown in Figure {[}ref here{]}, the
top-left panel is a good residual plot with residuals evenly distributed
at both sides of the horizontal zero line showing no noticeable
patterns. There are various types of departures from a good residual
plot. We will only discuss three most commonly checked departures in
this paper. Namely, non-linearity, heterskedasticity and non-normality.

Non-linearity is a type of model misspecification caused by failing to
include higher order terms of the regressors in the regression equation.
Any non-linear functional form of residuals on fitted values presented
in the residual plot could be considered as an indicative of
non-linearity. At the top-right of Figure {[}ref here{]}, there is a
residual plot giving an example of the visual pattern of non-linearity
when a cubic term is not captured by the regression model.

Heterskedasticity refers to the existence of nonconst error variance in
a regression model. It is mostly due to the strict but false assumptions
on the variance-covariance matrix of the error term. The usual pattern
of heterskedasticity on a residual plot is the inconsistent spread of
the residuals at different x values. Visually, it sometimes results in
the so-called ``butterfly'' shape as shown in the bottom-left panel of
Figure {[}ref here{]}, or the ``left-triangle'' and ``right-triganle''
shape where the smallest variance occurs at the edges of the x-axis.

Non-normality is usually harder to be detected from a residual plot
compared to non-linearity and heterskedasticity. Besides, a
quantile-quantile plot can often do a better job for this task. Note
that not all regression models assume normality of the error term, but a
certain amount of them does. If this assumption happens to be false,
then it is expected to see data points do not distribute noramlly on the
y-axis. For example, given a skewed error distribution, one will see
fewer data points and more outliers on one side of the zeroline as shown
in the bottom-right of Figure {[}ref here{]}.

\hypertarget{conventionally-testing-for-departures}{%
\subsection{Conventionally testing for
departures}\label{conventionally-testing-for-departures}}

Explain the tests you are showing later

\begin{itemize}
\tightlist
\item
  RESET
\item
  BP
\item
  SW
\end{itemize}

and show the results for the residual plots displayed in previous
section

Briefly mention any others

\hypertarget{visual-testing-for-departures}{%
\subsection{Visual testing for
departures}\label{visual-testing-for-departures}}

\begin{itemize}
\tightlist
\item
  Very briefly explain what a lineup test is
\item
  Lineup (maybe using your previous residual plot for nonlinearity)
\item
  \(p\)-value calulcation, briefly, including how multiple selections
  are handled
\item
  power calculation, briefly, including how multiple selections are
  handled
\end{itemize}

However, unlike hypothesis testing built upon rigorous statistical
procedures, reading diagnostic plots relies on graphical perception -
human's ability to interpret and decode the information embedded in the
graph \citep{cleveland_graphical_1984}, which is to some extent
subjective and indecisive. Further, visual discovery suffers from its
unsecured and unconfirmed nature where the degree of the presence of the
visual features typically can not be measured quantitatively and
objectively, which may lead to over or under-interpretations of the
data. One such example is finding an over-interpretation of the
separation between gene groups in a two-dimensional projection from a
linear discriminant analysis when in fact there are no differences in
the expression levels between the gene groups and separation is not an
uncommon occurrence \citep{roy_chowdhury_using_2015}.

Visual inference was first introduced in a 1999 Joint Statistical
Meetings (JSM) talk with the title ``Inference for Data Visualization''
by \citet{buja_inference_1999} as an idea to address the issue of valid
inference for visual discoveries of data plots
\citep{gelman_exploratory_2004}. Later, in the Bayesian context, data
plots was systematically considered as model diagnostics by taking
advantage of the data simulated from the assumed statistical models
\citep{gelman_bayesian_2003, gelman_exploratory_2004}.

It was surprising that the essential components of visual inference had
actually been established in \citet{buja_inference_1999}, but it was not
until 10 years later that \citet{buja_statistical_2009} formalized it as
an inferential framework to extend confirmatory statistics to visual
discoveries. This framework redefines the test statistics, tests, null
distribution, significance levels and \(p\)-value for visual discovery
modelled on the confirmatory statistical testing. Figure
\ref{fig:parallelism} outlines the parallelism between conventional
tests and visual discovery.

In visual inference, a collection of test statistics
\(T^{(i)}(\boldsymbol{\mathrm{y}})~(i \in I)\) is defined, where
\(\boldsymbol{\mathrm{y}}\) is the data and \(I\) is a set of all
possible visual features. \citet{buja_statistical_2009} described each
of the test statistics \(T^{(i)}(\boldsymbol{\mathrm{y}})\) as a
measurement of the degree of presence of a visual feature.
Alternatively, \citet{majumder_validation_2013} avoids the use of visual
features and defined the visual statistics \(T(.)\) as a mapping from a
dataset to a data plot. Both definitions of visual test statistics are
valid, but in the rest of the paper the first definition will be used as
it covers some details needed by the following discussion. A visual
discovery is defined as a rejection of a null hypothesis, and the same
null hypothesis can be rejected by many different visual discoveries
\citep{buja_statistical_2009}. For regression diagnostics, the null
hypothesis would be the assumed model, while the visual discoveries
would be any findings that are inconsistent with the null hypothesis.
The same regression model can be rejected by many reasons with residual
plot, including non-linearity and heteroskedasticity as shown in Figure
\ref{fig:residual-plot-cubic-heter}.

\begin{figure}
\centering
\includegraphics{paper_comparison_files/figure-latex/residual-plot-cubic-heter-1.pdf}
\caption{Residuals vs.~fitted values plot for a classical linear
regression model. The residuals are produced by fitting a two-predictor
multiple linear regression model with data generated from a cubic linear
model. From the residual plot, ``butterfly shape'' can be observed which
generally would be interpretd as evidence of heteroskedasticity.
Further, from the outline of the shape, nonlinear patterns exist. Both
visual discoveries are evidence against the null hypothesis, though
heteroskedasticity actually does not exist in the data generating
process. \label{fig:residual-plot-cubic-heter}}
\end{figure}

\hypertarget{se:sampling-from-null}{%
\subsubsection{Sampling from the null
distribution}\label{se:sampling-from-null}}

The null distribution of plots refers to the infinite collection of
plots of null datasets sampled from \(H_0\). It is defined as the
analogue of the null distribution of test statistics in conventional
test \citep{buja_statistical_2009}. In practice, a finite number of
plots of null datasets could be generated, called null plots. In the
context of regression diagnostics, sampling data from \(H_0\) is
equivalent to sampling data from the assumed model. As
\citet{buja_statistical_2009} suggested, \(H_0\) is usually composited
by a collection of distributions controlled by nuisance parameters.
Since regression models can have various forms, there is no general
solution to this problem, but it sometimes can be reduced to so called
``reference distribution'' by applying one of the three methods: (i)
sampling from a conditional distribution given a minimal sufficient
statistic under \(H_0\), (ii) parametric bootstrap sampling with
nuisance parameters estimated under \(H_0\), and (iii) Bayesian
posterior predictive sampling.

The conditional distribution given a minimal sufficient statistic is the
best justified reference distribution among the three
\citep{buja_statistical_2009}. Suppose there exists a minimal sufficient
statistic \(\boldsymbol{S}(\boldsymbol{y})\) under the null hypothesis,
any null datasets \(\boldsymbol{y^{*}}\) should fulfil the condition
\(\boldsymbol{S}(\boldsymbol{y}) = \boldsymbol{s}\). Using the classical
normal linear regression model as example, the minimal sufficient
statistic is
\(\boldsymbol{S}(\boldsymbol{y}) = (\hat{\boldsymbol{\beta}}, \boldsymbol{e}'\boldsymbol{e})\),
where \(\hat{\boldsymbol{\beta}}\) are the coefficient estimators and
\(\boldsymbol{e}'\boldsymbol{e}\) is the residual sum of square.
Alternatively, the minimal sufficient statistic can be constructed as
\(\boldsymbol{S}(\boldsymbol{y}) = (\hat{\boldsymbol{y}}, ||\boldsymbol{e}||)\),
where \(\hat{\boldsymbol{y}}\) are the fitted values and
\(||\boldsymbol{e}||\) is the length of residuals, which is more
intuitive as suggested by \citet{buja_statistical_2009}. Since the
fitted values are held fixed, the variation can only occur in the
residual space. And because the length of residual is also held fixed,
residuals obtained from a null dataset has to be a random rotation of
\(\boldsymbol{e}\) in the residual space. With this property, null
residuals can be simulated by regressing \(N\) i.i.d standard normal
random draws on the regressors, then rescaling it by the ratio of
residual sum of square in two regressions.

\hypertarget{se:lineup}{%
\subsubsection{Lineup protocol}\label{se:lineup}}

With the simulation mechanism of null plots being provided, another
aspect of hypothesis testing that needs to be addressed is the control
of false positive rate or Type I error. Any visual statistic
\(T^{(i)}(\boldsymbol{\mathrm{y}})\) needs to pair with a critical value
\(c^{(i)}\) to form a hypothesis test. When a visual feature \(i\) is
discovered by the observer from a plot, the corresponding visual
statistic \(T^{(i)}(\boldsymbol{\mathrm{y}})\) may not be known as there
is no general agreement on the measurement of the degree of presence of
a visual feature. It is only the event that
\(T^{(i)}(\boldsymbol{\mathrm{y}}) > c^{(i)}\) is confirmed. Similarly,
if any visual discovery is found by the observer, we say, there exists
\(i \in I:~T^{(i)}(\boldsymbol{\mathrm{y}}) > c^{(i)}\)
\citep{buja_statistical_2009}.

Using the above definition, the family-wise Type I error can be
controlled if one can provide the collection of critical values
\(c^{(i)}~(i \in I)\) such that
\(P(\mathrm{there~exists~} i \in I: T^{(i)}(\boldsymbol{\mathrm{y}}) > c^{(i)}|\boldsymbol{\mathrm{y}}) \leq \alpha\),
where \(\alpha\) is the significance level. However, since the quantity
of \(T^{(i)}(\boldsymbol{\mathrm{y}})\) may not be known, such
collection of critical values can not be provided.

\citet{buja_statistical_2009} proposed the lineup protocol as a visual
test to calibrate the Type I error issue without the specification of
\(c^{(i)}~(i \in I)\). It is inspired by the ``police lineup'' or
``identity parade'' which is the act of asking the eyewitness to
identify criminal suspect from a group of irrelevant people. The
protocol consists of \(m\) randomly placed plots, where one plot is the
actual data plot, and the remaining \(m - 1\) plots have the identical
graphical production as the data plot except the data has been replaced
with data consistent with the null hypothesis. Then, an observer who
have not seen the actual data plot will be asked to point out the most
different plot from the lineup.

Under the null hypothesis, it is expected that the actual data plot
would have no distinguishable difference with the null plots, and the
probability of the observer correctly picks the actual data plot is
\(1/m\). If we reject the null hypothesis as the observer correctly
picks the actual data plot, then the Type I error of this test is
\(1/m\).

This provides us with an mechanism to control the Type I error, because
\(m\) - the number of plots in a lineup can be chosen. A larger value of
\(m\) will result in a smaller Type I error, but the limit to the value
of \(m\) depends on the number of plots a human is willing to view
\citep{buja_statistical_2009}. Typically, \(m\) will be set to \(20\)
which is equivalent to set \(\alpha = 0.05\), a general choice of
significance level for conventional testing among statisticians.

Further, a visual test can involve \(K\) independent observers. Let
\(D_i = \{0,1\}\) be a binomial random variable denoting whether subject
\(i\) correctly detecting the actual data plot, and
\(X = \sum_{i=1}^{K}X_i\) be the number of observers correctly picking
the actual data plot. Then, by imposing a relatively strong assumption
on the visual test that all \(K\) evaluations are fully independent,
under the null hypothesis, \(X \sim \mathrm{Binom}_{K,1/m}\). Therefore,
the \(p\)-value of a lineup of size \(m\) evaluated by \(K\) observer is
given as \begin{equation} \label{eq:pvaluesingle}
P(X \geq x) = \sum_{i=x}^{K}{{K}\choose{i}}\left(\frac{1}{m}\right)^i\left(\frac{m-1}{m}\right)^{k-i},
\end{equation}

where \(x\) is the realization of number of observers correctly picking
the actual data plot \citep{majumder_validation_2013}.

The multiple individuals approach avoids the limit of \(m\), while
provides visual tests with \(p\)-value much smaller than \(0.05\). In
fact, the lower bound of \(p\)-value decreases exponentially as \(K\)
increases. With just \(4\) individuals and \(20\) data plots in a
lineup, the \(p\)-value could be as small as \(0.0001\). Additionally,
by involving multiple observers, variation of individual ability to read
plots can be addressed to some degree as different opinions about visual
discoveries can be collected.

As pointed out by \citet{vanderplas2021statistical}, though Equation
(\ref{eq:pvaluesingle}) is trivial, but it doesn't take into account the
possible dependencies in the visual test due to repeated evaluations of
the same lineup. And it is inapplicable to visual test where subjects
are asked to select one or more ``most different'' plots from the
lineup. They summarized three common different scenarios in visual
inference: (1) \(K\) different lineups are shown to \(K\) subjects, (2)
\(K\) lineups with different null plots but the same actual data plot
are shown to \(K\) subjects, and (3) the same lineup is shown to \(K\)
subjects. Out of these three scenarios, Scenario 3 is the most common in
previous studies as it puts the least constraints on the experimental
design. For Scenario 3, \citet{vanderplas2021statistical} modelled the
probability of a plot \(i\) being selected from a lineup as
\(\theta_i\), where \(\theta_i \sim Dirichlet(\alpha)\) for
\(i=1,...,m\) and \(\alpha > 0\). And defined \(c_i\) to be the number
of times plot \(i\) being selected in \(K\) evaluations. In case subject
\(j\) makes multiple selections, they decided to add \(1/s_j\) to
\(c_i\) instead of one, where \(s_j\) is the number of plots subject
\(j\) selected for \(j=1,...K\). This ensured \(\sum_{i}c_i=K\).

The full model was a Dirichlet-multinomial mixture distribution

\begin{align} \label{eq:dirichlet-multinomial}\begin{split}
\boldsymbol{\theta}&|\alpha \sim Dirichlet(\alpha)\\
(c_i,...,c_m)&|\boldsymbol{\theta} \sim Multinomial(K, \boldsymbol{\theta}).
\end{split}\end{align}

Since the p-value calculation only needs to concern the number of times
the actual data plot being selected denoted by \(C_i\), they showed the
model can be simplified to a beta-binomial mixture distribution

\begin{align} \label{eq:beta-binomial}\begin{split}
\theta_i&|\alpha \sim Beta(\alpha, (m-1)\alpha)\\
C_i&|\theta_i \sim Binomial(K, \theta_i).
\end{split}\end{align}

Thus, the visual p-value followed by the beta-binomial model is given as

\begin{equation} \label{eq:pvalue-beta-binomial}
P(C \geq c_i) = \sum_{x=c_i}^{K}{{K}\choose{x}}\frac{1}{B(\alpha, (m-1)\alpha)}B(x + \alpha, K - x + (m - 1)\alpha),
\end{equation}

where \(B(.)\) is the beta function defined as

\begin{equation} \label{eq:betafunction}
B(a, b) = \int_{0}^{1}t^{\alpha - 1}(1-t)^{b-1}dt,\quad \text{where}\quad a,b>0. 
\end{equation}

Note that the use of Equation (\ref{eq:pvalue-beta-binomial}) requires
the estimation of \(\hat{\alpha}\), which largely depends on the null
model, the type of the plot and other aesthetic features. They suggested
to estimate \(\hat{\alpha}\) visually based on the selections of null
plots of the experimental data, or to estimate \(\hat{\alpha}\)
numerically based on several additional Rorschach lineups, which is a
type of lineup containing only null plots. However, when the number of
null models are large, it could be expensive to manually estimate each
\(\alpha\) or include additional Rorschach lineups in the experiment.

Instead, in the experiments that will be described in section
\ref{experimental-design}, we adopt a simpler model implicitly used by
the \texttt{pmulti()} function of the \texttt{vinference} \texttt{R}
package. We assume the attractiveness of the plot \(i\) modelled as
\(w_i \sim Uniform(0,1)\) for \(i=1,..,m\). Let
\(\theta_i = w_i/\sum_{i=1}^{m}w_i\) be the probability of plot \(i\)
being selected by a subject. Then, given the number of selections
\(s_j\), for \(j=1,...,K\), the distribution of \(C_i\) can be
approximated by simulating the random selection process with computer.
The simulated visual test p-value is formulated as

\begin{equation} \label{eq:p-value-multi}
\text{p-value} = \frac{\#draws~that~the~actual~data~plota~being~selected~more~than~c_i~times}{\#simulation}.
\end{equation}

\hypertarget{effectiveness-of-visual-test-in-regression-diagnostics}{%
\subsection{Effectiveness of visual test in regression
diagnostics}\label{effectiveness-of-visual-test-in-regression-diagnostics}}

The effectiveness of visual inference has already been validated by
\citet{majumder_validation_2013} under relatively simple classical
normal linear regression model settings with only one or two regressors.
Their results suggest visual test is capable of testing the significance
of a single regressor with a similar power as a t-test, though they
expressed that in general it is unnecessary to use visual inference if
there exists a conventional test and they didn't expect the visual test
to perform equally well as the conventional test. In their third
experiment, where there does not exist a proper conventional test,
visual test outperforms the conventional test for a large margin. This
is encouraging as it promotes the use of visual inference in border
field of data science where there are no existing statistical testing
procedures. In fact, lineup protocol has been integrated into some model
diagnostic tools such as \citet{loy2013diagnostic}.

With our knowledge, what haven't been examined so far is the
effectiveness of visual test relative to the equivalent conventional
test in regression diagnostics. Particularly, its ability to detect
non-linearity and heteroskedasticity compared to F-test and BP-test.

\hypertarget{experimental-design}{%
\section{Experimental design}\label{experimental-design}}

\hypertarget{motivation-and-overview}{%
\subsection{Motivation and overview}\label{motivation-and-overview}}

\hypertarget{simulating-departures}{%
\subsection{Simulating departures}\label{simulating-departures}}

\hypertarget{nonlinearity}{%
\subsubsection{Nonlinearity}\label{nonlinearity}}

\hypertarget{heteroskedasticity}{%
\subsubsection{Heteroskedasticity}\label{heteroskedasticity}}

\hypertarget{experimental-setup}{%
\subsection{Experimental setup}\label{experimental-setup}}

\hypertarget{factors}{%
\subsubsection{Factors}\label{factors}}

\begin{itemize}
\tightlist
\item
  Treatments for nonlinearity experiment (plots summarising levels)
\item
  Treatments for heteroskedasticity experiment (plots summarising
  levels)
\end{itemize}

\hypertarget{assigning-subjects}{%
\subsubsection{Assigning subjects}\label{assigning-subjects}}

\hypertarget{collecting-results}{%
\subsubsection{Collecting results}\label{collecting-results}}

software/technical

\hypertarget{computing-power-curves}{%
\subsection{Computing power curves}\label{computing-power-curves}}

For the purpose of examining the effectiveness of visual test in
regression diagnostics, two experiments were conducted. The experiment I
has ideal scenario for conventional testing, where the visual test is
not expected to outperform the conventional test. The experiment II is a
scenario where the conventional test is an approximate test, in which
the visual test may have a chance to match the performance of the
conventional test.

Subjects for both experiments were recruited from an crowdsourcing
platform called Prolific {[}ref here{]}. Prescreening procedure was
applied during the recruitment, subjects were required to be fluent in
English, with \(98\%\) minimum approval rate in other studies and 10
minimum submissions.

During the experiment, every subject was presented with a block of 20
lineups. And for every lineup, the subject was asked to select one or
more plots that are most different from others, provide a reason for
their selections, and evaluate how different they think the selected
plots were from others. If there was no noticeable difference between
plots in a lineup, subjects were permitted to select zero plots without
providing the reason. No subject was shown the same lineup twice.
Information about preferred pronoun, age group, education, and previous
experience in visual experiment were also collected.

A pool of 12 different lineups with obvious visual patterns were
generated for experiment I and experiment II respectively. In every
block of 20 lineups that presented to a subject, two out of 12 lineups
were included as attention checks. A subject's submission was only
accepted if the actual data plot was identified for at least one
attention check. Data of rejected submissions were discarded
automatically to maintain the overall data quality.

\hypertarget{non-linearity}{%
\subsection{Non-linearity}\label{non-linearity}}

Experiment I is designed to study the ability of human subjects to
detect the effect of a random vector \(\boldsymbol{z}\) which is a
probabilist's Hermite polynomial {[}Herimite ref here{]} of another
random vector \(\boldsymbol{x}\) in a two variable statistical model
formulated as:

\begin{align} \label{eq:nonlinearity-model}
\boldsymbol{y} = 1 + \boldsymbol{x} + \boldsymbol{z} + \boldsymbol{\varepsilon},\\
\boldsymbol{x} = g(\boldsymbol{x}_{raw}, 1), \\
\boldsymbol{z} = g(\boldsymbol{z}_{raw}, 1), \\
\boldsymbol{z}_{raw} = He_j(g(\boldsymbol{z}, 2)),
\end{align}

where \(\boldsymbol{y}\), \(\boldsymbol{x}\),
\(\boldsymbol{\varepsilon}\), \(\boldsymbol{x}_{raw}\),
\(\boldsymbol{z}_{raw}\) are vector of size \(n\), \(He_{j}(.)\) is the
\(j\)th-order probabilist's Hermite polynomials,
\(\varepsilon \sim N(\boldsymbol{0}, \sigma^2\boldsymbol{I}_n)\), and
\(g(\boldsymbol{x}, k)\) is a scaling function to enforce the support of
the random vector to be \(\{-k, k\}\) defined as

\begin{equation} \label{eq:scaling-function}
g(\boldsymbol{x}, k) = (\boldsymbol{x} - min(\boldsymbol{x}))/max(\boldsymbol{x} - min(\boldsymbol{x})) \times 2k - k, \quad \text{for} \quad k > 0. 
\end{equation}

The null regression model used to fit the realizations generated by the
above model is formulated as:

\begin{equation} \label{eq:scaling-function}
\boldsymbol{y} = \beta_0 + \beta_1 \boldsymbol{x} + \boldsymbol{u},
\end{equation}

where
\(\boldsymbol{u} \sim N(\boldsymbol{0}, \sigma^2\boldsymbol{I}_n)\).

Model misspecification presents since the null model leaves out the
higher order term.

Experiment data were simulated using four different order of
probabilist's Hermite polynomials (\(j = 2, 3, 6, 18\)), three different
sample sizes (n = 50, 100, 300) , four different standard deviations of
the error (\(\sigma\) = 0.5, 1, 2, 4) and four different distribution of
\(X_{raw}\): (1) \(U(-1, 1)\), (2) \(N(0, 0.3^2)\), (3)
\(lognormal(0, 0.6^2)/3\) and (4) \(u\{1, 5\}\). A summary of the
parameters used in this experiment is given in Table
\ref{tab:parameter-table}.

The values of \(j\) was chosen so that different shapes of non-linearity
were included in the residual plot. These include ``U'' shape, ``S''
shape, ``M'' shape and ``Triple-U'' shape.

\includegraphics{paper_comparison_files/figure-latex/different-shape-of-herimite-1.pdf}

The range of \(\sigma\), which is a factor controlling the strength of
the signal, was chosen so that different difficulty levels of lineups
were generated, and therefore, the estimated power curve would be smooth
and continuous.

\includegraphics{paper_comparison_files/figure-latex/different-sigma-1.pdf}

Four different distribution were used to generate \(X_{raw}\). The
uniform and the normal distribution are symmetric and commonly assumed
in statistical models. The adjusted log-normal distribution provides
skewed density. And the discrete uniform distribution provides
discreteness in residual plot, which could enrich the pool of visual
patterns.

\includegraphics{paper_comparison_files/figure-latex/different-dist-1.pdf}

Three replications are made for each of the parameter values shown in
Table \ref{tab:parameter-table} resulting in 192 different lineups. For
each lineup, the actual data plot was drawn as a standard residual plot
of the null model with raw residuals on the y-axis and fitted values on
the x-axis. The 19 null datasets were generated by the residual rotation
technique, and plotted in the same way. The lineup consisted of 20
residual plots with one randomly placed actual data plot. Figure
\ref{fig:example-lineup} is an example of one of these lineups. It was
produced by using \(n = 300\), \(j = 6\), \(\sigma = 0.5\) and
\(X_{raw} \sim N(0.0.3^2)\). The actual data plot location was four. All
five subjects correctly identified the actual data plot for this lineup.

\begin{table}

\caption{\label{tab:parameter-table}Parameter values for $n$, $j$ $\sigma$, $X_{raw}$}
\centering
\begin{tabular}[t]{lrrl}
\toprule
\multicolumn{1}{c}{\makecell[c]{Sample size\\($n$)}} & \multicolumn{1}{c}{\makecell[c]{Order of Hermite polynomial\\($j$)}} & \multicolumn{1}{c}{\makecell[c]{Error SD\\($\sigma$)}} & \multicolumn{1}{c}{\makecell[c]{Distribution of $X_{raw}$\\}} \\
\cmidrule(l{3pt}r{3pt}){1-1} \cmidrule(l{3pt}r{3pt}){2-2} \cmidrule(l{3pt}r{3pt}){3-3} \cmidrule(l{3pt}r{3pt}){4-4}
50 & 2 & 0.5 & $U(-1, 1)$\\
100 & 3 & 1.0 & $N(0, 0.3^2)$\\
300 & 6 & 2.0 & $lognormal(0, 0.6^2)/3$\\
 & 18 & 4.0 & $U\{1, 5\}$\\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}
\centering
\includegraphics{paper_comparison_files/figure-latex/example-lineup-1.pdf}
\caption{Example lineup \label{fig:example-lineup}}
\end{figure}

In addition, each lineup is designed to be evaluated by five different
subjects to provide reasonable estimates of the visual p-value. Thus,
\(192 \times 3 \times 5 / (20 - 2) = 160\) subjects were recruited to
satisfy the design of the experiment I.

\hypertarget{heteroskedasticity-1}{%
\subsection{Heteroskedasticity}\label{heteroskedasticity-1}}

Experiment II is designed to study the ability of human subjects to
detect the appearance of a heteroskedasticity pattern under a simple
linear regression model setting:

\begin{align} \label{eq:heter-model}
\boldsymbol{y} = 1 + \boldsymbol{x} + \boldsymbol{\varepsilon},\\
\boldsymbol{\varepsilon} \sim N(\boldsymbol{0}, 1 + 2 - |a| b (\boldsymbol{x} - a)^2 \boldsymbol{I}), \\
\end{align}

where \(\boldsymbol{y}\), \(\boldsymbol{x}\),
\(\boldsymbol{\varepsilon}\) are vector of size \(n\).

The null regression model used to fit the realizations generated by the
above model is formulated exactly the same as the model used in the
first experiment:

\begin{equation} 
\boldsymbol{y} = \beta_0 + \beta_1 \boldsymbol{x} + \boldsymbol{u},
\end{equation}

where
\(\boldsymbol{u} \sim N(\boldsymbol{0}, \sigma^2\boldsymbol{I}_n)\).

Model misspecification presents since the assumption about the constant
error variance is violated.

Experiment data were simulated using three different shapes (\(a\) = -1,
0, 1), five different values of \(b\) (b = 0.25, 1, 4, 16, 64), three
different sample sizes (n = 50, 100, 300) and four different
distribution of \(X_{raw}\): (1) \(U(-1, 1)\), (2) \(N(0, 0.3^2)\), (3)
\(lognormal(0, 0.6^2)/3\) and (4) \(u\{1, 5\}\). A summary of the
parameters used in this experiment is given in Table
\ref{tab:parameter-table}.

The values of \(a\) was chosen so that different shapes of
heteroskedasticity were included in the residual plot. These include
triangle shape, butterfly shape and inverse triangle shape.

\includegraphics{paper_comparison_files/figure-latex/different-shape-of-heter-1.pdf}

The range of \(b\), which is a factor controlling the strength of the
signal, was chosen so that different difficulty levels of lineups were
generated, and therefore, the estimated power curve would be smooth and
continuous.

\hypertarget{analysis-and-results}{%
\section{Analysis and results}\label{analysis-and-results}}

\hypertarget{data-overview}{%
\subsection{Data overview}\label{data-overview}}

How many people? How many lineups?

Subjects recruited from Prolific received a fixed payment for
participating in the experiment. However, some subjects will try to
maximize their earnings for minimum effort. During the review of
submissions, if we found a subject objectively demonstrated clear
low-effort throughout the experiment, i.e., failed all attention checks,
we rejected the submission. The rejected submissions will be removed
immediately, and Prolific will automatically recruit another subject as
substitution. Therefore, we only paid for approved submissions and no
further data screening procedure needed to be applied on the collected
data.

A subject was allowed to select zero plots for a lineup if there was no
visible difference between plots, but the simulated visual p-value given
in Equation (\ref{eq:p-value-multi}) will effectively drop the subject
from the simulation for this case, leading to inaccurate estimation of
\(p\)-value. Therefore, we treated this case as making one selection but
failing to identify the actual data plot so that Equation
(\ref{eq:p-value-multi}) can be applied correctly.

In overall, there were a total of 3200 lineup evaluations made by 160
subjects in both experiment I and experiment II respectively, where 320
lineup evaluations were attention checks and were not used in the
following analysis.

The collated dataset is provided in \texttt{polynomials} and
\texttt{heter} of the \texttt{visage} \texttt{R} package.

\hypertarget{section}{%
\subsection{}\label{section}}

\hypertarget{nonlinearity-1}{%
\subsection{Nonlinearity}\label{nonlinearity-1}}

\begin{itemize}
\tightlist
\item
  Power curve overall
\item
  Four lineups also shown, selected from ones close to the visual power
  curve from the uniform treatment
\item
  Compare visual power against different factors
\end{itemize}

\hypertarget{heteroskedasticity-2}{%
\subsection{Heteroskedasticity}\label{heteroskedasticity-2}}

\begin{itemize}
\tightlist
\item
  Power curve overall
\item
  Four lineups also shown, selected from ones close to the visual power
  curve from the uniform treatment
\item
  Compare visual power against different factors
\end{itemize}

\hypertarget{demographic-summary}{%
\subsection{Demographic summary}\label{demographic-summary}}

Table \ref{tab:demographic-table} tabulates the number of subjects,
preferred pronouns, education backgrounds, age groups, and previous
experience in visual experiment. Figure
\ref{fig:demographic-summary-plot} visualizes the marginal distribution
of each of the category. The collated data was a balanced sample among
male and female. Most of the ages of subject were between 18 to 39,
while many of them were between 18 to 24. Very few subjects were awarded
degree higher than Bachelor Degree. Around 40\% of subjects had previous
experience in visual experiment.

\begin{table}

\caption{\label{tab:demographic-table}Summary of demographic information}
\centering
\begin{tabular}[t]{llllr}
\toprule
Preferred pronoun & Education & Age group & Previous experience & Subject\\
\midrule
She & Diploma and Bachelor Degree & 18-24 & Yes & 26\\
She & Diploma and Bachelor Degree & 18-24 & No & 24\\
He & Diploma and Bachelor Degree & 18-24 & No & 22\\
He & High School or below & 18-24 & No & 22\\
She & Diploma and Bachelor Degree & 25-39 & No & 21\\
He & Diploma and Bachelor Degree & 18-24 & Yes & 19\\
He & Diploma and Bachelor Degree & 25-39 & No & 19\\
She & High School or below & 18-24 & No & 19\\
He & High School or below & 18-24 & Yes & 15\\
She & Diploma and Bachelor Degree & 25-39 & Yes & 15\\
He & Diploma and Bachelor Degree & 25-39 & Yes & 12\\
She & High School or below & 18-24 & Yes & 10\\
He & Masters Degree & 25-39 & No & 8\\
He & Masters Degree & 25-39 & Yes & 8\\
He & High School or below & 25-39 & No & 7\\
She & Masters Degree & 25-39 & Yes & 7\\
She & High School or below & 25-39 & No & 6\\
He & High School or below & 25-39 & Yes & 5\\
She & Honours Degree & 25-39 & No & 5\\
She & Honours Degree & 25-39 & Yes & 4\\
She & Masters Degree & 25-39 & No & 4\\
He & Honours Degree & 25-39 & Yes & 3\\
She & Honours Degree & 18-24 & No & 3\\
He & Diploma and Bachelor Degree & 40-54 & Yes & 2\\
He & Diploma and Bachelor Degree & 55-64 & No & 2\\
He & Honours Degree & 25-39 & No & 2\\
He & Masters Degree & 40-54 & No & 2\\
She & Diploma and Bachelor Degree & 40-54 & No & 2\\
She & High School or below & 25-39 & Yes & 2\\
She & Masters Degree & 18-24 & No & 2\\
They & Diploma and Bachelor Degree & 18-24 & No & 2\\
They & Diploma and Bachelor Degree & 25-39 & No & 2\\
He & Diploma and Bachelor Degree & 40-54 & No & 1\\
He & High School or below & 40-54 & Yes & 1\\
He & High School or below & 55-64 & No & 1\\
He & Honours Degree & 18-24 & No & 1\\
He & Honours Degree & 18-24 & Yes & 1\\
He & Honours Degree & 40-54 & Yes & 1\\
He & Masters Degree & 40-54 & Yes & 1\\
He & Masters Degree & 55-64 & No & 1\\
Other & Diploma and Bachelor Degree & 18-24 & No & 1\\
Other & High School or below & 25-39 & No & 1\\
She & Diploma and Bachelor Degree & 40-54 & Yes & 1\\
She & High School or below & 40-54 & No & 1\\
She & High School or below & 55-64 & Yes & 1\\
She & Honours Degree & 40-54 & Yes & 1\\
She & Masters Degree & 40-54 & No & 1\\
They & High School or below & 18-24 & No & 1\\
They & High School or below & 18-24 & Yes & 1\\
They & High School or below & 25-39 & No & 1\\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}
\centering
\includegraphics{paper_comparison_files/figure-latex/demographic-summary-plot-1.pdf}
\caption{Summary of demographic information.
\label{fig:demographic-summary-plot}}
\end{figure}

\hypertarget{model-fitting}{%
\subsection{Model fitting}\label{model-fitting}}

For each parameter combination, effect \(E\) is derived from the
Kullback-Leibler divergence (see {[}appendix ref here{]}) formulated as:

\begin{equation} \label{eq:effect-size-ex1}
E = \frac{1}{2\sigma^2}\boldsymbol{X}_b'\boldsymbol{R}_a'(diag(\boldsymbol{R}_a))^{-1}\boldsymbol{R}_a\boldsymbol{X}_b,
\end{equation}

where \(diag(.)\) is the diagonal matrix constructed from the diagonal
elements of \(\boldsymbol{R}_a\).

The logistic regression is fit using \(log_e(E)\) as the only fixed
effect covariate for the power of visual test formulated as:

\begin{equation} \label{eq:logistic-regression-1-1}
Pr(\text{reject}~H_0|H_1,E) = \Lambda(\beta_0 + \beta_1 log_e(\boldsymbol{E})),
\end{equation}

where \(\Lambda(.)\) is the standard logistic function given as
\(\Lambda(z) = exp(z)/(1+exp(z))\).

To study various factors contributing to the power of the visual test,
the same logistic regression model is fit on different subsets of the
collated data grouped by levels of factors. This includes
{[}expansion{]}.

Table {[}table ref here{]} shows the parameter estimates of the logistic
regressions. {[}Discussion about the numeric estimates here{]}

\hypertarget{power-comparison}{%
\subsection{Power comparison}\label{power-comparison}}

\hypertarget{experiment-i}{%
\subsubsection{Experiment I}\label{experiment-i}}

Figure \ref{fig:power-overview} shows an overview of estimated power of
visual test against natural logarithm of the effect with comparison to
the power of an exact test - F-test, and the power of two other
residual-based conventional tests commonly used in regression
diagnostics but for testing other departures from the model assumptions.
In overall, the power of all four tests increases as the effect becomes
larger. The power curve of F-test climbs aggressively from 25\% to
around 90\% as \(log_e(E)\) increases from 0 to 2, while others respond
inactively to the change of effect and remain lower than 25\% throughout
the period, showing that as an exact test, the F-test is relatively more
sensitive to the type of model defects that being considered. The power
of visual test arises steadily and nearly linearly to around 90\% as
\(log_e(E)\) increases from 2 to 5, suggesting that the effect starts to
make noticeable impact on the degree of the presence of the designed
visual features. Other two inappropriate conventional tests shows
improvement at the same time but at a lower rate. This coincides the
point made by \citet{cook1982residuals} mentioned in
\ref{hypothesis-testing} that residual-based tests for a specific type
of model defect are sensitive to other types of model defects. At
\(log_e(E) = 6\), the power curve of F-test reaches almost 100\%
followed by the visual test by a small margin. The power of
Breusch--Pagan test and Shapiro--Wilk test reach around 75\% and 63\%
respectively.

What truly impress us is the huge difference between the estimated power
of visual test and the estimated power of F-test. The margin is largest
at around \(log_e(E) = 2\). An example lineup is included in Figure
\ref{fig:power-overview} where none of subjects detect the actual data
plot positioned at panel 14. It demonstrates that at this level of
difficulty, the designed visual feature is rarely visible, making the
actual data plot indistinguishable from residual plots simulated from
the assumed model. From a communication perspective, given the fact that
the visual difference is unperceivable, the argument that non-linearity
present in the fitted model is less convincing to the public even though
it is true. At around \(log_e(E) = 3\), the margin gets smaller as the
chance of identifying the actual data plot becomes larger. At this level
of difficulty, the designed visual features are usually detectable but
it may not stand out from the lineup as other null plots may happen to
include outliers or visual patterns that are are considered to be more
attractive by human, and thus recognized as the most different plot.
Without knowing the designed visual features beforehand, it is actually
hard to identify the actual data plot by pure image comparison. The
corresponding example lineup for \(log_e(E) = 3\) shown in Figure
\ref{fig:power-overview} has the actual data plot positioned at panel
20, where two out of five subjects detect it. It can be observed that a
M-shape is presented in plot 20, but the signal is not strong enough to
attract all five subjects, resulting in a visual p-value sightly above
the desired significance level \(\alpha = 0.05\). At \(log_e(E) = 4\)
and \(log_e(E) = 6\), the designed visual features become much clear and
attractive, leading to a high percentage of rejection of the null
hypothesis. Figure \ref{fig:power-overview} gives example lineups of
such cases.

\begin{figure}
\centering
\includegraphics{paper_comparison_files/figure-latex/power-overview-1.pdf}
\caption{Power overview. \label{fig:power-overview}}
\end{figure}

\hypertarget{distributions-of-regressor}{%
\subsubsection{Distributions of
regressor}\label{distributions-of-regressor}}

The impact of the distribution of \(X_raw\) on the power is shown in
Figure \ref{fig:dist-power}. The power curve of F-test is stable across
different distributions, while the visual test has a steeper power curve
for normal and uniform distribution. BP-test performs worse for discrete
uniform distribution and uniform distribution but has relatively high
power for normal distribution. SW-test outperforms BP-test for discrete
uniform distribution but remains as the worst test for other
distributions. The results indicate those inappropriate residual-based
tests are sensitive to the distribution of the regressor.

\begin{figure}
\centering
\includegraphics{paper_comparison_files/figure-latex/dist-power-1.pdf}
\caption{\label{dist-power}}
\end{figure}

\hypertarget{shpaes-of-non-linearity}{%
\paragraph{Shpaes of non-linearity}\label{shpaes-of-non-linearity}}

Figure \ref{fig:shape-power} illustrates the change of power under
different shape of non-linearity. Similar to the power curves shown in
\ref{fig:dist-power}, F-test is stable under different shapes. The power
curve of visual test also behaves similarly across different shapes.
What vary are the power curve of BP-test and SW-test. For Triple-U
shape, both BP-test and SW-test are insensitive to the change of the
effect. And for W shape, both tests have almost identical power curves.
It can be observed that both tests performs the best for U-shape.

\begin{figure}
\centering
\includegraphics{paper_comparison_files/figure-latex/shape-power-1.pdf}
\caption{\label{shape-power}}
\end{figure}

\hypertarget{reasons-for-making-selections}{%
\paragraph{Reasons for making
selections}\label{reasons-for-making-selections}}

\includegraphics{paper_comparison_files/figure-latex/unnamed-chunk-13-1.pdf}

\hypertarget{experiment-ii}{%
\subsubsection{Experiment II}\label{experiment-ii}}

\includegraphics{paper_comparison_files/figure-latex/unnamed-chunk-16-1.pdf}

\includegraphics{paper_comparison_files/figure-latex/unnamed-chunk-17-1.pdf}

\includegraphics{paper_comparison_files/figure-latex/unnamed-chunk-18-1.pdf}

\includegraphics{paper_comparison_files/figure-latex/unnamed-chunk-19-1.pdf}

\includegraphics{paper_comparison_files/figure-latex/unnamed-chunk-20-1.pdf}

--\textgreater{}

\bibliographystyle{tfcad}
\bibliography{paper.bib}




\end{document}
