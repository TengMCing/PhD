% interactcadsample.tex
% v1.03 - April 2017

\documentclass[]{interact}

\usepackage{epstopdf}% To incorporate .eps illustrations using PDFLaTeX, etc.
\usepackage{subfigure}% Support for small, `sub' figures and tables
%\usepackage[nolists,tablesfirst]{endfloat}% To `separate' figures and tables from text if required

\usepackage{natbib}% Citation support using natbib.sty
\bibpunct[, ]{(}{)}{;}{a}{}{,}% Citation support using natbib.sty
\renewcommand\bibfont{\fontsize{10}{12}\selectfont}% Bibliography support using natbib.sty

\theoremstyle{plain}% Theorem-like structures provided by amsthm.sty
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheorem{notation}{Notation}

% see https://stackoverflow.com/a/47122900

% Pandoc citation processing

\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\def\tightlist{}


\begin{document}

\articletype{ARTICLE TEMPLATE}

\title{Why shouldn't you use numerical tests to diagnose the linear
regression models?}


\author{\name{Weihao Li$^{a}$, Dianne Cook$^{a}$, Emi Tanaka$^{a}$}
\affil{$^{a}$Department of Econometrics and Business Statistics, Monash
University, Clayton, VIC, Australia}
}

\thanks{CONTACT Weihao
Li. Email: \href{mailto:weihao.li@monash.edu}{\nolinkurl{weihao.li@monash.edu}}, Dianne
Cook. Email: \href{mailto:dicook@monash.edu}{\nolinkurl{dicook@monash.edu}}, Emi
Tanaka. Email: \href{mailto:emi.tanaka@monash.edu}{\nolinkurl{emi.tanaka@monash.edu}}}

\maketitle

\begin{abstract}
Abstract to fill.
\end{abstract}

\begin{keywords}
visual inference; model diagnostics;
\end{keywords}

problem: residual plot diagnostics conventional test: too sensitive

background:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  residual plot for model diagnostics
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  residual is widely used
\item
  what are the types of residual plots
\item
  comparison
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  conventional test: F, BP
\item
  visual test: lineup, theory
\end{enumerate}

desc of experiment: 1. simulation setup 2. experimental design 3. result

comparison of conventional tests: 1. power (visual test vs.~conventional
test) (visual test most different one (everything test, any departure))
plot figure in a paper, desc, exp 2. investigate the difference (gap),
give examples 3. conventional is too sensitive 4. make conventional less
sensitive (vary alpha)

conclusion: 1. too sensitive, visual test is needed/preferable 2. visual
test is infeasible in large scale (expensive) 3. future work (role of
computer vision)

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Regression diagnostics conventionally involve evaluating the fitness of
the proposed model, detecting the presence of influential observations
and outliers, checking the validity of model assumptions and many more.
Common diagnostic techniques including summary statistics, hypothesis
testing, and data plots are essential tools for a systematic and
detailed examination of the regression model
\citep{mansfield1987diagnostic}.

\hypertarget{diagnostic-plots}{%
\subsection{Diagnostic plots}\label{diagnostic-plots}}

Regression analysis is a field of study with at least a hundred years of
history. Many of those regression diagnostic methods and procedures are
mature and well-established in books first published in the twentieth
century, such as \citet{draper_applied_2014},
\citet{montgomery_introduction_2012}, \citet{belsley_regression_1980},
\citet{cook_applied_1999} and \citet{cook1982residuals}. Regardless of
the level of difficulty of the book, one will find the importance and
usefulness of diagnostic plots being emphasized again and again.
Checking diagnostic plots is also the recommended starting point for
validating model assumptions like normality, homoscedasticity and
linearity \citep{anscombe_examination_1963}.

Graphical summaries in which residuals are plotted against fitted values
or other functions of the predictor variables that are approximately
orthogonal to residuals are refereed to as standard residual plots. They
are commonly used to identify patterns which are indicative of
nonconstant error variance or non-linearity \citep{cook1982residuals}.
Raw residuals and studentized residuals are the two most frequently used
residuals in standard residual plots. The debt on which type of
residuals should be used always present. While raw residuals are the
most common output of computer regression software package, by applying
a scaling factor, the ability of revealing nonconstant error variance in
standard residual plots will often be enhanced by studentized residuals
in small sample size \citep{gunst2018regression}.

As a two-dimensional representation of a model in a \(p\)-dimensional
space, standard residual plots project data points onto the variable of
the horizontal axis, which is a vector in \(p\)-dimensional space.
Observations with the same projection will be treated as equivalent as
they have the same position of the abscissa. Therefore, standard
residual plots are often useful in revealing model inadequacies in the
direction of the variable of the horizontal axis, but could be
inadequate for detecting patterns in other directions, especially in
those perpendicular to the variable of the horizontal axis. Hence, in
practice, multiple standard residual plots with different horizontal
axes will be examined.

Overlapping data points is a general issue in scatter plots not limited
to standard residual plots, which often makes plots difficult to
interpret because visual patterns are concealed. Thus, for relatively
large sample size, \citet{cleveland1975graphical} suggests the use of
robust moving statistics as reference lines to give aids to eye in
seeing patterns, which nowadays, are usually replaced with a spline or
local polynomial regression line.

Other types of data plots that are often used in regression diagnostics
include partial residual plots and probability plots. Partial residual
plots are useful supplements to standard residual plots as they provide
additional information on the extent of the non-linearity. Probability
plots can be used to compare the sampling distribution of the residuals
to the normal distribution for assessing the normality assumptions.

\hypertarget{hypothesis-testing}{%
\subsection{Hypothesis testing}\label{hypothesis-testing}}

In addition to diagnostic plots, researcher may also perform formal
tests for detecting model defects. Depends on the alternative, variety
of tests can be applied. For example, for testing heteroskedasticity,
one may use the White test
\citep{white_heteroskedasticity-consistent_1980} or the Breusch-Pagan
test \citep{breusch_simple_1979}. And for testing non-linearity, there
are RESET test \citep{ramsey_tests_1969} and F-test.

As discussed in \citet{cook1982residuals}, most residual based tests for
a particular type of departures from model assumptions are sensitive to
other types of departures. Especially, outliers will often incorrectly
trigger the rejection of null hypothesis despite the residuals are
well-behaved \citep{cook_applied_1999}. This can be largely avoided in
diagnostic plots as experienced analysts can evaluate the acceptability
of assumptions flexibly, even in the presence of outliers. Furthermore,
\citet{montgomery_introduction_2012} stated that based on their
experience, statistical tests are not widely used in regression
diagnostics. Most importantly, the same or even larger amount of
information can be provided by diagnostic plots than the corresponding
tests in most empirical studies. But still, the effectiveness of
statistical tests shall not be disrespected. Statistical tests have
chance to provide analysts with unique information. There are also
situations where no suitable diagnostic plots can be found for a
particular violation of the assumptions, or excessive diagnostic plots
need to be checked. One will have no choice but to rely on statistical
tests if there is any. A good regression diagnostic practice should be a
combination of both methods.

\hypertarget{visual-inference}{%
\subsection{Visual inference}\label{visual-inference}}

Diagnostic plots are

\hypertarget{experimental-design}{%
\section{Experimental design}\label{experimental-design}}

\hypertarget{data-processing}{%
\section{Data processing}\label{data-processing}}

\hypertarget{results}{%
\section{Results}\label{results}}

\hypertarget{overview-of-the-data}{%
\subsection{Overview of the Data}\label{overview-of-the-data}}

We collected 400 lineup evaluations made by 20 participants in
experiment I and 880 lineup evaluations made by 44 participants in
experiment II. In total, 442 unique lineups were evaluated by 64
subjects. In experiment I, one of the participants skipped all 20
lineups. Hence, the submission was rejected and removed from the
dataset. In experiment II, there was a participant failed one of the two
attention checks, but there was no further evidence of low-effort
throughout the experiment. Therefore, the submission was kept.

\hypertarget{power-comparision}{%
\subsection{Power comparision}\label{power-comparision}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  power (visual test vs.~conventional test) (visual test most different
  one (everything test, any departure)) plot figure in a paper, desc,
  exp
\item
  investigate the difference (gap), give examples
\item
  conventional is too sensitive
\item
  make conventional less sensitive (vary alpha)
\end{enumerate}

It was expected that with larger effect size, both conventional test and
visual test will have higher probability in rejecting the null
hypothesis when it is not true. To explore the difference in power
between conventional test and visual test, ten logistic regression
models are fit to the data, with natural logarithm of the effect size as
the only fixed effect, and whether the test successfully rejects the
null hypothesis as the response variable. Table \ref{tab:powerglmheter}
and \ref{tab:powerglmheter} summarizes the results. The natural
logarithm of the effect size is positive and significant across all
models. Figure \ref{fig:power-com} illustrates the fitted models, while
providing the local constant estimate of the power of F-test and
Breusch--Pagan test for comparison. Data for the conventional test is
simulated under the same model setting used in two experiments and
500000 samples are drawn for both cubic and heteroskedasticity model.

From Figure \ref{fig:power-com}, it can be observed that the fitted
power of visual test increased as the number of evaluations increased
for both cubic and heteroskedasticity model.

For heteroskedasticity model, this phenomenon was more obvious as the
curves of visual tests with evaluations greater than two were always
above the curves of visual test with evaluations smaller than two.
However, this only held for large enough effect size. For small effect
size, visual tests with fewer evaluations might have greater power. Note
that, the expected power of visual test derived by
\citet{majumder_validation_2013} followed by the assumption that human
has the ability to select the plot with the highest t-statistic from a
lineup under the classical linear model regression setting showed
similar properties, where visual tests with fewer evaluations were
expected to perform better when the parameter values close to the null
hypothesis.

For cubic model, the separation between curves was small. Fitted power
of visual test with three to five evaluations were almost identical to
each other in regards of effect size. In addition, all five curves
peaked at one as effect size increased, suggesting that identification
of non-linearity as a visual task can be completed reliably by human
when the effect size is large enough.

As shown in Figure @ref(fig:power-com), both F-test and Breusch--Pagan
test generally possessed greater power than visual test. It was also
found that there was a huge gap between the conventional test curves and
the visual test curves at around \(log(\text{effect size}) = 0\) for the
cubic model and \(log(\text{effect size}) = 2.5\) for the
heteroskedasticity model.

We further analysed the lineup with the corresponding effect size.

\begin{table}[!htbp] \centering 
  \caption{Logistic regressions with rejection as response variable and natural logarithm of the effect size as regressor fitted on the data collected from experiment I and II for cubic model. Five regression were fitted for different number of evaluations.} 
  \label{tab:powerglmcubic} 
\begin{tabular}{@{\extracolsep{5pt}}lccccc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{5}{c}{\textit{Dependent variable:}} \\ 
\cline{2-6} 
\\[-1.8ex] & \multicolumn{5}{c}{reject} \\ 
 & num\_eval: 1 & num\_eval:2 & num\_eval: 3 & num\_eval: 4 & num\_eval:5 \\ 
\hline \\[-1.8ex] 
 log\_effect\_size & 0.929$^{***}$ & 1.258$^{***}$ & 1.096$^{***}$ & 1.113$^{***}$ & 1.244$^{***}$ \\ 
  & (0.073) & (0.076) & (0.054) & (0.056) & (0.077) \\ 
  & & & & & \\ 
 Constant & $-$1.969$^{***}$ & $-$2.534$^{***}$ & $-$1.549$^{***}$ & $-$1.334$^{***}$ & $-$1.404$^{***}$ \\ 
  & (0.169) & (0.173) & (0.113) & (0.122) & (0.185) \\ 
  & & & & & \\ 
\hline \\[-1.8ex] 
Observations & 630 & 1,135 & 1,660 & 1,904 & 1,879 \\ 
Log Likelihood & $-$220.882 & $-$314.394 & $-$471.152 & $-$396.979 & $-$206.296 \\ 
Akaike Inf. Crit. & 445.764 & 632.788 & 946.305 & 797.958 & 416.592 \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{5}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table}

\begin{table}[!htbp] \centering 
  \caption{Logistic regressions with rejection as response variable and natural logarithm of the effect size as regressor fitted on the data collected from experiment I and II for heteroskedasticity model. Five regression were fitted for different number of evaluations.} 
  \label{tab:powerglmheter} 
\begin{tabular}{@{\extracolsep{5pt}}lccccc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{5}{c}{\textit{Dependent variable:}} \\ 
\cline{2-6} 
\\[-1.8ex] & \multicolumn{5}{c}{reject} \\ 
 & num\_eval: 1 & num\_eval:2 & num\_eval: 3 & num\_eval: 4 & num\_eval:5 \\ 
\hline \\[-1.8ex] 
 log\_effect\_size & 0.821$^{***}$ & 1.104$^{***}$ & 1.157$^{***}$ & 1.387$^{***}$ & 1.651$^{***}$ \\ 
  & (0.086) & (0.079) & (0.066) & (0.076) & (0.110) \\ 
  & & & & & \\ 
 Constant & $-$4.472$^{***}$ & $-$5.887$^{***}$ & $-$5.431$^{***}$ & $-$6.154$^{***}$ & $-$7.123$^{***}$ \\ 
  & (0.434) & (0.415) & (0.344) & (0.400) & (0.591) \\ 
  & & & & & \\ 
\hline \\[-1.8ex] 
Observations & 630 & 1,138 & 1,596 & 1,662 & 1,416 \\ 
Log Likelihood & $-$333.119 & $-$631.519 & $-$835.317 & $-$650.570 & $-$342.058 \\ 
Akaike Inf. Crit. & 670.238 & 1,267.038 & 1,674.634 & 1,305.140 & 688.116 \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{5}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table}

\begin{figure}
\centering
\includegraphics{paper_comparison_files/figure-latex/power-com-1.pdf}
\caption{\label{fig:power-com}power com}
\end{figure}

\bibliographystyle{tfcad}
\bibliography{paper.bib}




\end{document}
